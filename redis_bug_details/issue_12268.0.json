{
  "issue_number": 12268.0,
  "title": "[CRASH] Redis cluster node crashes with assertion failure 'myself->numslots == 0' is not true",
  "body": "When testing redis cluster, we triggered an assertion failure in a cluster node. This happens in both the latest release (7.0.11) and the unstable branch.\r\n\r\n## Log\r\n\r\n```\r\n4013349:C 05 Jun 2023 19:17:28.867 # WARNING: Changing databases number from 16 to 1 since we are in cluster mode\r\n4013349:C 05 Jun 2023 19:17:28.867 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\r\n4013349:C 05 Jun 2023 19:17:28.867 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\r\n4013349:C 05 Jun 2023 19:17:28.867 * Redis version=255.255.255, bits=64, commit=0bd1a3a4, modified=0, pid=4013349, just started\r\n4013349:C 05 Jun 2023 19:17:28.867 * Configuration loaded\r\n4013349:M 05 Jun 2023 19:17:28.868 * Increased maximum number of open files to 10032 (it was originally set to 1024).\r\n4013349:M 05 Jun 2023 19:17:28.868 * monotonic clock: POSIX clock_gettime\r\n                _._\r\n           _.-``__ ''-._\r\n      _.-``    `.  `_.  ''-._           Redis 255.255.255 (0bd1a3a4/0) 64 bit\r\n  .-`` .-```.  ```\\/    _.,_ ''-._\r\n (    '      ,       .-`  | `,    )     Running in cluster mode\r\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\r\n |    `-._   `._    /     _.-'    |     PID: 4013349\r\n  `-._    `-._  `-./  _.-'    _.-'\r\n |`-._`-._    `-.__.-'    _.-'_.-'|\r\n |    `-._`-._        _.-'_.-'    |           https://redis.io\r\n  `-._    `-._`-.__.-'_.-'    _.-'\r\n |`-._`-._    `-.__.-'    _.-'_.-'|\r\n |    `-._`-._        _.-'_.-'    |\r\n  `-._    `-._`-.__.-'_.-'    _.-'\r\n      `-._    `-.__.-'    _.-'\r\n          `-._        _.-'\r\n              `-.__.-'\r\n\r\n4013349:M 05 Jun 2023 19:17:28.868 * Node configuration loaded, I'm 98e8b3aab4861ee22fdf92972c206a8420287b69\r\n4013349:M 05 Jun 2023 19:17:28.868 * Server initialized\r\n4013349:M 05 Jun 2023 19:17:28.869 * Loading RDB produced by version 255.255.255\r\n4013349:M 05 Jun 2023 19:17:28.869 * RDB age 3 seconds\r\n4013349:M 05 Jun 2023 19:17:28.869 * RDB memory usage when created 1.56 Mb\r\n4013349:M 05 Jun 2023 19:17:28.869 * Done loading RDB, keys loaded: 0, keys expired: 0.\r\n4013349:M 05 Jun 2023 19:17:28.869 * DB loaded from disk: 0.000 seconds\r\n4013349:M 05 Jun 2023 19:17:28.869 * Ready to accept connections tcp\r\n4013349:M 05 Jun 2023 19:18:31.186 - Accepted 127.0.0.1:49084\r\n4013349:M 05 Jun 2023 19:18:31.192 * configEpoch set to 1 via CLUSTER SET-CONFIG-EPOCH\r\n4013349:M 05 Jun 2023 19:18:31.216 - Accepting cluster node connection from 127.0.0.1:34398\r\n4013349:M 05 Jun 2023 19:18:31.216 * IP address for this node updated to 127.0.0.1\r\n4013349:M 05 Jun 2023 19:18:31.252 - Accepting cluster node connection from 127.0.0.1:34404\r\n4013349:M 05 Jun 2023 19:18:35.195 - Client closed connection id=3 addr=127.0.0.1:49084 laddr=127.0.0.1:6379 fd=11 name= age=4 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=1024 rbp=1024 obl=0 oll=0 omem=0 tot-mem=22400 events=r cmd=cluster|nodes user=default redir=-1 resp=2 lib-name= lib-ver=\r\n4013349:M 05 Jun 2023 19:18:36.170 * Cluster state changed: ok\r\n4013349:M 05 Jun 2023 19:18:43.847 - Accepted 127.0.0.1:52222\r\n4013349:M 05 Jun 2023 19:18:43.847 # Cluster state changed: fail\r\n4013349:M 05 Jun 2023 19:18:43.848 - Client closed connection id=4 addr=127.0.0.1:52222 laddr=127.0.0.1:6379 fd=11 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=37760 events=r cmd=cluster|flushslots user=default redir=-1 resp=2 lib-name= lib-ver=\r\n4013349:M 05 Jun 2023 19:18:58.606 - Accepted 127.0.0.1:47218\r\n4013349:S 05 Jun 2023 19:18:58.606 * Before turning into a replica, using my own master parameters to synthesize a cached master: I may be able to synchronize with the new master with just a partial transfer.\r\n4013349:S 05 Jun 2023 19:18:58.606 * Connecting to MASTER 127.0.0.1:6381\r\n4013349:S 05 Jun 2023 19:18:58.606 * MASTER <-> REPLICA sync started\r\n4013349:S 05 Jun 2023 19:18:58.606 * Non blocking connect for SYNC fired the event.\r\n4013349:S 05 Jun 2023 19:18:58.606 * Master replied to PING, replication can continue...\r\n4013349:S 05 Jun 2023 19:18:58.606 * Trying a partial resynchronization (request 87fa56f55113dec207d1dbf0caf7b5ec93da853d:1).\r\n4013349:S 05 Jun 2023 19:18:58.606 - Client closed connection id=5 addr=127.0.0.1:47218 laddr=127.0.0.1:6379 fd=11 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=37760 events=r cmd=cluster|replicate user=default redir=-1 resp=2 lib-name= lib-ver=\r\n4013349:S 05 Jun 2023 19:19:03.878 * Full resync from master: b0d2ec9ec5e1a58ce258843c59f0f8ed63720f0a:14\r\n4013349:S 05 Jun 2023 19:19:03.879 * MASTER <-> REPLICA sync: receiving streamed RDB from master with EOF to disk\r\n4013349:S 05 Jun 2023 19:19:03.879 * Discarding previously cached master state.\r\n4013349:S 05 Jun 2023 19:19:03.879 * MASTER <-> REPLICA sync: Flushing old data\r\n4013349:S 05 Jun 2023 19:19:03.879 * MASTER <-> REPLICA sync: Loading DB in memory\r\n4013349:S 05 Jun 2023 19:19:03.880 * Loading RDB produced by version 255.255.255\r\n4013349:S 05 Jun 2023 19:19:03.880 * RDB age 0 seconds\r\n4013349:S 05 Jun 2023 19:19:03.880 * RDB memory usage when created 1.78 Mb\r\n4013349:S 05 Jun 2023 19:19:03.880 * Done loading RDB, keys loaded: 0, keys expired: 0.\r\n4013349:S 05 Jun 2023 19:19:03.880 * MASTER <-> REPLICA sync: Finished with success\r\n4013349:S 05 Jun 2023 19:19:23.106 - Accepted 127.0.0.1:39290\r\n4013349:S 05 Jun 2023 19:19:23.107 - Client closed connection id=8 addr=127.0.0.1:39290 laddr=127.0.0.1:6379 fd=17 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=37760 events=r cmd=cluster|addslots user=default redir=-1 resp=2 lib-name= lib-ver=\r\n4013349:S 05 Jun 2023 19:19:37.890 - Accepted 127.0.0.1:55736\r\n\r\n\r\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\r\n4013349:S 05 Jun 2023 19:19:37.890 # === ASSERTION FAILED ===\r\n4013349:S 05 Jun 2023 19:19:37.890 # ==> cluster.c:4931 'myself->numslots == 0' is not true\r\n\r\n------ STACK TRACE ------\r\n\r\nBacktrace:\r\n../../redis-server *:6379 [cluster](+0x13755b)[0x555b25be055b]\r\n../../redis-server *:6379 [cluster](clusterCommand+0xf67)[0x555b25be5ee7]\r\n../../redis-server *:6379 [cluster](call+0x186)[0x555b25b40bb6]\r\n../../redis-server *:6379 [cluster](processCommand+0xba9)[0x555b25b42149]\r\n../../redis-server *:6379 [cluster](processInputBuffer+0x107)[0x555b25b67f27]\r\n../../redis-server *:6379 [cluster](readQueryFromClient+0x368)[0x555b25b684a8]\r\n../../redis-server *:6379 [cluster](+0x1c11ac)[0x555b25c6a1ac]\r\n../../redis-server *:6379 [cluster](aeMain+0xf9)[0x555b25b368d9]\r\n../../redis-server *:6379 [cluster](main+0x3df)[0x555b25b2afbf]\r\n/lib/x86_64-linux-gnu/libc.so.6(+0x29d90)[0x7f843b1d7d90]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80)[0x7f843b1d7e40]\r\n../../redis-server *:6379 [cluster](_start+0x25)[0x555b25b2b785]\r\n\r\n------ INFO OUTPUT ------\r\n# Server\r\nredis_version:255.255.255\r\nredis_git_sha1:0bd1a3a4\r\nredis_git_dirty:0\r\nredis_build_id:b5019077ff9fccd6\r\nredis_mode:cluster\r\nos:Linux 5.15.0-47-generic x86_64\r\narch_bits:64\r\nmonotonic_clock:POSIX clock_gettime\r\nmultiplexing_api:epoll\r\natomicvar_api:c11-builtin\r\ngcc_version:11.3.0\r\nprocess_id:4013349\r\nprocess_supervised:no\r\nrun_id:1a181acb00bab7e09911f945efb86254322d9dfa\r\ntcp_port:6379\r\nserver_time_usec:1685992777890620\r\nuptime_in_seconds:129\r\nuptime_in_days:0\r\nhz:10\r\nconfigured_hz:10\r\nlru_clock:8271177\r\nexecutable:/home/congyu/redis/src/redis-server\r\nconfig_file:\r\nio_threads_active:0\r\nlistener0:name=tcp,bind=*,bind=-::*,port=6379\r\n\r\n# Clients\r\nconnected_clients:2\r\ncluster_connections:4\r\nmaxclients:10000\r\nclient_recent_max_input_buffer:24\r\nclient_recent_max_output_buffer:0\r\nblocked_clients:0\r\ntracking_clients:0\r\nclients_in_timeout_table:0\r\ntotal_blocking_keys:0\r\ntotal_blocking_keys_on_nokey:0\r\n\r\n# Memory\r\nused_memory:1854360\r\nused_memory_human:1.77M\r\nused_memory_rss:8544256\r\nused_memory_rss_human:8.15M\r\nused_memory_peak:1900440\r\nused_memory_peak_human:1.81M\r\nused_memory_peak_perc:97.58%\r\nused_memory_overhead:1609404\r\nused_memory_startup:1582480\r\nused_memory_dataset:244956\r\nused_memory_dataset_perc:90.10%\r\nallocator_allocated:2138096\r\nallocator_active:2600960\r\nallocator_resident:12455936\r\ntotal_system_memory:134750920704\r\ntotal_system_memory_human:125.50G\r\nused_memory_lua:31744\r\nused_memory_vm_eval:31744\r\nused_memory_lua_human:31.00K\r\nused_memory_scripts_eval:0\r\nnumber_of_cached_scripts:0\r\nnumber_of_functions:0\r\nnumber_of_libraries:0\r\nused_memory_vm_functions:32768\r\nused_memory_vm_total:64512\r\nused_memory_vm_total_human:63.00K\r\nused_memory_functions:184\r\nused_memory_scripts:184\r\nused_memory_scripts_human:184B\r\nmaxmemory:0\r\nmaxmemory_human:0B\r\nmaxmemory_policy:noeviction\r\nallocator_frag_ratio:1.22\r\nallocator_frag_bytes:462864\r\nallocator_rss_ratio:4.79\r\nallocator_rss_bytes:9854976\r\nrss_overhead_ratio:0.69\r\nrss_overhead_bytes:-3911680\r\nmem_fragmentation_ratio:4.71\r\nmem_fragmentation_bytes:6730152\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:20508\r\nmem_total_replication_buffers:20504\r\nmem_clients_slaves:0\r\nmem_clients_normal:1944\r\nmem_cluster_links:4288\r\nmem_aof_buffer:0\r\nmem_allocator:jemalloc-5.3.0\r\nactive_defrag_running:0\r\nlazyfree_pending_objects:0\r\nlazyfreed_objects:0\r\n\r\n# Persistence\r\nloading:0\r\nasync_loading:0\r\ncurrent_cow_peak:0\r\ncurrent_cow_size:0\r\ncurrent_cow_size_age:0\r\ncurrent_fork_perc:0.00\r\ncurrent_save_keys_processed:0\r\ncurrent_save_keys_total:0\r\nrdb_changes_since_last_save:0\r\nrdb_bgsave_in_progress:0\r\nrdb_last_save_time:1685992648\r\nrdb_last_bgsave_status:ok\r\nrdb_last_bgsave_time_sec:-1\r\nrdb_current_bgsave_time_sec:-1\r\nrdb_saves:0\r\nrdb_last_cow_size:0\r\nrdb_last_load_keys_expired:0\r\nrdb_last_load_keys_loaded:0\r\naof_enabled:0\r\naof_rewrite_in_progress:0\r\naof_rewrite_scheduled:0\r\naof_last_rewrite_time_sec:-1\r\naof_current_rewrite_time_sec:-1\r\naof_last_bgrewrite_status:ok\r\naof_rewrites:0\r\naof_rewrites_consecutive_failures:0\r\naof_last_write_status:ok\r\naof_last_cow_size:0\r\nmodule_fork_in_progress:0\r\nmodule_fork_last_cow_size:0\r\n\r\n# Stats\r\ntotal_connections_received:5\r\ntotal_commands_processed:19\r\ninstantaneous_ops_per_sec:0\r\ntotal_net_input_bytes:54382\r\ntotal_net_output_bytes:19564\r\ntotal_net_repl_input_bytes:306\r\ntotal_net_repl_output_bytes:0\r\ninstantaneous_input_kbps:0.00\r\ninstantaneous_output_kbps:0.02\r\ninstantaneous_input_repl_kbps:0.00\r\ninstantaneous_output_repl_kbps:0.00\r\nrejected_connections:0\r\nsync_full:0\r\nsync_partial_ok:0\r\nsync_partial_err:0\r\nexpired_keys:0\r\nexpired_stale_perc:0.00\r\nexpired_time_cap_reached_count:0\r\nexpire_cycle_cpu_milliseconds:0\r\nevicted_keys:0\r\nevicted_clients:0\r\ntotal_eviction_exceeded_time:0\r\ncurrent_eviction_exceeded_time:0\r\nkeyspace_hits:0\r\nkeyspace_misses:0\r\npubsub_channels:0\r\npubsub_patterns:0\r\npubsubshard_channels:0\r\nlatest_fork_usec:0\r\ntotal_forks:0\r\nmigrate_cached_sockets:0\r\nslave_expires_tracked_keys:0\r\nactive_defrag_hits:0\r\nactive_defrag_misses:0\r\nactive_defrag_key_hits:0\r\nactive_defrag_key_misses:0\r\ntotal_active_defrag_time:0\r\ncurrent_active_defrag_time:0\r\ntracking_total_keys:0\r\ntracking_total_items:0\r\ntracking_total_prefixes:0\r\nunexpected_error_replies:0\r\ntotal_error_replies:0\r\ndump_payload_sanitizations:0\r\ntotal_reads_processed:26\r\ntotal_writes_processed:51\r\nio_threaded_reads_processed:0\r\nio_threaded_writes_processed:0\r\nreply_buffer_shrinks:2\r\nreply_buffer_expands:0\r\neventloop_cycles:1601\r\neventloop_duration_sum:59284\r\neventloop_duration_cmd_sum:1109\r\ninstantaneous_eventloop_cycles_per_sec:12\r\ninstantaneous_eventloop_duration_usec:33\r\nacl_access_denied_auth:0\r\nacl_access_denied_cmd:0\r\nacl_access_denied_key:0\r\nacl_access_denied_channel:0\r\n\r\n# Replication\r\nrole:slave\r\nmaster_host:127.0.0.1\r\nmaster_port:6381\r\nmaster_link_status:up\r\nmaster_last_io_seconds_ago:5\r\nmaster_sync_in_progress:0\r\nslave_read_repl_offset:56\r\nslave_repl_offset:56\r\nslave_priority:100\r\nslave_read_only:1\r\nreplica_announced:1\r\nconnected_slaves:0\r\nmaster_failover_state:no-failover\r\nmaster_replid:b0d2ec9ec5e1a58ce258843c59f0f8ed63720f0a\r\nmaster_replid2:0000000000000000000000000000000000000000\r\nmaster_repl_offset:56\r\nsecond_repl_offset:-1\r\nrepl_backlog_active:1\r\nrepl_backlog_size:1048576\r\nrepl_backlog_first_byte_offset:15\r\nrepl_backlog_histlen:42\r\n\r\n# CPU\r\nused_cpu_sys:0.032695\r\nused_cpu_user:0.033974\r\nused_cpu_sys_children:0.000000\r\nused_cpu_user_children:0.000000\r\nused_cpu_sys_main_thread:0.040645\r\nused_cpu_user_main_thread:0.025403\r\n\r\n# Modules\r\n\r\n# Commandstats\r\ncmdstat_ping:calls=3,usec=0,usec_per_call=0.00,rejected_calls=0,failed_calls=0\r\ncmdstat_info:calls=3,usec=134,usec_per_call=44.67,rejected_calls=0,failed_calls=0\r\ncmdstat_cluster|addslots:calls=2,usec=160,usec_per_call=80.00,rejected_calls=0,failed_calls=0\r\ncmdstat_cluster|info:calls=1,usec=8,usec_per_call=8.00,rejected_calls=0,failed_calls=0\r\ncmdstat_cluster|flushslots:calls=1,usec=492,usec_per_call=492.00,rejected_calls=0,failed_calls=0\r\ncmdstat_cluster|nodes:calls=7,usec=211,usec_per_call=30.14,rejected_calls=0,failed_calls=0\r\ncmdstat_cluster|replicate:calls=1,usec=94,usec_per_call=94.00,rejected_calls=0,failed_calls=0\r\ncmdstat_cluster|set-config-epoch:calls=1,usec=10,usec_per_call=10.00,rejected_calls=0,failed_calls=0\r\n\r\n# Errorstats\r\n\r\n# Latencystats\r\nlatency_percentiles_usec_ping:p50=0.001,p99=0.001,p99.9=0.001\r\nlatency_percentiles_usec_info:p50=38.143,p99=72.191,p99.9=72.191\r\nlatency_percentiles_usec_cluster|addslots:p50=15.039,p99=145.407,p99.9=145.407\r\nlatency_percentiles_usec_cluster|info:p50=8.031,p99=8.031,p99.9=8.031\r\nlatency_percentiles_usec_cluster|flushslots:p50=493.567,p99=493.567,p99.9=493.567\r\nlatency_percentiles_usec_cluster|nodes:p50=28.031,p99=38.143,p99.9=38.143\r\nlatency_percentiles_usec_cluster|replicate:p50=94.207,p99=94.207,p99.9=94.207\r\nlatency_percentiles_usec_cluster|set-config-epoch:p50=10.047,p99=10.047,p99.9=10.047\r\n\r\n# Cluster\r\ncluster_enabled:1\r\n\r\n# Keyspace\r\n\r\n# Cluster info\r\ncluster_state:fail\r\ncluster_slots_assigned:10924\r\ncluster_slots_ok:10924\r\ncluster_slots_pfail:0\r\ncluster_slots_fail:0\r\ncluster_known_nodes:3\r\ncluster_size:2\r\ncluster_current_epoch:3\r\ncluster_my_epoch:3\r\ncluster_stats_messages_ping_sent:64\r\ncluster_stats_messages_pong_sent:70\r\ncluster_stats_messages_sent:134\r\ncluster_stats_messages_ping_received:68\r\ncluster_stats_messages_pong_received:64\r\ncluster_stats_messages_meet_received:2\r\ncluster_stats_messages_received:134\r\ntotal_cluster_links_buffer_limit_exceeded:0\r\n\r\n------ CLUSTER NODES OUTPUT ------\r\na4d687936a05fabea0798f35c494390af1fd6a24 127.0.0.1:6380@16380,,shard-id=9a86af15129537b02350ee8bfe72ae2c040fd2d1 master - 0 1685992775976 2 connected 5461-10922\r\ncab2ad6ff2a6f611b7e9873c3cafa455bd951222 127.0.0.1:6381@16381,,shard-id=63204e65945e016afa82fc37d12a465affe6b5b5 master - 0 1685992776978 3 connected 10923-16383\r\n98e8b3aab4861ee22fdf92972c206a8420287b69 127.0.0.1:6379@16379,,shard-id=63204e65945e016afa82fc37d12a465affe6b5b5 myself,slave cab2ad6ff2a6f611b7e9873c3cafa455bd951222 0 1685992776000 3 connected 1\r\n\r\n------ CLIENT LIST OUTPUT ------\r\nid=7 addr=127.0.0.1:6381 laddr=127.0.0.1:42290 fd=16 name= age=34 idle=5 flags=M db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=14 argv-mem=0 multi-mem=0 rbs=1024 rbp=35 obl=0 oll=0 omem=0 tot-mem=1944 events=r cmd=ping user=(superuser) redir=-1 resp=2 lib-name= lib-ver=\r\nid=9 addr=127.0.0.1:55736 laddr=127.0.0.1:6379 fd=17 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=79 qbuf-free=20395 argv-mem=56 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=37840 events=r cmd=cluster|replicate user=default redir=-1 resp=2 lib-name= lib-ver=\r\n\r\n------ CURRENT CLIENT INFO ------\r\nid=9 addr=127.0.0.1:55736 laddr=127.0.0.1:6379 fd=17 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=79 qbuf-free=20395 argv-mem=56 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=37840 events=r cmd=cluster|replicate user=default redir=-1 resp=2 lib-name= lib-ver=\r\nargc: '3'\r\nargv[0]: '\"CLUSTER\"'\r\nargv[1]: '\"REPLICATE\"'\r\nargv[2]: '\"a4d687936a05fabea0798f35c494390af1fd6a24\"'\r\n\r\n------ EXECUTING CLIENT INFO ------\r\nid=9 addr=127.0.0.1:55736 laddr=127.0.0.1:6379 fd=17 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=79 qbuf-free=20395 argv-mem=56 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=37840 events=r cmd=cluster|replicate user=default redir=-1 resp=2 lib-name= lib-ver=\r\nargc: '3'\r\nargv[0]: '\"CLUSTER\"'\r\nargv[1]: '\"REPLICATE\"'\r\nargv[2]: '\"a4d687936a05fabea0798f35c494390af1fd6a24\"'\r\n\r\n------ MODULES INFO OUTPUT ------\r\n\r\n------ CONFIG DEBUG OUTPUT ------\r\nrepl-diskless-load disabled\r\nlazyfree-lazy-user-flush no\r\nio-threads-do-reads no\r\nproto-max-bulk-len 512mb\r\nreplica-read-only yes\r\nlazyfree-lazy-server-del no\r\nsanitize-dump-payload no\r\nlazyfree-lazy-user-del no\r\nclient-query-buffer-limit 1gb\r\nlazyfree-lazy-expire no\r\nio-threads 1\r\nrepl-diskless-sync yes\r\nlazyfree-lazy-eviction no\r\nactivedefrag no\r\nslave-read-only yes\r\nlist-compress-depth 0\r\n\r\n------ FAST MEMORY TEST ------\r\n4013349:S 05 Jun 2023 19:19:37.891 # Bio worker thread #0 terminated\r\n4013349:S 05 Jun 2023 19:19:37.891 # Bio worker thread #1 terminated\r\n4013349:S 05 Jun 2023 19:19:37.891 # Bio worker thread #2 terminated\r\n*** Preparing to test memory region 555b25e26000 (2269184 bytes)\r\n*** Preparing to test memory region 555b276d4000 (135168 bytes)\r\n*** Preparing to test memory region 7f8430000000 (135168 bytes)\r\n*** Preparing to test memory region 7f8437000000 (8388608 bytes)\r\n*** Preparing to test memory region 7f8437800000 (2097152 bytes)\r\n*** Preparing to test memory region 7f8437c00000 (8388608 bytes)\r\n*** Preparing to test memory region 7f8438400000 (6291456 bytes)\r\n*** Preparing to test memory region 7f8438a15000 (8388608 bytes)\r\n*** Preparing to test memory region 7f8439216000 (8388608 bytes)\r\n*** Preparing to test memory region 7f8439a17000 (8388608 bytes)\r\n*** Preparing to test memory region 7f843a217000 (3145728 bytes)\r\n*** Preparing to test memory region 7f843a800000 (8388608 bytes)\r\n*** Preparing to test memory region 7f843b1ab000 (12288 bytes)\r\n*** Preparing to test memory region 7f843b3c9000 (53248 bytes)\r\n*** Preparing to test memory region 7f843b4cc000 (8192 bytes)\r\n.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O\r\nFast memory test PASSED, however your memory can still be broken. Please run a memory test for several hours if possible.\r\n\r\n=== REDIS BUG REPORT END. Make sure to include from START to END. ===\r\n\r\n       Please report the crash by opening an issue on github:\r\n\r\n           http://github.com/redis/redis/issues\r\n\r\n  If a Redis module was involved, please open in the module's repo instead.\r\n\r\n  Suspect RAM error? Use redis-server --test-memory to verify it.\r\n\r\n  Some other issues could be detected by redis-server --check-system\r\nAborted (core dumped)\r\n```\r\n\r\n\r\n## Reproduce\r\n\r\nFirst start a redis cluster with 3 nodes with options `--protected-mode no --cluster-enabled yes --loglevel verbose --port ...`. Then run following commands. Here I started three nodes locally with port 6379, 6380 and 6381. Node 6379 crashes eventually.\r\n\r\n```shell\r\n$./redis-cli --cluster-yes --cluster create 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381\r\n>>> Performing hash slots allocation on 3 nodes...\r\nMaster[0] -> Slots 0 - 5460\r\nMaster[1] -> Slots 5461 - 10922\r\nMaster[2] -> Slots 10923 - 16383\r\nM: 98e8b3aab4861ee22fdf92972c206a8420287b69 127.0.0.1:6379\r\n   slots:[0-5460] (5461 slots) master\r\nM: a4d687936a05fabea0798f35c494390af1fd6a24 127.0.0.1:6380\r\n   slots:[5461-10922] (5462 slots) master\r\nM: cab2ad6ff2a6f611b7e9873c3cafa455bd951222 127.0.0.1:6381\r\n   slots:[10923-16383] (5461 slots) master\r\n>>> Nodes configuration updated\r\n>>> Assign a different config epoch to each node\r\n>>> Sending CLUSTER MEET messages to join the cluster\r\nWaiting for the cluster to join\r\n...\r\n>>> Performing Cluster Check (using node 127.0.0.1:6379)\r\nM: 98e8b3aab4861ee22fdf92972c206a8420287b69 127.0.0.1:6379\r\n   slots:[0-5460] (5461 slots) master\r\nM: a4d687936a05fabea0798f35c494390af1fd6a24 127.0.0.1:6380\r\n   slots:[5461-10922] (5462 slots) master\r\nM: cab2ad6ff2a6f611b7e9873c3cafa455bd951222 127.0.0.1:6381\r\n   slots:[10923-16383] (5461 slots) master\r\n[OK] All nodes agree about slots configuration.\r\n>>> Check for open slots...\r\n>>> Check slots coverage...\r\n[OK] All 16384 slots covered.\r\n$ ./redis-cli -p 6379 -c CLUSTER FLUSHSLOTS\r\nOK\r\n$ ./redis-cli -p 6381 -c CLUSTER MYID\r\n\"cab2ad6ff2a6f611b7e9873c3cafa455bd951222\"\r\n$ ./redis-cli -p 6379 -c CLUSTER REPLICATE cab2ad6ff2a6f611b7e9873c3cafa455bd951222\r\nOK\r\n$ ./redis-cli -p 6379 -c CLUSTER ADDSLOTS 1\r\nOK\r\n$ ./redis-cli -p 6380 -c CLUSTER MYID\r\n\"a4d687936a05fabea0798f35c494390af1fd6a24\"\r\n$ ./redis-cli -p 6379 -c CLUSTER REPLICATE a4d687936a05fabea0798f35c494390af1fd6a24\r\nError: Server closed the connection\r\n```",
  "state": "open",
  "created_at": "2023-06-05T19:31:08Z",
  "updated_at": "2023-06-08T04:04:16Z",
  "closed_at": null,
  "labels": [],
  "comments_data": [
    {
      "id": 1581230915,
      "user": "hwware",
      "created_at": "2023-06-07T17:20:29Z",
      "body": "Hello @Congyu-Liu , I tried to reproduce the issue in latest redis version, but I cannot see any crash,In fact redis is displying the correct error msg.\r\n![image](https://github.com/redis/redis/assets/51993843/ac4b7fbd-cda2-4c87-887e-1abf54df87d9)\r\n\r\nIs there is something else , you were doing along with this steps.? Could you share more info."
    },
    {
      "id": 1581280543,
      "user": "Congyu-Liu",
      "created_at": "2023-06-07T18:03:51Z",
      "body": "Hi @hwware. It seems that you miss a CLUSTER REPLICATE command before CLUSTER ADDSLOTS. Also some commands are not sent to the correct node.\r\n\r\nIn short, here is what the input does: \r\n1. Flush slots on node 0\r\n2. Let node 0 replicate node 1\r\n3.  Add slot 1 in node 0\r\n4. Let node 0 replicate node 2\r\n\r\nI just added some comments in the instruction. Hopefully it can be helpful.\r\n```shell\r\n# CLUSTER FLUSHSLOTS send to node 0\r\n$ ./redis-cli -p 6379 -c CLUSTER FLUSHSLOTS\r\nOK\r\n# CLUSTER MYID send to node 2\r\n$ ./redis-cli -p 6381 -c CLUSTER MYID\r\n\"cab2ad6ff2a6f611b7e9873c3cafa455bd951222\"\r\n# CLUSTER REPLICATE send to node 0\r\n$ ./redis-cli -p 6379 -c CLUSTER REPLICATE cab2ad6ff2a6f611b7e9873c3cafa455bd951222\r\nOK\r\n# CLUSTER ADDSLOTS 1 send to node 0\r\n$ ./redis-cli -p 6379 -c CLUSTER ADDSLOTS 1\r\nOK\r\n# CLUSTER MYID send to node 1\r\n$ ./redis-cli -p 6380 -c CLUSTER MYID\r\n\"a4d687936a05fabea0798f35c494390af1fd6a24\"\r\n# CLUSTER REPLICATE send to node 0\r\n$ ./redis-cli -p 6379 -c CLUSTER REPLICATE a4d687936a05fabea0798f35c494390af1fd6a24\r\nError: Server closed the connection\r\n```"
    },
    {
      "id": 1581859358,
      "user": "enjoy-binbin",
      "created_at": "2023-06-08T04:04:15Z",
      "body": "thanks for the report, i reproduced it and located the problem, we will fix it\r\nmaybe an overlook in https://github.com/redis/redis/commit/ac3850cabd3944c06a07ece83ad44f3dc6ad50c3"
    }
  ]
}