{
  "issue_number": 13659.0,
  "title": "[BUG] Performance regression of mset command after introducing INFO KEYSIZES",
  "body": "**Describe the bug**\r\n\r\nWhen running redis-benchmark, I found that the mset benchmark on latest unstable version(#[cf83803](https://github.com/redis/redis/commit/cf838038802b6d5049e3368953a3a737dd3aaee5)) is obviously slower than v7.4.1, and there is about 5~10% performance degradation.\r\n\r\n**To reproduce**\r\nEnter the installation directory of Redis, run the following script to benchmarking mset 100 rounds:\r\n``` bash\r\n#!/bin/bash\r\nTEST_ROUNDS=100\r\nfor i in $(seq 1 $TEST_ROUNDS)\r\ndo\r\n    rm -f dump.rdb\r\n    taskset -c 7 ./redis-server --save \"\" --daemonize yes\r\n    sleep 0.5\r\n    taskset -c 11 ./redis-benchmark -t mset --csv > ${i}.csv\r\n    taskset -c 11 ./redis-cli shutdown\r\n    sleep 0.5\r\ndone\r\n```\r\nThen run the python script to integrate 100 test results into one table:\r\n``` python\r\nimport pandas as pd\r\n\r\nround_number = 100\r\noutput_file = 'output.csv'\r\ndata = {}\r\n\r\n# Read file data\r\nfor i in range(1, round_number + 1):\r\n    file_name = f'{i}.csv'\r\n    df = pd.read_csv(file_name, index_col=0)\r\n    \r\n    for test_name in df.index:\r\n        for metric_name in df.columns:\r\n            if metric_name == 'avg_latency_ms' or metric_name == 'p99_latency_ms':\r\n                key = f'{test_name}@{metric_name}'\r\n                if key not in data:\r\n                    data[key] = [''] * round_number\r\n                data[key][i-1] = df.at[test_name, metric_name]\r\n\r\n# Generate a new DataFrame\r\nkeys = sorted(data.keys())\r\noutput_data = {str(i): [data[key][i-1] for key in keys] for i in range(1, round_number + 1)}\r\noutput_df = pd.DataFrame(output_data, index=keys)\r\n\r\n# Save as a CSV file\r\noutput_df.to_csv(output_file)\r\n```\r\nI ran the command on v7.4.1 and latest unstable version, obtained their respective 100 rounds of test data, and calculated the average of MSET (10 keys)@avg_latency_ms and MSET (10 keys)@p99_latency_ms:\r\n|               | MSET (10 keys)@avg_latency_ms | MSET (10 keys)@p99_latency_ms |\r\n| --------  | ------------------------------------ | ------------------------------------ |\r\n|   7.4.1    |                     0.21391                     |                    0.41932                      |\r\n|   latest   |                     0.24663                     |                    0.49308                      |\r\n\r\nDraw the line chart to show differences more clearly:\r\nhttps://github.com/user-attachments/assets/bef1be1c-d3da-4d7e-b78d-8908fa83c649\r\nhttps://github.com/user-attachments/assets/193c68e1-581d-49aa-9ae2-e4fba6e1e739\r\n\r\nI also modified the `processCommandAndResetClient` to measure and print the latency of `processCommand` if mset command is processed:\r\n``` c\r\n    clock_gettime(CLOCK_MONOTONIC, &start);\r\n    int res = processCommand(c);\r\n    clock_gettime(CLOCK_MONOTONIC, &stop);\r\n    long nanos = (stop.tv_sec - start.tv_sec) * 1000000000 + (stop.tv_nsec - start.tv_nsec);\r\n    if (!strcmp((char*)c->argv[0]->ptr, \"MSET\")) {\r\n        printf(\"%f us\", nanos / 1000.0);\r\n    }\r\n```\r\nUsing `redis-benchmark -t mset` to trigger the instrumentation, the `processCommand`  averagely costs 1.89 us in 7.4.1 while 2.17us in latest unstable version.\r\n\r\n**Expected behavior**\r\nThe mset benchmark on latest unstable version has same performance with v7.4.1.\r\n\r\n**Additional information**\r\nWith some debugging methods, I finally found that #[2ec78d2](https://github.com/redis/redis/commit/2ec78d262d06e8097e12278bd10c4c0216f4d1c9) can be the main culprit of performance degradation. The commit added two calls to `updateKeysizesList` in the `dbSetValue` function, but it seems that the change introduced a little high overhead for mset benchmark. I ran the above scripts and drew the chart for the version exactly before this commit(old) and after this commit(new), and the chart show the differences:\r\nhttps://github.com/user-attachments/assets/89bce2a0-88b2-4ce8-a61a-4ff0c0cc21da\r\nhttps://github.com/user-attachments/assets/a672aac0-0ba5-461d-b23a-b2cc95bf9e0d\r\n\r\nAlso, measure the latency of `processCommand`. Before this commit, it costs 1.97us. After this commit, it costs 2.27us.\r\nIf I delete two calls to `updateKeysizesList` in the `dbSetValue` function, then the performance regression seems disappeared.\r\n\r\n",
  "state": "open",
  "created_at": "2024-11-19T14:59:05Z",
  "updated_at": "2024-11-20T16:11:23Z",
  "closed_at": null,
  "labels": [],
  "comments_data": [
    {
      "id": 2487787597,
      "user": "ShooterIT",
      "created_at": "2024-11-20T07:52:21Z",
      "body": "thanks for your report @Gallopm \r\n@moticless could you have a look, maybe `mset` command make it obvious,  it seems our `Performance Automation` doesn't have `mset`, only have `hmset` https://github.com/redis/redis/pull/13592#issuecomment-2413111949 @fcostaoliveira "
    },
    {
      "id": 2488925172,
      "user": "moticless",
      "created_at": "2024-11-20T15:41:18Z",
      "body": "Hi @Gallopm, \r\nthanks for the invstigation. The function `updateKeySizesHist` on its own written rather optimized, I guess most of the penalty reaches from cache miss. \r\n\r\nWe can reduce the two calls into one call by extedning the function declaration to become:\r\n```\r\nvoid updateKeysizesHist(redisDb *db, int didx, uint32_t type, uint64_t oldLen, uint64_t newLen);\r\n--->\r\nvoid updateKeysizesHist(redisDb *db, int didx, uint32_t oldType, uint64_t oldLen, uint32_t newType, uint64_t newLen) ;\r\n```\r\n\r\nSuch that at function `dbSetValue()` it will be:\r\n```\r\nupdateKeysizesHist(db, slot, old->type, getObjectLength(old), 0);\r\nupdateKeysizesHist(db, slot, val->type, 0, getObjectLength(val));\r\n--->\r\nupdateKeysizesHist(db, slot, old->type, getObjectLength(old), val->type, getObjectLength(val));\r\n```\r\n\r\nBefore exploring this issue further, i think we should have first a benchmark coverage that will backup our effort. \r\n\r\n@fcostaoliveira WDYT?\r\n"
    },
    {
      "id": 2489002154,
      "user": "fcostaoliveira",
      "created_at": "2024-11-20T16:11:21Z",
      "body": "@moticless concerning:\r\n>Before exploring this issue further, i think we should have first a benchmark coverage that will backup our effort.\r\n> @fcostaoliveira WDYT?\r\n\r\ntotally agree. will add it today EOD /tomorrow and reply back here.  \r\n"
    }
  ]
}