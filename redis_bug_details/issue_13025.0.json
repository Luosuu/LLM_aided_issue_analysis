{
  "issue_number": 13025.0,
  "title": "[CRASH] When role change occurs, if the new master causes a write, it crashes",
  "body": "Although this is related to a module, we've created a super simple reproducible module to ensure the issue was in fact not specific to our module.\r\n\r\n**Crash report**\r\n\r\n```\r\n1:S 02 Feb 2024 22:11:28.598 * Successful partial resynchronization with master.\r\n1:S 02 Feb 2024 22:11:28.598 * Master replication ID changed to 2fe1b84f88ef01b46170de4eb12023a46a3c718c\r\n1:S 02 Feb 2024 22:11:28.598 * <example> [EventHandler] Event Handler EVENT 7 SUBEVENT 0\r\n1:S 02 Feb 2024 22:11:28.598 * <example> [EventHandler] Master Replication Link Up\r\n1:S 02 Feb 2024 22:11:28.598 * MASTER <-> REPLICA sync: Master accepted a Partial Resynchronization.\r\n1:S 02 Feb 2024 22:11:28.598 * <example> [EventHandler] Event Handler EVENT 7 SUBEVENT 1\r\n1:S 02 Feb 2024 22:11:28.598 * <example> [EventHandler] Master Replication Link Down\r\n1:M 02 Feb 2024 22:11:28.598 * Connection with master lost.\r\n1:M 02 Feb 2024 22:11:28.598 * Caching the disconnected master state.\r\n1:M 02 Feb 2024 22:11:28.599 * <example> [EventHandler] Event Handler EVENT 7 SUBEVENT 1\r\n1:M 02 Feb 2024 22:11:28.599 * <example> [EventHandler] Master Replication Link Down\r\n1:M 02 Feb 2024 22:11:28.599 * Discarding previously cached master state.\r\n1:M 02 Feb 2024 22:11:28.599 * Setting secondary replication ID to 2fe1b84f88ef01b46170de4eb12023a46a3c718c, valid up to offset: 49540. New replication ID is 802c95cd352f2914af3d36592c2e761ca5d323de\r\n1:M 02 Feb 2024 22:11:28.599 * <example> [EventHandler] Event Handler EVENT 0 SUBEVENT 0\r\n1:M 02 Feb 2024 22:11:28.599 * <example> [EventHandler] Became Master\r\n1:M 02 Feb 2024 22:11:28.599 * <example> [KAU] AAAAA master set\r\n\r\n\r\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\r\n1:M 02 Feb 2024 22:11:28.599 # Redis 7.2.4 crashed by signal: 11, si_code: 1\r\n1:M 02 Feb 2024 22:11:28.599 # Accessing address: 0xffffffffffffffff\r\n1:M 02 Feb 2024 22:11:28.599 # Crashed running the instruction at: 0x55bf9930d41b\r\n\r\n------ STACK TRACE ------\r\nEIP:\r\nredis-server *:6379(getClientMemoryUsage+0x4b)[0x55bf9930d41b]\r\n\r\nBacktrace:\r\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x13140)[0x7fa834e60140]\r\nredis-server *:6379(getClientMemoryUsage+0x4b)[0x55bf9930d41b]\r\nredis-server *:6379(catClientInfoString+0x16e)[0x55bf9931168e]\r\nredis-server *:6379(replicaofCommand+0x17c)[0x55bf9932b06c]\r\nredis-server *:6379(call+0x170)[0x55bf992ed740]\r\nredis-server *:6379(processCommand+0xb69)[0x55bf992ee9e9]\r\nredis-server *:6379(processInputBuffer+0xf7)[0x55bf99312b37]\r\nredis-server *:6379(readQueryFromClient+0x350)[0x55bf993130a0]\r\nredis-server *:6379(+0x1ae77c)[0x55bf9940477c]\r\nredis-server *:6379(+0x1b4562)[0x55bf9940a562]\r\nredis-server *:6379(aeMain+0xf9)[0x55bf992e3d09]\r\nredis-server *:6379(main+0x3cd)[0x55bf992d8ecd]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xea)[0x7fa834c9cd0a]\r\nredis-server *:6379(_start+0x2a)[0x55bf992d964a]\r\n\r\n------ REGISTERS ------\r\n1:M 02 Feb 2024 22:11:28.600 # \r\nRAX:0000000000000000 RBX:00007fa83492c880\r\nRCX:00000000000000ff RDX:0000000000000000\r\nRDI:0000000000000000 RSI:00007ffdf2a8de58\r\nRBP:00007fa83492c880 RSP:00007ffdf2a8dd70\r\nR8 :00007fa834858253 R9 :0000000000000000\r\nR10:0000000000e17908 R11:00007fa834c751c0\r\nR12:0000000000000000 R13:00007ffdf2a8de60\r\nR14:000055bf994103e0 R15:00007ffdf2a8df50\r\nRIP:000055bf9930d41b EFL:0000000000010202\r\nCSGSFS:002b000000000033\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd7f) -> 000000407794b4af\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd7e) -> 0000000000000000\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd7d) -> 0000000000000000\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd7c) -> 0000000000000000\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd7b) -> 0000000000000000\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd7a) -> 0000000000000000\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd79) -> 0000000000000000\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd78) -> 0000000000000040\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd77) -> 0000000000000000\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd76) -> 0000000000000000\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd75) -> 000055bf9931168e\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd74) -> 000055bf994103e0\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd73) -> 00007ffdf2a8de60\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd72) -> 00007fa834863828\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd71) -> 00007fa83492c880\r\n1:M 02 Feb 2024 22:11:28.600 # (00007ffdf2a8dd70) -> 00007fa83492c880\r\n\r\n------ INFO OUTPUT ------\r\n# Server\r\nredis_version:7.2.4\r\nredis_git_sha1:00000000\r\nredis_git_dirty:0\r\nredis_build_id:5480667114e70c31\r\nredis_mode:standalone\r\nos:Linux 4.18.0-477.15.1.el8_8.x86_64 x86_64\r\narch_bits:64\r\nmonotonic_clock:POSIX clock_gettime\r\nmultiplexing_api:epoll\r\natomicvar_api:c11-builtin\r\ngcc_version:10.2.1\r\nprocess_id:1\r\nprocess_supervised:no\r\nrun_id:f4ef00a857c392c56b11d06e766baa679420c353\r\ntcp_port:6379\r\nserver_time_usec:1706911888598894\r\nuptime_in_seconds:154\r\nuptime_in_days:0\r\nhz:10\r\nconfigured_hz:10\r\nlru_clock:12413072\r\nexecutable:/redis-server\r\nconfig_file:\r\nio_threads_active:0\r\nlistener2:name=tls,bind=*,bind=-::*,port=6379\r\n\r\n# Clients\r\nconnected_clients:1\r\ncluster_connections:0\r\nmaxclients:10000\r\nclient_recent_max_input_buffer:20480\r\nclient_recent_max_output_buffer:0\r\nblocked_clients:0\r\ntracking_clients:0\r\nclients_in_timeout_table:0\r\ntotal_blocking_keys:0\r\ntotal_blocking_keys_on_nokey:0\r\n\r\n# Memory\r\nused_memory:1337704\r\nused_memory_human:1.28M\r\nused_memory_rss:15814656\r\nused_memory_rss_human:15.08M\r\nused_memory_peak:1401080\r\nused_memory_peak_human:1.34M\r\nused_memory_peak_perc:95.48%\r\nused_memory_overhead:971108\r\nused_memory_startup:883824\r\nused_memory_dataset:366596\r\nused_memory_dataset_perc:80.77%\r\nallocator_allocated:1460864\r\nallocator_active:1789952\r\nallocator_resident:4861952\r\ntotal_system_memory:8070426624\r\ntotal_system_memory_human:7.52G\r\nused_memory_lua:31744\r\nused_memory_vm_eval:31744\r\nused_memory_lua_human:31.00K\r\nused_memory_scripts_eval:0\r\nnumber_of_cached_scripts:0\r\nnumber_of_functions:0\r\nnumber_of_libraries:0\r\nused_memory_vm_functions:32768\r\nused_memory_vm_total:64512\r\nused_memory_vm_total_human:63.00K\r\nused_memory_functions:184\r\nused_memory_scripts:184\r\nused_memory_scripts_human:184B\r\nmaxmemory:0\r\nmaxmemory_human:0B\r\nmaxmemory_policy:noeviction\r\nallocator_frag_ratio:1.23\r\nallocator_frag_bytes:329088\r\nallocator_rss_ratio:2.72\r\nallocator_rss_bytes:3072000\r\nrss_overhead_ratio:3.25\r\nrss_overhead_bytes:10952704\r\nmem_fragmentation_ratio:12.35\r\nmem_fragmentation_bytes:14533648\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:61516\r\nmem_total_replication_buffers:61512\r\nmem_clients_slaves:0\r\nmem_clients_normal:25472\r\nmem_cluster_links:0\r\nmem_aof_buffer:0\r\nmem_allocator:jemalloc-5.3.0\r\nactive_defrag_running:0\r\nlazyfree_pending_objects:0\r\nlazyfreed_objects:0\r\n\r\n# Persistence\r\nloading:0\r\nasync_loading:0\r\ncurrent_cow_peak:0\r\ncurrent_cow_size:0\r\ncurrent_cow_size_age:0\r\ncurrent_fork_perc:0.00\r\ncurrent_save_keys_processed:0\r\ncurrent_save_keys_total:0\r\nrdb_changes_since_last_save:2\r\nrdb_bgsave_in_progress:0\r\nrdb_last_save_time:1706911734\r\nrdb_last_bgsave_status:ok\r\nrdb_last_bgsave_time_sec:-1\r\nrdb_current_bgsave_time_sec:-1\r\nrdb_saves:0\r\nrdb_last_cow_size:0\r\nrdb_last_load_keys_expired:0\r\nrdb_last_load_keys_loaded:0\r\naof_enabled:0\r\naof_rewrite_in_progress:0\r\naof_rewrite_scheduled:0\r\naof_last_rewrite_time_sec:-1\r\naof_current_rewrite_time_sec:-1\r\naof_last_bgrewrite_status:ok\r\naof_rewrites:0\r\naof_rewrites_consecutive_failures:0\r\naof_last_write_status:ok\r\naof_last_cow_size:0\r\nmodule_fork_in_progress:0\r\nmodule_fork_last_cow_size:0\r\n\r\n# Stats\r\ntotal_connections_received:70\r\ntotal_commands_processed:1020\r\ninstantaneous_ops_per_sec:7\r\ntotal_net_input_bytes:108741\r\ntotal_net_output_bytes:585012\r\ntotal_net_repl_input_bytes:49057\r\ntotal_net_repl_output_bytes:0\r\ninstantaneous_input_kbps:0.40\r\ninstantaneous_output_kbps:11.02\r\ninstantaneous_input_repl_kbps:0.00\r\ninstantaneous_output_repl_kbps:0.00\r\nrejected_connections:0\r\nsync_full:0\r\nsync_partial_ok:0\r\nsync_partial_err:0\r\nexpired_keys:0\r\nexpired_stale_perc:0.00\r\nexpired_time_cap_reached_count:0\r\nexpire_cycle_cpu_milliseconds:0\r\nevicted_keys:0\r\nevicted_clients:0\r\ntotal_eviction_exceeded_time:0\r\ncurrent_eviction_exceeded_time:0\r\nkeyspace_hits:0\r\nkeyspace_misses:0\r\npubsub_channels:0\r\npubsub_patterns:0\r\npubsubshard_channels:0\r\nlatest_fork_usec:0\r\ntotal_forks:0\r\nmigrate_cached_sockets:0\r\nslave_expires_tracked_keys:0\r\nactive_defrag_hits:0\r\nactive_defrag_misses:0\r\nactive_defrag_key_hits:0\r\nactive_defrag_key_misses:0\r\ntotal_active_defrag_time:0\r\ncurrent_active_defrag_time:0\r\ntracking_total_keys:0\r\ntracking_total_items:0\r\ntracking_total_prefixes:0\r\nunexpected_error_replies:0\r\ntotal_error_replies:1\r\ndump_payload_sanitizations:0\r\ntotal_reads_processed:1047\r\ntotal_writes_processed:2016\r\nio_threaded_reads_processed:0\r\nio_threaded_writes_processed:0\r\nreply_buffer_shrinks:48\r\nreply_buffer_expands:48\r\neventloop_cycles:2767\r\neventloop_duration_sum:420291\r\neventloop_duration_cmd_sum:7374\r\ninstantaneous_eventloop_cycles_per_sec:20\r\ninstantaneous_eventloop_duration_usec:170\r\nacl_access_denied_auth:0\r\nacl_access_denied_cmd:0\r\nacl_access_denied_key:0\r\nacl_access_denied_channel:0\r\n\r\n# Replication\r\nrole:master\r\nconnected_slaves:0\r\nmaster_failover_state:no-failover\r\nmaster_replid:802c95cd352f2914af3d36592c2e761ca5d323de\r\nmaster_replid2:2fe1b84f88ef01b46170de4eb12023a46a3c718c\r\nmaster_repl_offset:49539\r\nsecond_repl_offset:49540\r\nrepl_backlog_active:1\r\nrepl_backlog_size:1048576\r\nrepl_backlog_first_byte_offset:1268\r\nrepl_backlog_histlen:48272\r\n\r\n# CPU\r\nused_cpu_sys:0.263239\r\nused_cpu_user:0.100963\r\nused_cpu_sys_children:0.024350\r\nused_cpu_user_children:0.012801\r\nused_cpu_sys_main_thread:0.261811\r\nused_cpu_user_main_thread:0.100837\r\n\r\n# Modules\r\nmodule:name=example,ver=1,api=1,filters=0,usedby=[],using=[],options=[]\r\n\r\n# Commandstats\r\ncmdstat_publish:calls=398,usec=2190,usec_per_call=5.50,rejected_calls=0,failed_calls=0\r\ncmdstat_select:calls=3,usec=3,usec_per_call=1.00,rejected_calls=0,failed_calls=0\r\ncmdstat_exec:calls=1,usec=1152,usec_per_call=1152.00,rejected_calls=0,failed_calls=0\r\ncmdstat_set:calls=2,usec=9,usec_per_call=4.50,rejected_calls=0,failed_calls=0\r\ncmdstat_config|rewrite:calls=1,usec=3,usec_per_call=3.00,rejected_calls=0,failed_calls=1\r\ncmdstat_subscribe:calls=3,usec=9,usec_per_call=3.00,rejected_calls=0,failed_calls=0\r\ncmdstat_client|setname:calls=6,usec=7,usec_per_call=1.17,rejected_calls=0,failed_calls=0\r\ncmdstat_client|kill:calls=2,usec=294,usec_per_call=147.00,rejected_calls=0,failed_calls=0\r\ncmdstat_slaveof:calls=1,usec=831,usec_per_call=831.00,rejected_calls=0,failed_calls=0\r\ncmdstat_multi:calls=1,usec=10,usec_per_call=10.00,rejected_calls=0,failed_calls=0\r\ncmdstat_ping:calls=470,usec=563,usec_per_call=1.20,rejected_calls=0,failed_calls=0\r\ncmdstat_auth:calls=70,usec=308,usec_per_call=4.40,rejected_calls=0,failed_calls=0\r\ncmdstat_info:calls=61,usec=3128,usec_per_call=51.28,rejected_calls=0,failed_calls=0\r\ncmdstat_replconf:calls=1,usec=4,usec_per_call=4.00,rejected_calls=0,failed_calls=0\r\n\r\n# Errorstats\r\nerrorstat_ERR:count=1\r\n\r\n# Latencystats\r\nlatency_percentiles_usec_publish:p50=5.023,p99=23.039,p99.9=89.087\r\nlatency_percentiles_usec_select:p50=1.003,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_exec:p50=1155.071,p99=1155.071,p99.9=1155.071\r\nlatency_percentiles_usec_set:p50=4.015,p99=5.023,p99.9=5.023\r\nlatency_percentiles_usec_config|rewrite:p50=3.007,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_subscribe:p50=3.007,p99=4.015,p99.9=4.015\r\nlatency_percentiles_usec_client|setname:p50=1.003,p99=2.007,p99.9=2.007\r\nlatency_percentiles_usec_client|kill:p50=106.495,p99=188.415,p99.9=188.415\r\nlatency_percentiles_usec_slaveof:p50=831.487,p99=831.487,p99.9=831.487\r\nlatency_percentiles_usec_multi:p50=10.047,p99=10.047,p99.9=10.047\r\nlatency_percentiles_usec_ping:p50=1.003,p99=2.007,p99.9=25.087\r\nlatency_percentiles_usec_auth:p50=4.015,p99=11.007,p99.9=22.015\r\nlatency_percentiles_usec_info:p50=51.199,p99=104.447,p99.9=117.247\r\nlatency_percentiles_usec_replconf:p50=4.015,p99=4.015,p99.9=4.015\r\n\r\n# Cluster\r\ncluster_enabled:0\r\n\r\n# Keyspace\r\ndb0:keys=2,expires=0,avg_ttl=0\r\n\r\n------ CLIENT LIST OUTPUT ------\r\nid=20 addr=10.42.2.161:38250 laddr=10.42.0.127:6379 fd=14 name=sentinel-065e2884-cmd age=111 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=4096 rbp=2048 obl=0 oll=0 omem=0 tot-mem=25472 events=r cmd=publish user=default redir=-1 resp=2 lib-name= lib-ver=\r\n\r\n------ EXECUTING CLIENT INFO ------\r\n\r\n```\r\n\r\n\r\n1. Debian (docker.io/bitnami/redis:7.2.4-debian-11-r2)\r\n2. Deploy a 3 node redis (with 3 sentinel sidecars)\r\n3. Once all are loaded kill the master\r\n\r\nThe module was taken from [here](https://github.com/RedisLabsModules/RedisModulesSDK/tree/master/example). \r\nCompiled with \r\n```\r\ngcc -I/usr/include -Wall -g -fPIC -lc -lm -std=gnu99     -c -o module.o module.c\r\nld -o module.so module.o -shared -Bsymbolic  -lc \r\n```\r\n\r\nThe `module.c` has been very much simplified by essentially doing nothing. We tested the failover with just log messages and it worked perfectly. Once we added the SET calls it crashes every time.\r\n\r\n```\r\n#include <redismodule.h>\r\n#include <inttypes.h>\r\n\r\nint ParseCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc) {\r\n  return REDISMODULE_OK;\r\n}\r\n\r\nvoid EventHandler(RedisModuleCtx *ctx, RedisModuleEvent eid, uint64_t subevent, void *data)\r\n{\r\n    RedisModule_Log(ctx, REDISMODULE_LOGLEVEL_NOTICE, \"[EventHandler] Event Handler EVENT %\"PRIu64\" SUBEVENT %\"PRIu64, eid.id, subevent);\r\n    switch (eid.id)\r\n    {\r\n        case REDISMODULE_EVENT_MASTER_LINK_CHANGE:\r\n            if (subevent == REDISMODULE_SUBEVENT_MASTER_LINK_DOWN){\r\n                RedisModule_Log(ctx, REDISMODULE_LOGLEVEL_NOTICE, \"[EventHandler] Master Replication Link Down\");\r\n            }\r\n            if (subevent == REDISMODULE_SUBEVENT_MASTER_LINK_UP){\r\n                RedisModule_Log(ctx, REDISMODULE_LOGLEVEL_NOTICE, \"[EventHandler] Master Replication Link Up\");\r\n            }\r\n            break;\r\n        case REDISMODULE_EVENT_REPLICATION_ROLE_CHANGED:\r\n            switch (subevent)\r\n            {\r\n                case REDISMODULE_EVENT_REPLROLECHANGED_NOW_MASTER:\r\n                {\r\n                    RedisModule_Log(ctx, REDISMODULE_LOGLEVEL_NOTICE, \"[EventHandler] Became Master\");\r\n                    RedisModule_Log(ctx, REDISMODULE_LOGLEVEL_NOTICE, \"[KAU] AAAAA master set\");\r\n\t            RedisModule_Call(ctx, \"SET\", \"cc\", \"kau-master\", \"1\");\r\n                    break;\r\n                }\r\n                case REDISMODULE_EVENT_REPLROLECHANGED_NOW_REPLICA:\r\n                    RedisModule_Log(ctx, REDISMODULE_LOGLEVEL_NOTICE, \"[EventHandler] Became Replica\");\r\n                    RedisModule_Log(ctx, REDISMODULE_LOGLEVEL_NOTICE, \"[KAU] AAAAA replica set\");\r\n\t            RedisModule_Call(ctx, \"SET\", \"cc\", \"kau-replica\", \"1\");\r\n                    break;\r\n                default:\r\n                    break;\r\n            }\r\n            break;\r\n        default:\r\n            break;\r\n    }\r\n}\r\n\r\nint RedisModule_OnLoad(RedisModuleCtx *ctx) {\r\n\r\n  // Register the module itself\r\n  if (RedisModule_Init(ctx, \"example\", 1, REDISMODULE_APIVER_1) == REDISMODULE_ERR) {\r\n    return REDISMODULE_ERR;\r\n  }\r\n\r\n  // register example.parse - the default registration syntax\r\n  if (RedisModule_CreateCommand(ctx, \"example.parse\", ParseCommand, \"readonly\", 1, 1, 1) == REDISMODULE_ERR) {\r\n    return REDISMODULE_ERR;\r\n  }\r\n\r\n  RedisModule_SubscribeToServerEvent(ctx, RedisModuleEvent_ReplicationRoleChanged, EventHandler);\r\n  /* Example on how to check if a server sub event is supported */\r\n  if (RedisModule_IsSubEventSupported(RedisModuleEvent_MasterLinkChange, REDISMODULE_SUBEVENT_MASTER_LINK_UP)) {\r\n      RedisModule_SubscribeToServerEvent(ctx, RedisModuleEvent_MasterLinkChange, EventHandler);\r\n  }\r\n\r\n  return REDISMODULE_OK;\r\n}\r\n```",
  "state": "closed",
  "created_at": "2024-02-02T22:32:19Z",
  "updated_at": "2024-02-05T23:31:41Z",
  "closed_at": "2024-02-05T17:46:15Z",
  "labels": [],
  "comments_data": [
    {
      "id": 1925623113,
      "user": "enjoy-binbin",
      "created_at": "2024-02-04T08:09:10Z",
      "body": "Can you provide more specific steps? I tried it but couldn't reproduce it. I'm worried that my steps are wrong:\r\n```\r\n69592:S 04 Feb 2024 16:06:07.092 * Master replied to PING, replication can continue...\r\n69592:S 04 Feb 2024 16:06:07.092 * Trying a partial resynchronization (request 0a3f50861333bbbbe59f4c90679f00a2b45fb939:1).\r\n69592:S 04 Feb 2024 16:06:07.093 * Full resync from master: 94e431343b5df4d1c60ac31bd223dfd4cac5eb15:0\r\n69592:S 04 Feb 2024 16:06:07.094 * MASTER <-> REPLICA sync: receiving streamed RDB from master with EOF to disk\r\n69592:S 04 Feb 2024 16:06:07.094 * Discarding previously cached master state.\r\n69592:S 04 Feb 2024 16:06:07.094 * MASTER <-> REPLICA sync: Flushing old data\r\n69592:S 04 Feb 2024 16:06:07.094 * MASTER <-> REPLICA sync: Loading DB in memory\r\n69592:S 04 Feb 2024 16:06:07.116 * Loading RDB produced by version 7.2.4\r\n69592:S 04 Feb 2024 16:06:07.116 * RDB age 0 seconds\r\n69592:S 04 Feb 2024 16:06:07.116 * RDB memory usage when created 1.21 Mb\r\n69592:S 04 Feb 2024 16:06:07.116 * Done loading RDB, keys loaded: 0, keys expired: 0.\r\n69592:S 04 Feb 2024 16:06:07.117 * <example> [EventHandler] Event Handler EVENT 7 SUBEVENT 0\r\n69592:S 04 Feb 2024 16:06:07.117 * <example> [EventHandler] Master Replication Link Up\r\n69592:S 04 Feb 2024 16:06:07.117 * MASTER <-> REPLICA sync: Finished with success\r\n69592:S 04 Feb 2024 16:06:09.103 - Client closed connection id=8 addr=127.0.0.1:21114 laddr=127.0.0.1:52974 fd=13 name= age=2 idle=2 flags=M db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=45050 argv-mem=0 multi-mem=0 rbs=1024 rbp=34 obl=0 oll=0 omem=0 tot-mem=46864 events=r cmd=NULL user=(superuser) redir=-1 resp=2 lib-name= lib-ver=\r\n69592:S 04 Feb 2024 16:06:09.103 * Connection with master lost.\r\n69592:S 04 Feb 2024 16:06:09.103 * Caching the disconnected master state.\r\n69592:S 04 Feb 2024 16:06:09.103 * <example> [EventHandler] Event Handler EVENT 7 SUBEVENT 1\r\n69592:S 04 Feb 2024 16:06:09.103 * <example> [EventHandler] Master Replication Link Down\r\n69592:S 04 Feb 2024 16:06:09.103 * Reconnecting to MASTER 127.0.0.1:21114\r\n69592:S 04 Feb 2024 16:06:09.103 * MASTER <-> REPLICA sync started\r\n69592:S 04 Feb 2024 16:06:09.103 # Error condition on socket for SYNC: Connection refused\r\n69592:S 04 Feb 2024 16:06:09.533 * Connecting to MASTER 127.0.0.1:21114\r\n69592:S 04 Feb 2024 16:06:09.533 * MASTER <-> REPLICA sync started\r\n69592:S 04 Feb 2024 16:06:09.533 # Error condition on socket for SYNC: Connection refused\r\n69592:M 04 Feb 2024 16:06:10.106 * Discarding previously cached master state.\r\n69592:M 04 Feb 2024 16:06:10.106 * Setting secondary replication ID to 94e431343b5df4d1c60ac31bd223dfd4cac5eb15, valid up to offset: 1. New replication ID is ce61250a200d94bf02b34822981b1564329d889d\r\n69592:M 04 Feb 2024 16:06:10.106 * <example> [EventHandler] Event Handler EVENT 0 SUBEVENT 0\r\n69592:M 04 Feb 2024 16:06:10.106 * <example> [EventHandler] Became Master\r\n69592:M 04 Feb 2024 16:06:10.106 * <example> [KAU] AAAAA master set\r\n69592:M 04 Feb 2024 16:06:10.107 * MASTER MODE enabled (user request from 'id=4 addr=127.0.0.1:52965 laddr=127.0.0.1:21111 fd=12 name= age=4 idle=0 flags=N db=9 sub=0 psub=0 ssub=0 multi=-1 qbuf=34 qbuf-free=16856 argv-mem=12 multi-mem=0 rbs=1024 rbp=5 obl=0 oll=0 omem=0 tot-mem=18740 events=r cmd=slaveof user=default redir=-1 resp=2 lib-name= lib-ver=')\r\n69592:M 04 Feb 2024 16:06:11.543 - DB 0: 1 keys (0 volatile) in 4 slots HT.\r\n69592:M 04 Feb 2024 16:06:12.235 - Client closed connection id=4 addr=127.0.0.1:52965 laddr=127.0.0.1:21111 fd=12 name= age=6 idle=2 flags=N db=9 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=16890 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=18704 events=r cmd=slaveof user=default redir=-1 resp=2 lib-name= lib-ver=\r\n69592:signal-handler (1707033972) Received SIGTERM scheduling shutdown...\r\n69592:M 04 Feb 2024 16:06:12.249 * User requested shutdown...\r\n\r\n```\r\n"
    },
    {
      "id": 1927238086,
      "user": "wgnathanael",
      "created_at": "2024-02-05T15:18:36Z",
      "body": "Hmm... I'm not sure. We're using the bitnami provided containers... Perhaps the issue lies there. \r\n\r\nHow were you testing your setup so we can give that a try as well? \r\n\r\nIn our setup we had 3 nodes running in k8s. Each redis instance had a sentinel sidecar. The setup for this was via a helm chart. I'll see if I can manually setup some redis containers to see if it still happens in a different environment. I'll also look at posting a step by step build+deploy scenario that can reproduce maybe just via podman/docker so its easier to test."
    },
    {
      "id": 1927582624,
      "user": "wgnathanael",
      "created_at": "2024-02-05T17:46:15Z",
      "body": "Ok so upon further testing, this seems to only crash when using the bitnami container. I'll close this ticket and see if we can narrow down the issue. Thanks for checking and spending time on this."
    },
    {
      "id": 1928495246,
      "user": "wgnathanael",
      "created_at": "2024-02-05T23:31:41Z",
      "body": "So although this doesn't happen in the regular redis container if you have any insights into what could be going wrong I would appreciate it. I've ran redis under gdb in their container and it comes down to the function call\r\n```\r\nsize_t getClientMemoryUsage(client *c, size_t *output_buffer_mem_usage) {\r\n    size_t mem = getClientOutputBufferMemoryUsage(c);\r\n    if (output_buffer_mem_usage != NULL)\r\n        *output_buffer_mem_usage = mem;\r\n    mem += sdsZmallocSize(c->querybuf); <--- crash point\r\n    mem += zmalloc_size(c);\r\n    ...\r\n```\r\nAny thoughts on what would have to happen for that to crash? Its not saying sdsZmallocSize was called so c->querybuff is null or c is null?? I doesn't seem like c is null based on the bt:\r\n```\r\n#0  0x00005583d656a41b in getClientMemoryUsage (c=0x7fc797f0ec00, output_buffer_mem_usage=0x7ffcb46d1eb8) at networking.c:3787\r\n```\r\n\r\nAnyway, I imaging you're all busy but any pointers (no pun intended) would be helpful"
    }
  ]
}