{
  "issue_number": 10077.0,
  "title": "[BUG] During Bgsave, failed to disconnect idle client connection properly",
  "body": "**Describe the bug**\r\n\r\nDuring Bgsave, the client’s command blocked for 4771ms and threw an IOException. By capturing packets, the server did not properly disconnect idle client connection. Normally, the server would have sent the FIN packet, but it didn't.\r\n\r\n\r\n\r\n**To reproduce**\r\n\r\nService side:\r\n\r\n> Deployment: A 6 nodes cluster.\r\n>\r\n> Key configurations: \r\n>\r\n> ```\r\n> timeout 10\r\n> save '60 1'\r\n> loglevel verbose\r\n> ```\r\n>\r\n> used_memory_human: 2.06G\r\n\r\nClient side\r\n\r\n> Pool size: The minimum size is 8\r\n>\r\n> Command frequency: One command every 3 seconds.\r\n\r\n\r\n\r\n**Expected behavior**\r\n\r\nDuring Bgsave, the server can properly disconnect idle client  connections.\r\n\r\n\r\n\r\n**Additional information**\r\n\r\nThe client sends the set command at 01:17:39.940 and throws an exception at 01:17:44.711. It blocked for 4771ms.\r\n\r\n```\r\n2022-01-08 01:17:44.711  WARN 5468 --- [ntloop-thread-7] c.c.m.c.m.c.RedisTestController : The time spent on the set command：4771ms\r\n2022-01-08 01:17:44.711 ERROR 5468 --- [ntloop-thread-7] c.c.m.c.m.c.RedisTestController : error:\r\n\r\njava.io.IOException: An existing connection was forcibly closed by the remote host\r\n\tat sun.nio.ch.SocketDispatcher.read0(Native Method)\r\n\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)\r\n\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\r\n\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\r\n\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)\r\n\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\r\n\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1133)\r\n\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n```\r\n\r\n\r\n**packets  of client side:**\r\n\r\nserver: 192.168.100.13:6371\r\n\r\nclient: 192.168.100.3:53901\r\n\r\nNote: The time difference between the client and the server is less than 1s.\r\n\r\n![image](https://user-images.githubusercontent.com/20969338/148629962-37705c19-8e1a-4b98-a1fb-b8221454f58b.png)\r\n\r\n\r\n**The log of server:**\r\n\r\n```\r\nlatest_fork_usec:41966\r\nrdb_last_bgsave_time_sec:16\r\n```\r\n![image](https://user-images.githubusercontent.com/20969338/148629977-92e8cbe0-0975-4c3c-b859-1e167c79015c.png)\r\n\r\nI have captured the packets and analyzed the connection that timed out and threw an IOException.\r\n\r\n| Client action                               | Time line    | server action                                 |\r\n| ------------------------------------------- | ------------ | --------------------------------------------- |\r\n| last packet                                 | 01:17:27.931 |                                               |\r\n|                                             | 01:17:28.698 | log: Background saving started                |\r\n| Expected but did not receive the fin packet | 01:17:38.080 | log: Closing idle client                      |\r\n| command send                                | 01:17:39.940 |                                               |\r\n|                                             | 01:17:44.100 | log:Background saving terminated with success |\r\n| connection threw an IOException             | 01:17:44.711 |                                               |\r\n\r\nTwo phenomena indicate that there is something wrong with the server:\r\n\r\n1. 10 seconds after the last packet, the server had a log that closed the idle connection, but the client does not receive it.\r\n2. An exception is not thrown until the end of the bgsave.\r\n\r\n\r\n\r\nI will try to analyze the server code and solve it. Thanks.\r\n",
  "state": "closed",
  "created_at": "2022-01-08T03:35:23Z",
  "updated_at": "2022-11-04T16:46:39Z",
  "closed_at": "2022-11-04T16:46:39Z",
  "labels": [],
  "comments_data": [
    {
      "id": 1008243279,
      "user": "oranagra",
      "created_at": "2022-01-09T07:11:33Z",
      "body": "i'm guessing that since the `fork()` child is holding the file descriptors, the `close` in `unlinkClient` -> `connClose` isn't sufficient, and maybe we better use `shutdown()` instead of `close()`.\r\n@yossigo please take a look."
    },
    {
      "id": 1008253602,
      "user": "yossigo",
      "created_at": "2022-01-09T08:33:07Z",
      "body": "@oranagra yes, this is the root cause and using `shutdown()` is the solution. But we'll need to consider the impact of getting a `EBADF` in such cases, and possibly make sure childs never end up performing a `shutdown()` on their side."
    },
    {
      "id": 1008254386,
      "user": "oranagra",
      "created_at": "2022-01-09T08:39:51Z",
      "body": "@yossigo FYI, in the distant past i added a `shutdown` when disconnecting a replica, in order to cause the diskless bgsave child to fail.\r\nat that time, Salvatore didn't want to use it on every replica, and added a `c->replstate == SLAVE_STATE_WAIT_BGSAVE_END` condition. i don't recall what where the arguments. possibly only paranoia."
    },
    {
      "id": 1156876260,
      "user": "awesomecit",
      "created_at": "2022-06-15T20:00:33Z",
      "body": "Could be happen also during a generic fork (not only BGSAVE)?\r\nI'v the same issue on client that was connected to the redis server without any fork running, when the server start the fork of the process (maybe for load reason), the connected client stop to works until fork stops or will be killed, than have an Exception. \r\n\r\nDo you think that is possible to customize a proper module adding a command to start and stop a RedisModuleFork properly?"
    },
    {
      "id": 1157249550,
      "user": "oranagra",
      "created_at": "2022-06-16T05:30:35Z",
      "body": "> when the server start the fork of the process (maybe for load reason), the connected client stop to works until fork stops or will be killed\r\n\r\n@awesomecit what do you mean by \"stop to work\"? not being able to issue commands and read responses?\r\nthat makes no sense to me, and i'm quite sure we would have noticed already if such a problem existed.\r\n\r\nthe problem that we discussed was about the fact that closing the socket on the parent process, won't terminate the connection as long as the fork still has a hold of the file descriptor."
    },
    {
      "id": 1262032171,
      "user": "oranagra",
      "created_at": "2022-09-29T09:42:17Z",
      "body": "@yossigo maybe now is the time to try and change this? (use `shutdown`), when we're far enough from the next release?\r\nmaybe we can try being conservative, and only use shutdown if a fork is active?\r\nanyone else has any concerns or suggestions?"
    }
  ]
}