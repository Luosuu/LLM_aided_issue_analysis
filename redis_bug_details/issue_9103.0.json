{
  "issue_number": 9103.0,
  "title": "[BUG] Failover not happening after enabling announce-hostnames & resolve-hostnames in sentinel",
  "body": "**Failover not happening once master gets restarted**\r\n\r\nAfter enabling announce-hostnames & resolve-hostnames at first replica formation is happening without any issues.\r\nBut after master failover sentinels are not starting failover and I don't see ```+odown``` in sentinel logs which I see when running without hostnames.\r\n\r\n**To reproduce**\r\nRedis 6.2.4 on 3 pods along with sentinels on each with the below configurations.\r\n\r\n**master.conf**\r\n```\r\nreplica-announce-ip  <DNS>\r\n```\r\n\r\n**slave.conf**\r\n```\r\nreplica-announce-ip  <SLAVE DNS>\r\nreplicaof <MASTER-DNS> <MASTER-PORT>\r\n ```\r\n**sentinel.conf**\r\n```\r\n SENTINEL resolve-hostnames yes\r\n SENTINEL announce-hostnames yes\r\n sentinel parallel-syncs mymaster 1\r\n replica-announce-ip  <Sentinel DNS>\r\n```\r\nDelete master pod and force it to not start again, see failover behavior and delete new master, and observe the same.\r\n\r\n**Expected behavior**\r\nReplica should become master when master went down.\r\n\r\n**Additional information**\r\nBelow are the entries in logs when hostnames enabled where i only see ```+sdown```.\r\n\r\n```\r\n18:15:42.038 # +sdown master mymaster redis-0.redis.dev-wb.svc.cluster.local 6379\r\n18:15:42.038 # +sdown sentinel eef584c8262dd5eaa3d8850e6932bfde80839a24 172.1.0.171 26379 @ mymaster redis-0.redis.dev-wb.svc.cluster.local 6379\r\n\r\n```\r\n\r\nBelow is the log when hostnames were set to false, where I can see ```+odown```.\r\n\r\n```\r\n+sdown sentinel 9f8616a7f32bac48b49be67c2fce7039c0d16916 172.31.16.74 26379 @ RedisMaster 172.31.16.74 6379\r\n+sdown master RedisMaster 172.31.16.74 6379\r\n+odown master RedisMaster 172.31.16.74 6379 #quorum 2/2\r\n+new-epoch 3\r\n```\r\n",
  "state": "closed",
  "created_at": "2021-06-17T18:16:58Z",
  "updated_at": "2022-06-23T07:06:02Z",
  "closed_at": "2022-01-29T19:00:29Z",
  "labels": [
    "state:to-be-closed"
  ],
  "comments_data": [
    {
      "id": 879366109,
      "user": "hwware",
      "created_at": "2021-07-13T20:06:08Z",
      "body": "@sivanagireddyb \r\nHi I try to reproduce your problems in the 6.2.4 version, but even I set sentinel resolve-hostnames is yes and  sentinel announce-hostnames is yes, I could get the \"odown\" information in the logs and Replica should become master.   Following is my test profile, test steps and output logs,  Let me know you have any questions, thanks\r\n\r\n**_Part 1.  Test Profile -- I have 1 master redis instance, 2 repli instances and 3 sentinels_**\r\n\r\n**_master.conf:_**\r\n\r\nreplica-announce-ip testHost\r\nport 6380\r\nprotected-mode no\r\n\r\n**_replica1.conf_**\r\n\r\nreplica-announce-ip testHost\r\nport 6381\r\nprotected-mode no\r\nreplicaof testHost 6380\r\n\r\n**_replica2.conf_**\r\n\r\nreplica-announce-ip testHost\r\nport 6382\r\nprotected-mode no\r\nreplicaof testHost 6380\r\n\r\n**_sentinel1.conf:_**\r\n\r\nsentinel monitor mymaster testHost 6380 2\r\nsentinel down-after-milliseconds mymaster 6000\r\nsentinel failover-timeout mymaster 18000\r\nreplica-announce-ip testHost\r\nport 26380\r\nsentinel resolve-hostnames yes\r\nsentinel announce-hostnames yes\r\n\r\n**_sentinel2.conf:_**\r\n\r\nsentinel monitor mymaster testHost 6380 2\r\nsentinel down-after-milliseconds mymaster 6000\r\nsentinel failover-timeout mymaster 18000\r\nreplica-announce-ip testHost\r\nport 26381\r\nsentinel resolve-hostnames yes\r\nsentinel announce-hostnames yes\r\n\r\n**_sentinel3.conf:_**\r\n\r\nsentinel monitor mymaster testHost 6380 2\r\nsentinel down-after-milliseconds mymaster 6000\r\nsentinel failover-timeout mymaster 18000\r\nreplica-announce-ip testHost\r\nport 26382\r\nsentinel resolve-hostnames yes\r\nsentinel announce-hostnames yes\r\n\r\n**_Part 2.  Test Step_**\r\n\r\n**_after all master, replicas, and sentinels startup, first shutdown sentinel1, and wait for a few seconds,\r\n  shutdown master, and never startup again_**\r\n\r\n**_Part 3 Output logs:_**\r\n\r\n**_Sentinel 2 log:_**\r\n\r\n**_3271:X 14 Jul 2021 12:02:33.033 # +sdown master mymaster testHost 6380_**\r\n**_3271:X 14 Jul 2021 12:02:33.107 # +odown master mymaster testHost 6380 #quorum 2/2_**\r\n3271:X 14 Jul 2021 12:02:33.107 # +new-epoch 1\r\n3271:X 14 Jul 2021 12:02:33.107 # +try-failover master mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:33.116 # +vote-for-leader d82a59bbe49eb5b98607f9c3c56eaab8d137d1c8 1\r\n3271:X 14 Jul 2021 12:02:33.131 # ee04e963aa001bf423055f20af65ad3630d8c3e7 voted for d82a59bbe49eb5b98607f9c3c56eaab8d137d1c8 1\r\n3271:X 14 Jul 2021 12:02:33.188 # +elected-leader master mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:33.188 # +failover-state-select-slave master mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:33.264 # +selected-slave slave testHost:6381 testHost 6381 @ mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:33.264 * +failover-state-send-slaveof-noone slave testHost:6381 testHost 6381 @ mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:33.332 * +failover-state-wait-promotion slave testHost:6381 testHost 6381 @ mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:34.188 # +promoted-slave slave testHost:6381 testHost 6381 @ mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:34.189 # +failover-state-reconf-slaves master mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:34.243 * +slave-reconf-sent slave testHost:6382 testHost 6382 @ mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:35.196 * +slave-reconf-inprog slave testHost:6382 testHost 6382 @ mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:35.196 * +slave-reconf-done slave testHost:6382 testHost 6382 @ mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:35.283 # -odown master mymaster testHost 6380\r\n3271:X 14 Jul 2021 12:02:35.283 # +failover-end master mymaster testHost 6380\r\n**_3271:X 14 Jul 2021 12:02:35.283 # +switch-master mymaster testHost 6380 testHost 6381_**\r\n3271:X 14 Jul 2021 12:02:35.283 * +slave slave testHost:6382 testHost 6382 @ mymaster testHost 6381\r\n3271:X 14 Jul 2021 12:02:35.283 * +slave slave testHost:6380 testHost 6380 @ mymaster testHost 6381\r\n3271:X 14 Jul 2021 12:02:41.315 # +sdown slave testHost:6380 testHost 6380 @ mymaster testHost 6381\r\n\r\n**_Sentinel 3 log:_**\r\n\r\n**_3276:X 14 Jul 2021 12:02:32.938 # +sdown master mymaster testHost 6380_**\r\n3276:X 14 Jul 2021 12:02:33.124 # +new-epoch 1\r\n3276:X 14 Jul 2021 12:02:33.131 # +vote-for-leader d82a59bbe49eb5b98607f9c3c56eaab8d137d1c8 1\r\n**_3276:X 14 Jul 2021 12:02:34.075 # +odown master mymaster testHost 6380 #quorum 2/2_**\r\n3276:X 14 Jul 2021 12:02:34.075 # Next failover delay: I will not start a failover before Wed Jul 14 12:03:09 2021\r\n3276:X 14 Jul 2021 12:02:34.243 # +config-update-from sentinel d82a59bbe49eb5b98607f9c3c56eaab8d137d1c8 127.0.0.1 26381 @ mymaster testHost 6380\r\n**_3276:X 14 Jul 2021 12:02:34.243 # +switch-master mymaster testHost 6380 testHost 6381_**\r\n3276:X 14 Jul 2021 12:02:34.243 * +slave slave testHost:6382 testHost 6382 @ mymaster testHost 6381\r\n3276:X 14 Jul 2021 12:02:34.243 * +slave slave testHost:6380 testHost 6380 @ mymaster testHost 6381\r\n3276:X 14 Jul 2021 12:02:40.272 # +sdown slave testHost:6380 testHost 6380 @ mymaster testHost 6381\r\n\r\nFrom the log, we can see The replica testHost:6381 is promoted to master.\r\n"
    },
    {
      "id": 879493883,
      "user": "SivaBu-kore",
      "created_at": "2021-07-14T00:36:47Z",
      "body": "@hwware use DNS/hostnames names instead of ips"
    },
    {
      "id": 880022916,
      "user": "hwware",
      "created_at": "2021-07-14T16:09:40Z",
      "body": "> @hwware use DNS/hostnames names instead of ips\r\n\r\nHi @SivaBu-kore  I update the config file, replace the ips with hostname, after shutdown one of the sentinels and master, replica still could be promoted to master.  Please verify my reproduced steps and let me know any concerns. \r\n\r\nThanks"
    },
    {
      "id": 880433396,
      "user": "SivaBu-kore",
      "created_at": "2021-07-15T06:29:44Z",
      "body": "@hmware I have tested with 1 Master & 1 Replica. You are testing with 1 Master & 2 Replicas. I'm not sure it will be an issue. "
    },
    {
      "id": 880719290,
      "user": "hwware",
      "created_at": "2021-07-15T14:00:55Z",
      "body": "@SivaBu-kore Following is my test result with 1 Master & 1 Replica,  it looks Replica still could be promoted to Master. \r\n@sivanagireddyb Please check the following log with 1 Master & 1 Replica\r\n\r\nPlease let me know if some test steps are not consistent with you, thanks\r\n\r\n**_Part 1. Test Profile -- I have 1 master redis instance, 1 repli instances and 3 sentinels_**\r\n\r\n**_master.conf:_**\r\n\r\nreplica-announce-ip testHost\r\nport 6380\r\nprotected-mode no\r\n\r\n**_replica1.conf_**\r\n\r\nreplica-announce-ip testHost\r\nport 6381\r\nprotected-mode no\r\nreplicaof testHost 6380\r\n\r\n**_sentinel1.conf:_**\r\n\r\nsentinel monitor mymaster testHost 6380 2\r\nsentinel down-after-milliseconds mymaster 6000\r\nsentinel failover-timeout mymaster 18000\r\nreplica-announce-ip testHost\r\nport 26380\r\nsentinel resolve-hostnames yes\r\nsentinel announce-hostnames yes\r\n\r\n**_sentinel2.conf:_**\r\n\r\nsentinel monitor mymaster testHost 6380 2\r\nsentinel down-after-milliseconds mymaster 6000\r\nsentinel failover-timeout mymaster 18000\r\nreplica-announce-ip testHost\r\nport 26381\r\nsentinel resolve-hostnames yes\r\nsentinel announce-hostnames yes\r\n\r\n**_sentinel3.conf:_**\r\n\r\nsentinel monitor mymaster testHost 6380 2\r\nsentinel down-after-milliseconds mymaster 6000\r\nsentinel failover-timeout mymaster 18000\r\nreplica-announce-ip testHost\r\nport 26382\r\nsentinel resolve-hostnames yes\r\nsentinel announce-hostnames yes\r\n\r\n**Part 2. Test Step**\r\n\r\nafter all master, replicas, and sentinels startup, **_first shutdown sentinel1, and wait for a few seconds,\r\nshutdown master_**, and never startup again\r\n\r\n**Part 3 Output logs:**\r\n\r\n**_Sentinel 2 log:_**\r\n\r\n**_2495:X 15 Jul 2021 09:45:01.584 # +sdown master mymaster testHost 6380_**\r\n2495:X 15 Jul 2021 09:45:01.695 # +new-epoch 1\r\n2495:X 15 Jul 2021 09:45:01.701 # +vote-for-leader 72c18be5a45f6a5fed5bc9d1e1ab6067510ad4a4 1\r\n**_2495:X 15 Jul 2021 09:45:02.724 # +odown master mymaster testHost 6380 #quorum 2/2_**\r\n2495:X 15 Jul 2021 09:45:02.724 # Next failover delay: I will not start a failover before Thu Jul 15 09:45:38 2021\r\n2495:X 15 Jul 2021 09:45:02.952 # +config-update-from sentinel 72c18be5a45f6a5fed5bc9d1e1ab6067510ad4a4 127.0.0.1 26382 @ mymaster testHost 6380\r\n2495:X 15 Jul 2021 09:45:02.952 # +switch-master mymaster testHost 6380 testHost 6381\r\n2495:X 15 Jul 2021 09:45:02.953 * +slave slave testHost:6380 testHost 6380 @ mymaster testHost 6381\r\n2495:X 15 Jul 2021 09:45:09.053 # +sdown slave testHost:6380 testHost 6380 @ mymaster testHost 6381\r\n\r\n**_Sentinel 3 log:_**\r\n\r\n**_2500:X 15 Jul 2021 09:45:01.588 # +sdown master mymaster testHost 6380_**\r\n**_2500:X 15 Jul 2021 09:45:01.660 # +odown master mymaster testHost 6380 #quorum 2/2_**\r\n2500:X 15 Jul 2021 09:45:01.660 # +new-epoch 1\r\n2500:X 15 Jul 2021 09:45:01.660 # +try-failover master mymaster testHost 6380\r\n2500:X 15 Jul 2021 09:45:01.687 # +vote-for-leader 72c18be5a45f6a5fed5bc9d1e1ab6067510ad4a4 1\r\n2500:X 15 Jul 2021 09:45:01.701 # c6a6398e2873710278c4a5ea5ed14aea0fe98465 voted for 72c18be5a45f6a5fed5bc9d1e1ab6067510ad4a4 1\r\n2500:X 15 Jul 2021 09:45:01.744 # +elected-leader master mymaster testHost 6380\r\n2500:X 15 Jul 2021 09:45:01.744 # +failover-state-select-slave master mymaster testHost 6380\r\n2500:X 15 Jul 2021 09:45:01.841 # +selected-slave slave testHost:6381 testHost 6381 @ mymaster testHost 6380\r\n2500:X 15 Jul 2021 09:45:01.841 * +failover-state-send-slaveof-noone slave testHost:6381 testHost 6381 @ mymaster testHost 6380\r\n2500:X 15 Jul 2021 09:45:01.908 * +failover-state-wait-promotion slave testHost:6381 testHost 6381 @ mymaster testHost 6380\r\n2500:X 15 Jul 2021 09:45:02.883 # +promoted-slave slave testHost:6381 testHost 6381 @ mymaster testHost 6380\r\n2500:X 15 Jul 2021 09:45:02.883 # +failover-state-reconf-slaves master mymaster testHost 6380\r\n2500:X 15 Jul 2021 09:45:02.945 # +failover-end master mymaster testHost 6380\r\n2500:X 15 Jul 2021 09:45:02.945 # +switch-master mymaster testHost 6380 testHost 6381\r\n2500:X 15 Jul 2021 09:45:02.945 * +slave slave testHost:6380 testHost 6380 @ mymaster testHost 6381\r\n2500:X 15 Jul 2021 09:45:08.979 # +sdown slave testHost:6380 testHost 6380 @ mymaster testHost 6381\r\n\r\n"
    },
    {
      "id": 886171828,
      "user": "thed0ct0r",
      "created_at": "2021-07-25T09:15:15Z",
      "body": "@hwware i am also running into this issue attempting to use sentinel in a docker swarm environment (where the internal DNS can resolve task names to addresses because ip's may change. running on an overlay network - where nat should not be an issue as all ports are open and mapped 1:1)\r\n\r\nbelow is the simplest compose file which is basically a copy of your suggested configuration, and the issue reproduces both on a single machine, as well as on a cluster.\r\n\r\n```\r\nversion: '3.8'\r\n\r\nservices:\r\n  master:\r\n    image: redis:alpine\r\n    deploy:\r\n      replicas: 1\r\n      restart_policy:\r\n        delay: 5s\r\n    networks:\r\n      - redis-net\r\n    hostname: master\r\n    volumes:\r\n      - type: volume\r\n        source: master-data\r\n        target: /data\r\n    entrypoint:\r\n      - \"sh\"\r\n      - \"-c\"\r\n      - |\r\n        cat <<EOF > /data/redis.conf\r\n        replica-announce-ip tasks.master\r\n        protected-mode no\r\n        bind 0.0.0.0\r\n        EOF\r\n        docker-entrypoint.sh redis-server /data/redis.conf --loglevel debug\r\n\r\n  replica:\r\n    image: redis:alpine\r\n    deploy:\r\n      replicas: 1\r\n      restart_policy:\r\n        delay: 5s\r\n    networks:\r\n      - redis-net\r\n    hostname: replica\r\n    volumes:\r\n      - type: volume\r\n        source: replica-data\r\n        target: /data\r\n    environment:\r\n      - REPLICA_PRIORITY={{.Task.Slot}}\r\n      - REPLICA_ADDR={{.Task.Name}}\r\n    entrypoint:\r\n      - \"sh\"\r\n      - \"-c\"\r\n      - |\r\n        cat <<EOF >> /data/redis.conf\r\n        protected-mode no\r\n        bind 0.0.0.0\r\n        replica-announce-ip $$REPLICA_ADDR\r\n        replicaof tasks.master 6379\r\n        replica-priority $$REPLICA_PRIORITY\r\n        EOF\r\n        docker-entrypoint.sh redis-server /data/redis.conf --loglevel debug\r\n\r\n  sentinel:\r\n    image: redis:alpine\r\n    deploy:\r\n      replicas: 3\r\n      restart_policy:\r\n        delay: 5s\r\n    networks:\r\n      - redis-net\r\n    hostname: sentinel-{{.Task.Slot}}\r\n    environment:\r\n      - SENTINEL_ADDR={{.Task.Name}}\r\n    entrypoint:\r\n      - \"sh\"\r\n      - \"-c\"\r\n      - |\r\n        cat <<EOF >> /data/sentinel.conf\r\n        protected-mode no\r\n        bind 0.0.0.0\r\n        sentinel announce-ip $$SENTINEL_ADDR\r\n        sentinel monitor test-cluster tasks.master 6379 2\r\n        sentinel down-after-milliseconds test-cluster 6000\r\n        sentinel failover-timeout test-cluster 18000\r\n        sentinel resolve-hostnames yes\r\n        sentinel announce-hostnames yes\r\n        EOF\r\n        docker-entrypoint.sh redis-sentinel /data/sentinel.conf --loglevel debug\r\n\r\nnetworks:\r\n  redis-net:\r\n    driver: overlay\r\n    attachable: true\r\n\r\nvolumes:\r\n  master-data:\r\n    name: 'redis_volume_{{.Service.Name}}_{{.Task.Slot}}'\r\n  replica-data:\r\n    name: 'redis_volume_{{.Service.Name}}_{{.Task.Slot}}'\r\n```\r\n\r\nhaving sentinel announce-hostnames yes results in sentinels emitting the +sdown message for the master but never moving on to +odown and failover.\r\nsimply changing sentinel announce-hostnames to no in the compose file fixes this without any other change. \r\nthis is a problem because it would need to pin the master's ip address and in case of a machine failure the master would never be re-added to the set (there is no record in the sentinel's config/history of the original master), not even as a replica.\r\n\r\nyou can run the compose file using `docker stack deploy -c sentinel-compose.yml test` with docker running in swarm mode"
    },
    {
      "id": 903030336,
      "user": "troyanov",
      "created_at": "2021-08-21T01:18:29Z",
      "body": "I'm having same issue and I think I was able to localise it.\r\n\r\n---\r\nHere is my investigation of I got when I running `alpine` based image on k8s as a StatefulSet\r\n\r\nCheck IP on `redis-0.redis-headless.default.svc.cluster.local` pod:\r\n```bash\r\n/data # ifconfig\r\neth0      Link encap:Ethernet \r\n              inet addr:10.244.0.161\r\n```\r\n\r\nStarting `redis-sentinel` pod and we can see it is connecting to `redis-0` right away:\r\n\r\n```bash\r\n/data # redis-cli\r\n127.0.0.1:6379> monitor\r\nOK\r\n1629506678.413582 [0 10.244.0.177:53103] \"PING\"\r\n1629506678.413711 [0 10.244.0.177:53103] \"INFO\"\r\n1629506678.413838 [0 10.244.0.177:42955] \"SUBSCRIBE\" \"__sentinel__:hello\"\r\n1629506679.513769 [0 10.244.0.177:53103] \"PING\"\r\n1629506680.463244 [0 10.244.0.177:53103] \"PUBLISH\" \"__sentinel__:hello\" \"10.244.0.177,26379,e51cc7822a48f34ae85f8cf0faa8f0a75ff6a243,0,mymaster,redis-0.redis-headless.default.svc.cluster.local,6379,0\"\r\n1629506680.534972 [0 10.244.0.177:53103] \"PING\"\r\n1629506681.536829 [0 10.244.0.177:53103] \"PING\"\r\n1629506682.512930 [0 10.244.0.177:53103] \"PUBLISH\" \"__sentinel__:hello\" \"10.244.0.177,26379,e51cc7822a48f34ae85f8cf0faa8f0a75ff6a243,0,mymaster,redis-0.redis-headless.default.svc.cluster.local,6379,0\"\r\n1629506682.579558 [0 10.244.0.177:53103] \"PING\"\r\n```\r\n\r\nChecking networking info for our `redis-sentinel-0` pod:\r\n```bash\r\n❯ kubectl exec -it redis-sentinel-0 -- /bin/sh\r\nDefaulted container \"redis-sentinel\" out of: redis-sentinel, config (init)\r\n/data # netstat\r\nActive Internet connections (w/o servers)\r\nProto Recv-Q Send-Q Local Address           Foreign Address         State\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:42955 redis-0.redis-headless.default.svc.cluster.local:redis ESTABLISHED\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:34497 redis-1.redis-headless.default.svc.cluster.local:redis ESTABLISHED\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:59095 redis-1.redis-headless.default.svc.cluster.local:redis TIME_WAIT\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:53103 redis-0.redis-headless.default.svc.cluster.local:redis ESTABLISHED\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:39105 redis-1.redis-headless.default.svc.cluster.local:redis ESTABLISHED\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:41515 redis-1.redis-headless.default.svc.cluster.local:redis TIME_WAIT\r\nActive UNIX domain sockets (w/o servers)\r\nProto RefCnt Flags       Type       State         I-Node Path\r\n```\r\n\r\nNow we are killing `redis-0` pod with `kubectl delete pod redis-0` and checking it's new IP address:\r\n```bash\r\n/data # ifconfig\r\neth0      Link encap:Ethernet \r\n              inet addr:10.244.0.237\r\n```\r\n\r\nNow let's check networking info for our `redis-sentinel-0` pod one more time:\r\n\r\n```bash\r\n❯ kubectl exec -it redis-sentinel-0 -- /bin/sh\r\nDefaulted container \"redis-sentinel\" out of: redis-sentinel, config (init)\r\n/data # netstat\r\nActive Internet connections (w/o servers)\r\nProto Recv-Q Send-Q Local Address           Foreign Address         State\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:34497 redis-1.redis-headless.default.svc.cluster.local:redis ESTABLISHED\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:59095 redis-1.redis-headless.default.svc.cluster.local:redis TIME_WAIT\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:39105 redis-1.redis-headless.default.svc.cluster.local:redis ESTABLISHED\r\ntcp        0      0 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:41515 redis-1.redis-headless.default.svc.cluster.local:redis TIME_WAIT\r\ntcp        0      1 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:55851 10.244.0.161:redis      SYN_SENT\r\ntcp        0      1 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:52127 10.244.0.161:redis      SYN_SENT\r\nActive UNIX domain sockets (w/o servers)\r\nProto RefCnt Flags       Type       State         I-Node Path\r\n```\r\n\r\nNote those hanging `SYN_SENT` that still using `10.244.0.161` (which was initial IP of `redis-0`) \r\n```bash\r\ntcp        0      1 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:55851 10.244.0.161:redis      SYN_SENT\r\ntcp        0      1 redis-sentinel-0.redis-sentinel.default.svc.cluster.local:52127 10.244.0.161:redis      SYN_SENT\r\n```\r\n\r\nAt the end after killing pods several times it looks like this:\r\n```bash\r\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\r\ntcp        0      1 10.244.0.211:40581      10.244.0.201:6379       SYN_SENT    1/redis-sentinel 0.\r\ntcp        0      1 10.244.0.211:41353      10.244.1.38:6379        SYN_SENT    1/redis-sentinel 0.\r\ntcp        0      1 10.244.0.211:44925      10.244.0.201:6379       SYN_SENT    1/redis-sentinel 0.\r\ntcp        0      0 10.244.0.211:26379      10.244.0.234:46771      ESTABLISHED 1/redis-sentinel 0.\r\ntcp        0      0 10.244.0.211:26379      10.244.1.10:33485       ESTABLISHED 1/redis-sentinel 0.\r\ntcp        0      0 10.244.0.211:33909      10.244.1.10:26379       ESTABLISHED 1/redis-sentinel 0.\r\ntcp        0      0 10.244.0.211:54913      10.244.0.234:26379      ESTABLISHED 1/redis-sentinel 0.\r\ntcp        0      1 10.244.0.211:36375      10.244.1.38:6379        SYN_SENT    1/redis-sentinel 0.\r\n```"
    },
    {
      "id": 903212544,
      "user": "troyanov",
      "created_at": "2021-08-22T04:42:17Z",
      "body": "It looks like Sentinel is memorising IP after hostname lookup and keep trying to connect to that address.\r\n\r\nHere `10.244.1.32` is IP address that used to be valid for `redis-1` before that pod was restarted (after restart DNS name for a StatefulSet pod is the same, but IP address is a not preserved) \r\n\r\n```\r\nroot@redis-sentinel-0:/data# netstat -etd\r\nActive Internet connections (w/o servers)\r\nProto Recv-Q Send-Q Local Address           Foreign Address         State       User       Inode\r\ntcp        0      0 redis-sentinel-0.:48011 redis-0.redis-head:6379 ESTABLISHED root       64189289\r\ntcp        0      0 redis-sentinel-0.:52896 151.101.18.132:80       TIME_WAIT   root       0\r\ntcp        0      0 redis-sentinel-0.:43725 10-244-1-81.redis:26379 ESTABLISHED root       64185624\r\ntcp        0      0 redis-sentinel-0.:47791 redis-0.redis-head:6379 ESTABLISHED root       64189288\r\ntcp        0      1 redis-sentinel-0.:44463 10.244.1.32:6379        SYN_SENT    root       66661160\r\ntcp        0      0 redis-sentinel-0.:54909 10-244-0-194.redi:26379 ESTABLISHED root       64184651\r\ntcp        0      0 redis-sentinel-0.:26379 10-244-0-194.redi:55715 ESTABLISHED root       64184635\r\ntcp        0      0 redis-sentinel-0.:26379 10-244-1-81.redis:54561 ESTABLISHED root       64184707\r\ntcp        0      1 redis-sentinel-0.:36145 10.244.1.32:6379        SYN_SENT    root       66661984\r\nroot@redis-sentinel-0:/data# tcpdump host 10.244.1.32\r\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\r\nlistening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes\r\n23:24:20.482923 IP redis-sentinel-0.redis-sentinel.default.svc.cluster.local.36937 > 10.244.1.32.6379: Flags [S], seq 689568883, win 64240, options [mss 1460,sackOK,TS val 567563557 ecr 0,nop,wscale 7], length 0\r\n23:24:25.165632 IP redis-sentinel-0.redis-sentinel.default.svc.cluster.local.53155 > 10.244.1.32.6379: Flags [S], seq 135490147, win 64240, options [mss 1460,sackOK,TS val 567568239 ecr 0,nop,wscale 7], length 0\r\n23:24:26.178933 IP redis-sentinel-0.redis-sentinel.default.svc.cluster.local.53155 > 10.244.1.32.6379: Flags [S], seq 135490147, win 64240, options [mss 1460,sackOK,TS val 567569253 ecr 0,nop,wscale 7], length 0\r\n23:24:28.194907 IP redis-sentinel-0.redis-sentinel.default.svc.cluster.local.53155 > 10.244.1.32.6379: Flags [S], seq 135490147, win 64240, options [mss 1460,sackOK,TS val 567571269 ecr 0,nop,wscale 7], length 0\r\n23:24:28.433471 IP redis-sentinel-0.redis-sentinel.default.svc.cluster.local.43915 > 10.244.1.32.6379: Flags [S], seq 4200356803, win 64240, options [mss 1460,sackOK,TS val 567571507 ecr 0,nop,wscale 7], length 0\r\n23:24:29.442940 IP redis-sentinel-0.redis-sentinel.default.svc.cluster.local.43915 > 10.244.1.32.6379: Flags [S], seq 4200356803, win 64240, options [mss 1460,sackOK,TS val 567572517 ecr 0,nop,wscale 7], length 0\r\n23:24:31.458932 IP redis-sentinel-0.redis-sentinel.default.svc.cluster.local.43915 > 10.244.1.32.6379: Flags [S], seq 4200356803, win 64240, options [mss 1460,sackOK,TS val 567574533 ecr 0,nop,wscale 7], length 0```"
    },
    {
      "id": 903214692,
      "user": "troyanov",
      "created_at": "2021-08-22T05:10:54Z",
      "body": "I'm not familiar with Redis codebase, but it seems like it indeed stores `ip:port` after doing hostname lookup\r\nE.g. https://github.com/redis/redis/blob/63e2a6d212e9a30d9768b1d044348420e5b128c9/src/sentinel.c#L1427-L1437"
    },
    {
      "id": 982829474,
      "user": "bkhuong",
      "created_at": "2021-11-30T16:58:08Z",
      "body": "Also running into this issue, any resolution?"
    },
    {
      "id": 1000248115,
      "user": "amitgoyal14",
      "created_at": "2021-12-23T11:44:10Z",
      "body": "I am also facing same issue . After using hostname in place of ip , failover is not happening . \r\nCan you please share any fix ."
    },
    {
      "id": 1000251573,
      "user": "amitgoyal14",
      "created_at": "2021-12-23T11:51:00Z",
      "body": "> \r\n\r\n@hwware why you have used same hostname 'testhost'  for all replica ?  "
    },
    {
      "id": 1011051582,
      "user": "moticless",
      "created_at": "2022-01-12T13:34:09Z",
      "body": "Indeed, even though Sentinel using hostnames, it doesn't support dynamic IPs unfortunately. \r\nI will evaluate the required effort to support it. \r\nThanks."
    },
    {
      "id": 1016541799,
      "user": "moticless",
      "created_at": "2022-01-19T14:51:52Z",
      "body": "Hope this [PR](https://github.com/redis/redis/pull/10146) will fix it. \r\nThanks"
    },
    {
      "id": 1163781284,
      "user": "M-Kepler",
      "created_at": "2022-06-23T00:01:48Z",
      "body": "I have solve this problem by changing image from `redis:alpine` to `redis:latest` and it work."
    }
  ]
}