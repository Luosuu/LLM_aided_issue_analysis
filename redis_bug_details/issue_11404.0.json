{
  "issue_number": 11404.0,
  "title": "Different status in sentinel and redis[BUG]",
  "body": "**Describe the bug**\r\nRedis 5.0.14 running in k8s, with one slave node(pod0) and one master node(pod1), and three sentinels monitor the master node. \r\nwhen I check `info replication` and `role`  in both pod0 and pod1, it shows itself a slave node, but it **`slaves of ` an invalide master node, with master_link_status up**; \r\nBut when I check `sentinel master <master_name>` and `sentinel slaves <master_name>` in sentinel , sentinel says pod1 is the master node, and pod0 is the slave node and **the invalid node, also is a slave node with status up**\r\nHere is the log:\r\n```bash\r\n[root@k8s-master1]# kubectl get pod -owide\r\nNAME.               READY              STATUS              RESTARTS              AGE              IP\r\npod0                  2/2                     RUNNING          0                              142m            172.29.24.160\r\npod1                  2/2                     RUNNING          0                               5d3h            172.29.54.166\r\nsentinel0          2/2                     RUNNING          0                               5d3h            172.29.76.170\r\nsentinel1           2/2                     RUNNING          0                               5d3h            172.29.49.217\r\nsentinel2          2/2                     RUNNING          0                               5d3h            172.29.232.91\r\n\r\n# check `info replication` and `role` in pod0\r\n[root@k8s-master1]# redis-cli -h 172.29.24.160\r\n>info replication\r\n# Replication\r\nrole: slave\r\nmaster_host: 172.29.76.175 (the invalide node)\r\nmaster_link_status: up\r\nmaster_last_io_seconds_ago:1\r\nmaster_sync_in_progress:0\r\nslave_repl_offset:103228379\r\nslave_read_only:1\r\nconnected_slaves:0\r\n> role\r\n1) \"slave\"\r\n2)\"172.29.76.175\" (the invalide node)\r\n3)(integer) 6379\r\n4)\"connected\"\r\n5)(integer) 103231897\r\n\r\n# check `info replication` and `role` in pod1\r\n[root@k8s-master1]# redis-cli -h 172.29.54.166\r\n>info replication\r\n# Replication\r\nrole: slave\r\nmaster_host: 172.29.76.175 (the invalide node)\r\nmaster_link_status: up\r\nmaster_last_io_seconds_ago:2\r\nmaster_sync_in_progress:0\r\nslave_repl_offset:103246243\r\nslave_read_only:1\r\nconnected_slaves:0\r\n> role\r\n1) \"slave\"\r\n2)\"172.29.76.175\" (the invalide node)\r\n3)(integer) 6379\r\n4)\"connected\"\r\n5)(integer) 103231897\r\n\r\n# check `sentinel master <master_name>` and `sentinel slaves <master_name>`  in sentinel2(the same output in sentinel1)\r\n[root@k8s-master1]# redis-cli -h 172.29.232.91 -p 26379\r\n>sentinel master mymaster\r\n1) \"name\"\r\n2)\"mymaster\"\r\n3)\"ip\"\r\n4)\"172.29.54.166\" (pod1)\r\n5)\"port\"\r\n6)\"6379\"\r\n9)\"flags\"\r\n10)\"master\"\r\n29) \"config-epoch\"\r\n30) \"16\"\r\n31) \"num-slaves\"\r\n32) \"1\"\r\n33) \"num-other-sentinels\"\r\n34) \"2\"\r\n35) \"quorum\"\r\n36) \"2\"\r\n> sentinel slaves mymaster\r\n1)  1) \"name\"\r\n    2) \"172.29.76.175:6379\" (the invalide node)\r\n    3) \"ip\"\r\n    4) \"172.29.76.175\"\r\n    5) \"port\"\r\n    6) \"6379\"\r\n    9) \"flags\"\r\n   10) \"slave\"\r\n   11) \"link-pending-commands\"\r\n   12) \"-2\"\r\n   13) \"link-refcount\"\r\n   14) \"1\"\r\n   15) \"last-ping-sent\"\r\n   16) \"0\"\r\n   17) \"last-ok-ping-reply\"\r\n   18) \"537\"\r\n   19) \"last-ping-reply\"\r\n   20) \"537\"\r\n   21) \"down-after-milliseconds\"\r\n   22) \"15000\"\r\n   23) \"info-refresh\"\r\n   24) \"3367\"\r\n   25) \"role-reported\"\r\n   26) \"slave\"\r\n   27) \"role-reported-time\"\r\n   28) \"1124513\"\r\n   29) \"master-link-down-time\"\r\n   30) \"0\"\r\n   31) \"master-link-status\"\r\n   32) \"ok\"\r\n   33) \"master-host\"\r\n   34) \"172.29.54.166\" (pod1)\r\n   35) \"master-port\"\r\n   36) \"6379\"\r\n   37) \"slave-priority\"\r\n   38) \"100\"\r\n   39) \"slave-repl-offset\"\r\n   40) \"118674508\"\r\n2)  1) \"name\"\r\n    2) \"172.29.24.160:6379\" (pod0)\r\n    3) \"ip\"\r\n    4) \"172.29.24.160\"\r\n    5) \"port\"\r\n    6) \"6379\"\r\n    9) \"flags\"\r\n   10) \"slave\"\r\n   11) \"link-pending-commands\"\r\n   12) \"0\"\r\n   13) \"link-refcount\"\r\n   14) \"1\"\r\n   15) \"last-ping-sent\"\r\n   16) \"0\"\r\n   17) \"last-ok-ping-reply\"\r\n   18) \"39\"\r\n   19) \"last-ping-reply\"\r\n   20) \"39\"\r\n   21) \"down-after-milliseconds\"\r\n   22) \"15000\"\r\n   23) \"info-refresh\"\r\n   24) \"2293\"\r\n   25) \"role-reported\"\r\n   26) \"slave\"\r\n   27) \"role-reported-time\"\r\n   28) \"1207740\"\r\n   29) \"master-link-down-time\"\r\n   30) \"0\"\r\n   31) \"master-link-status\"\r\n   32) \"ok\"\r\n   33) \"master-host\"\r\n   34) \"172.29.54.166\" (pod1)\r\n   35) \"master-port\"\r\n   36) \"6379\"\r\n   37) \"slave-priority\"\r\n   38) \"100\"\r\n   39) \"slave-repl-offset\"\r\n   40) \"118674824\"\r\n\r\n```\r\n**To reproduce**\r\n\r\nI don't know how to reproduce it, and why it occurred\r\n",
  "state": "closed",
  "created_at": "2022-10-19T03:02:31Z",
  "updated_at": "2022-10-19T08:05:10Z",
  "closed_at": "2022-10-19T08:05:10Z",
  "labels": [],
  "comments_data": [
    {
      "id": 1283475399,
      "user": "yongman",
      "created_at": "2022-10-19T06:04:02Z",
      "body": "It's related to the cni of kubernetes. With some cni plugins, `getpeername()` can not work correctly which way redis use to get the peer ip address. The result of calling `getpeername()` may be the address of the host that the peer pod located in. "
    },
    {
      "id": 1283596229,
      "user": "fengyinqiao",
      "created_at": "2022-10-19T08:05:05Z",
      "body": "After careful investigation, the cause has been found out. After the pod0 is deleted, the container remains on the k8s node, and the redis process in the container is still alive. And it has a different IP address from the renewed pod."
    }
  ]
}