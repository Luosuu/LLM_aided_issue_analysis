{
  "issue_number": 13414.0,
  "title": "[BUG] CLUSTER SHARDS command returns \"empty array\" in slots section",
  "body": "We are running a 6-node Redis cluster (version 7.2.0) in a Docker environment with 1 replica. When we stop one of the master nodes in the cluster, the `CLUSTER SHARDS` command returns empty slots for that specific shard. The node from the failed shard returns the correct output for the `CLUSTER SHARRD` command.\r\n \r\nOutput with an `empty array` from the container which is not a part of the failed shard.\r\n```\r\n1) 1) \"slots\"\r\n   2) (empty array)\r\n   3) \"nodes\"\r\n   4) 1)  1) \"id\"\r\n          2) \"b1c9fe739d6e8d0c519f98ac5e8ebcd1e52cfbe3\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.3\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.3\"\r\n          9) \"role\"\r\n         10) \"master\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 224\r\n         13) \"health\"\r\n         14) \"fail\"\r\n      2)  1) \"id\"\r\n          2) \"42baa4b4da6a0cc4ef9e18c43c2f86403822b72b\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.5\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.5\"\r\n          9) \"role\"\r\n         10) \"master\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 224\r\n         13) \"health\"\r\n         14) \"online\"\r\n2) 1) \"slots\"\r\n   2) 1) (integer) 5461\r\n      2) (integer) 10922\r\n   3) \"nodes\"\r\n   4) 1)  1) \"id\"\r\n          2) \"7baa9f314205d4047655830f45e4014187918e0c\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.6\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.6\"\r\n          9) \"role\"\r\n         10) \"master\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 322\r\n         13) \"health\"\r\n         14) \"online\"\r\n      2)  1) \"id\"\r\n          2) \"0c51817bbfb0879bf4aaad66a1244b76d1a64d2b\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.7\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.7\"\r\n          9) \"role\"\r\n         10) \"replica\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 322\r\n         13) \"health\"\r\n         14) \"online\"\r\n3) 1) \"slots\"\r\n   2) 1) (integer) 0\r\n      2) (integer) 5460\r\n   3) \"nodes\"\r\n   4) 1)  1) \"id\"\r\n          2) \"5fa7cec07512060397bcfda7bbb1cec73052a905\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.2\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.2\"\r\n          9) \"role\"\r\n         10) \"master\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 308\r\n         13) \"health\"\r\n         14) \"online\"\r\n      2)  1) \"id\"\r\n          2) \"98d6ec2bd84ae48527f6c67148464d5e8d55afb1\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.4\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.4\"\r\n          9) \"role\"\r\n         10) \"replica\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 308\r\n         13) \"health\"\r\n         14) \"online\"\r\n```\r\n\r\nCorrect output from one of the replicas (part of the same failed shard):\r\n```\r\n1) 1) \"slots\"\r\n   2) 1) (integer) 5461\r\n      2) (integer) 10922\r\n   3) \"nodes\"\r\n   4) 1)  1) \"id\"\r\n          2) \"7baa9f314205d4047655830f45e4014187918e0c\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.6\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.6\"\r\n          9) \"role\"\r\n         10) \"master\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 12222\r\n         13) \"health\"\r\n         14) \"online\"\r\n      2)  1) \"id\"\r\n          2) \"0c51817bbfb0879bf4aaad66a1244b76d1a64d2b\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.7\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.7\"\r\n          9) \"role\"\r\n         10) \"replica\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 12222\r\n         13) \"health\"\r\n         14) \"online\"\r\n2) 1) \"slots\"\r\n   2) 1) (integer) 0\r\n      2) (integer) 5460\r\n   3) \"nodes\"\r\n   4) 1)  1) \"id\"\r\n          2) \"98d6ec2bd84ae48527f6c67148464d5e8d55afb1\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.4\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.4\"\r\n          9) \"role\"\r\n         10) \"replica\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 12208\r\n         13) \"health\"\r\n         14) \"online\"\r\n      2)  1) \"id\"\r\n          2) \"5fa7cec07512060397bcfda7bbb1cec73052a905\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.2\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.2\"\r\n          9) \"role\"\r\n         10) \"master\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 12208\r\n         13) \"health\"\r\n         14) \"online\"\r\n3) 1) \"slots\"\r\n   2) 1) (integer) 10923\r\n      2) (integer) 16383\r\n   3) \"nodes\"\r\n   4) 1)  1) \"id\"\r\n          2) \"42baa4b4da6a0cc4ef9e18c43c2f86403822b72b\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.5\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.5\"\r\n          9) \"role\"\r\n         10) \"master\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 224\r\n         13) \"health\"\r\n         14) \"online\"\r\n      2)  1) \"id\"\r\n          2) \"b1c9fe739d6e8d0c519f98ac5e8ebcd1e52cfbe3\"\r\n          3) \"port\"\r\n          4) (integer) 6379\r\n          5) \"ip\"\r\n          6) \"172.18.0.3\"\r\n          7) \"endpoint\"\r\n          8) \"172.18.0.3\"\r\n          9) \"role\"\r\n         10) \"master\"\r\n         11) \"replication-offset\"\r\n         12) (integer) 210\r\n         13) \"health\"\r\n         14) \"fail\"\r\n```\r\n\r\n\r\nSteps to reproduce the behavior and/or a minimal code sample.\r\n\r\n- start cluster using attached [docker-compose.yml.txt](https://github.com/user-attachments/files/16202071/docker-compose.yml.txt)\r\n- create a cluster using below command\r\n `docker exec -it redis-node-0 redis-cli --cluster create redis-node-0:6379 redis-node-1:6379 redis-node-2:6379 redis-node-3:6379 redis-node-4:6379 redis-node-5:6379 --cluster-replicas 1`\r\n- stop one of the container and check output of `CLUSTER SHARDS` command from different container.\r\n `docker stop redis-node-2`\r\n `docker exec -it redis-node-0 redis-cli -h redis-node-5 CLUSTER SHARDS`\r\n `docker exec -it redis-node-0 redis-cli -h redis-node-0 CLUSTER SHARDS`\r\n\r\n\r\nIt should return slots correctly from all of the nodes in the cluster. Please let us know if we are doing something wrong or if this is expected behavior.\r\n\r\n\r\n",
  "state": "closed",
  "created_at": "2024-07-13T12:29:02Z",
  "updated_at": "2024-08-01T23:22:14Z",
  "closed_at": "2024-08-01T23:22:14Z",
  "labels": [
    "class:bug"
  ],
  "comments_data": [
    {
      "id": 2226923994,
      "user": "sundb",
      "created_at": "2024-07-13T14:17:17Z",
      "body": "@patademahesh was the replica of the failed node promoted to master?"
    },
    {
      "id": 2226929638,
      "user": "patademahesh",
      "created_at": "2024-07-13T14:26:21Z",
      "body": "Yes, here is the NODES command output\r\n\r\n```\r\n$ docker exec -it redis-node-0 redis-cli -h redis-node-5 CLUSTER NODES\r\n7baa9f314205d4047655830f45e4014187918e0c 172.18.0.6:6379@16379 master - 0 1720880745097 2 connected 5461-10922\r\n0c51817bbfb0879bf4aaad66a1244b76d1a64d2b 172.18.0.7:6379@16379 myself,slave 7baa9f314205d4047655830f45e4014187918e0c 0 1720880742000 2 connected\r\n98d6ec2bd84ae48527f6c67148464d5e8d55afb1 172.18.0.4:6379@16379 slave 5fa7cec07512060397bcfda7bbb1cec73052a905 0 1720880743086 1 connected\r\n42baa4b4da6a0cc4ef9e18c43c2f86403822b72b 172.18.0.5:6379@16379 master - 0 1720880744092 7 connected 10923-16383\r\n5fa7cec07512060397bcfda7bbb1cec73052a905 172.18.0.2:6379@16379 master - 0 1720880743000 1 connected 0-5460\r\nb1c9fe739d6e8d0c519f98ac5e8ebcd1e52cfbe3 172.18.0.3:6379@16379 master,fail - 1720863593778 1720863590000 3 connected\r\n```"
    },
    {
      "id": 2226942127,
      "user": "sundb",
      "created_at": "2024-07-13T14:58:40Z",
      "body": "@patademahesh since the old master has been in the fail state, it will no longer receive messages from other nodes, so you need to manually delete it(cluster forget) and add it as a replica of the new master.\r\ni'm not expect with cluster, please figure me out if i'm wrong, thanks."
    },
    {
      "id": 2226945302,
      "user": "patademahesh",
      "created_at": "2024-07-13T15:03:25Z",
      "body": "Hi @sundb, the issue is all nodes except the newly elected master shows empty slots."
    }
  ]
}