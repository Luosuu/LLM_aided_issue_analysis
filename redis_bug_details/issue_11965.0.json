{
  "issue_number": 11965.0,
  "title": "[CRASH] 7.0.10 memcpy sigabrt due to buffer overflow in replication.c line 367",
  "body": "This was code changed between 7.0.8 and 7.0.10\r\n\r\n```\r\ngit diff -w 7.0.8..7.0.10 -- src/replication.c\r\ndiff --git a/src/replication.c b/src/replication.c\r\nindex 2c7755512..e86aa4b59 100644\r\n--- a/src/replication.c\r\n+++ b/src/replication.c\r\n@@ -324,9 +324,8 @@ void feedReplicationBuffer(char *s, size_t len) {\r\n     static long long repl_block_id = 0;\r\n \r\n     if (server.repl_backlog == NULL) return;\r\n-    server.master_repl_offset += len;\r\n-    server.repl_backlog->histlen += len;\r\n \r\n+    while(len > 0) {\r\n         size_t start_pos = 0; /* The position of referenced block to start sending. */\r\n         listNode *start_node = NULL; /* Replica/backlog starts referenced node. */\r\n         int add_new_block = 0; /* Create new block if current block is total used. */\r\n@@ -345,20 +344,27 @@ void feedReplicationBuffer(char *s, size_t len) {\r\n             tail->used += copy;\r\n             s += copy;\r\n             len -= copy;\r\n+            server.master_repl_offset += copy;\r\n+            server.repl_backlog->histlen += copy;\r\n         }\r\n         if (len) {\r\n             /* Create a new node, make sure it is allocated to at\r\n              * least PROTO_REPLY_CHUNK_BYTES */\r\n             size_t usable_size;\r\n-        size_t size = (len < PROTO_REPLY_CHUNK_BYTES) ? PROTO_REPLY_CHUNK_BYTES : len;\r\n+            /* Avoid creating nodes smaller than PROTO_REPLY_CHUNK_BYTES, so that we can append more data into them,\r\n+             * and also avoid creating nodes bigger than repl_backlog_size / 16, so that we won't have huge nodes that can't\r\n+             * trim when we only still need to hold a small portion from them. */\r\n+            size_t limit = max((size_t)server.repl_backlog_size / 16, (size_t)PROTO_REPLY_CHUNK_BYTES);\r\n+            size_t size = min(max(len, (size_t)PROTO_REPLY_CHUNK_BYTES), limit);\r\n             tail = zmalloc_usable(size + sizeof(replBufBlock), &usable_size);\r\n             /* Take over the allocation's internal fragmentation */\r\n             tail->size = usable_size - sizeof(replBufBlock);\r\n-        tail->used = len;\r\n+            size_t copy = (tail->size >= len) ? len : tail->size;\r\n+            tail->used = copy;\r\n             tail->refcount = 0;\r\n-        tail->repl_offset = server.master_repl_offset - tail->used + 1;\r\n+            tail->repl_offset = server.master_repl_offset + 1;\r\n             tail->id = repl_block_id++;\r\n-        memcpy(tail->buf, s, len);\r\n+            memcpy(tail->buf, s, copy);\r\n             listAddNodeTail(server.repl_buffer_blocks, tail);\r\n             /* We also count the list node memory into replication buffer memory. */\r\n             server.repl_buffer_mem += (usable_size + sizeof(listNode));\r\n@@ -367,6 +373,10 @@ void feedReplicationBuffer(char *s, size_t len) {\r\n                 start_node = listLast(server.repl_buffer_blocks);\r\n                 start_pos = 0;\r\n             }\r\n+            s += copy;\r\n+            len -= copy;\r\n+            server.master_repl_offset += copy;\r\n+            server.repl_backlog->histlen += copy;\r\n         }\r\n \r\n         /* For output buffer of replicas. */\r\n@@ -408,6 +418,7 @@ void feedReplicationBuffer(char *s, size_t len) {\r\n          * in freeMemoryGetNotCountedMemory for details. */\r\n         incrementalTrimReplicationBacklog(REPL_BACKLOG_TRIM_BLOCKS_PER_CALL);\r\n     }\r\n+}\r\n \r\n /* Propagate write commands to replication stream.\r\n  *\r\n\r\n```\r\n\r\nIt seems the changed buffer size calculation leads to \r\n\r\n```\r\n(gdb) bt\r\n#0  0x00007fe91f64367b in __GI_kill () at ../sysdeps/unix/syscall-template.S:120\r\n#1  0x00005568bf6c67d3 in bugReportEnd (killViaSignal=<optimized out>, sig=6) at /usr/src/debug/redis-7.0.10/src/debug.c:2114\r\n#2  <signal handler called>\r\n#3  __pthread_kill_implementation (threadid=<optimized out>, signo=signo@entry=6, no_tid=no_tid@entry=0) at pthread_kill.c:44\r\n#4  0x00007fe91f694e03 in __pthread_kill_internal (signo=6, threadid=<optimized out>) at pthread_kill.c:78\r\n#5  0x00007fe91f643356 in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26\r\n#6  0x00007fe91f62b897 in __GI_abort () at abort.c:79\r\n#7  0x00007fe91f62c611 in __libc_message (fmt=fmt@entry=0x7fe91f7b02e9 \"*** %s ***: terminated\\n\") at ../sysdeps/posix/libc_fatal.c:150\r\n#8  0x00007fe91f72ae9b in __GI___fortify_fail (msg=msg@entry=0x7fe91f7b028f \"buffer overflow detected\") at fortify_fail.c:24\r\n#9  0x00007fe91f729316 in __GI___chk_fail () at chk_fail.c:28\r\n#10 0x00005568bf68aa79 in memcpy (__len=72100, __src=0x7fe9199f21fd, __dest=0x7fe919a28ca8) at /usr/include/bits/string_fortified.h:29\r\n#11 feedReplicationBuffer (s=<optimized out>, s@entry=0x7fe9199ef389 \"[snip]\"..., len=<optimized out>)\r\n    at /usr/src/debug/redis-7.0.10/src/replication.c:367\r\n#12 0x00005568bf68ae32 in feedReplicationBuffer (len=<optimized out>, s=0x7fe9199ef389 \"[snip]\"...)\r\n    at /usr/src/debug/redis-7.0.10/src/replication.c:326\r\n#13 feedReplicationBufferWithObject (o=<optimized out>) at /usr/src/debug/redis-7.0.10/src/replication.c:242\r\n#14 0x00005568bf68b08c in replicationFeedSlaves (slaves=<optimized out>, dictid=<optimized out>, argv=<optimized out>, argc=<optimized out>) at /usr/src/debug/redis-7.0.10/src/replication.c:501\r\n#15 0x00005568bf65714e in propagatePendingCommands () at /usr/src/debug/redis-7.0.10/src/server.c:3268\r\n#16 0x00005568bf6578e7 in afterCommand (c=<optimized out>) at /usr/src/debug/redis-7.0.10/src/server.c:3597\r\n#17 afterCommand (c=0x7fe91ae2ad00) at /usr/src/debug/redis-7.0.10/src/server.c:3590\r\n#18 call (c=c@entry=0x7fe91ae2ad00, flags=<optimized out>, flags@entry=15) at /usr/src/debug/redis-7.0.10/src/server.c:3539\r\n#19 0x00005568bf6584ad in processCommand (c=0x7fe91ae2ad00) at /usr/src/debug/redis-7.0.10/src/server.c:4018\r\n#20 0x00005568bf671eeb in processCommandAndResetClient (c=0x7fe91ae2ad00) at /usr/src/debug/redis-7.0.10/src/networking.c:2472\r\n#21 processInputBuffer (c=c@entry=0x7fe91ae2ad00) at /usr/src/debug/redis-7.0.10/src/networking.c:2576\r\n#22 0x00005568bf6723a8 in readQueryFromClient (conn=<optimized out>) at /usr/src/debug/redis-7.0.10/src/networking.c:2712\r\n#23 0x00005568bf743d53 in callHandler (handler=<optimized out>, conn=0x7fe9198160c0) at /usr/src/debug/redis-7.0.10/src/connhelpers.h:79\r\n#24 connSocketEventHandler (el=<optimized out>, fd=<optimized out>, clientData=0x7fe9198160c0, mask=<optimized out>) at /usr/src/debug/redis-7.0.10/src/connection.c:310\r\n#25 0x00005568bf64e148 in aeProcessEvents (eventLoop=eventLoop@entry=0x7fe91f02b0f0, flags=flags@entry=27) at /usr/src/debug/redis-7.0.10/src/ae.c:436\r\n#26 0x00005568bf64e52d in aeProcessEvents (flags=27, eventLoop=0x7fe91f02b0f0) at /usr/src/debug/redis-7.0.10/src/ae.c:362\r\n#27 aeMain (eventLoop=0x7fe91f02b0f0) at /usr/src/debug/redis-7.0.10/src/ae.c:496\r\n#28 0x00005568bf646662 in main (argc=2, argv=<optimized out>) at /usr/src/debug/redis-7.0.10/src/server.c:7167\r\n\r\n```\r\n\r\n**Additional information**\r\n\r\n1. openSUSE Tumbleweed\r\n",
  "state": "closed",
  "created_at": "2023-03-24T11:09:52Z",
  "updated_at": "2023-04-13T09:23:23Z",
  "closed_at": "2023-04-10T17:38:42Z",
  "labels": [],
  "comments_data": [
    {
      "id": 1482656433,
      "user": "darix",
      "created_at": "2023-03-24T11:30:02Z",
      "body": "FWIW: the machine doesnt even do replication. it is a standalone redis server."
    },
    {
      "id": 1482658001,
      "user": "sundb",
      "created_at": "2023-03-24T11:31:29Z",
      "body": "@darix Thx, could you provide the full crash logs?"
    },
    {
      "id": 1482668899,
      "user": "darix",
      "created_at": "2023-03-24T11:41:46Z",
      "body": "which part are you missing? not sure that the parts from the redis log are helpful here. sigabrt because memcpy would write beyond the allocated buffer, is pretty obvious."
    },
    {
      "id": 1482671934,
      "user": "sundb",
      "created_at": "2023-03-24T11:44:30Z",
      "body": "Like:\r\n```\r\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\r\n...\r\n------ FAST MEMORY TEST ------\r\n...\r\n```"
    },
    {
      "id": 1482673282,
      "user": "darix",
      "created_at": "2023-03-24T11:45:19Z",
      "body": "```\r\n------ FAST MEMORY TEST ------\r\n20863:M 24 Mar 2023 03:36:14.932 # Bio thread for job type #0 terminated\r\n20863:M 24 Mar 2023 03:36:14.932 # Bio thread for job type #1 terminated\r\n20863:M 24 Mar 2023 03:36:14.932 # Bio thread for job type #2 terminated\r\n*** Preparing to test memory region 5568bf8f3000 (2306048 bytes)\r\n*** Preparing to test memory region 5568c0c93000 (270336 bytes)\r\n*** Preparing to test memory region 7fe918efc000 (63963136 bytes)\r\n*** Preparing to test memory region 7fe91cbfd000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91d3fe000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91dbff000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91e400000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91ec00000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91f604000 (4096 bytes)\r\n*** Preparing to test memory region 7fe91f7f2000 (57344 bytes)\r\n*** Preparing to test memory region 7fe91fc25000 (12288 bytes)\r\n*** Preparing to test memory region 7fe91fc34000 (24576 bytes)\r\n*** Preparing to test memory region 7fe91fc78000 (8192 bytes)\r\n*** Preparing to test memory region 7fe91fd72000 (8192 bytes)\r\n*** Preparing to test memory region 7fe91feeb000 (4096 bytes)\r\n*** Preparing to test memory region 7fe91ffd8000 (12288 bytes)\r\n.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O\r\nFast memory test PASSED, however your memory can still be broken. Please run a memory test for several hours if possible.\r\n```"
    },
    {
      "id": 1482675632,
      "user": "sundb",
      "created_at": "2023-03-24T11:46:59Z",
      "body": "@darix Is there any logs after `REDIS BUG REPORT START: Cut & paste starting from here`"
    },
    {
      "id": 1482692871,
      "user": "darix",
      "created_at": "2023-03-24T12:03:06Z",
      "body": "yes. but as i said ... not sure any more relevant info is in there.\r\n\r\n```\r\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\r\n20863:M 24 Mar 2023 03:36:14.929 # Redis 7.0.10 crashed by signal: 6, si_code: -6\r\n20863:M 24 Mar 2023 03:36:14.929 # Crashed running the instruction at: 0x7fe91f694d7c\r\n\r\n------ STACK TRACE ------\r\nEIP:\r\n/lib64/libc.so.6(+0x8fd7c)[0x7fe91f694d7c]\r\n\r\nBacktrace:\r\n/lib64/libc.so.6(+0x3e420)[0x7fe91f643420]\r\n/lib64/libc.so.6(+0x8fd7c)[0x7fe91f694d7c]\r\n/lib64/libc.so.6(gsignal+0x18)[0x7fe91f643356]\r\n/lib64/libc.so.6(abort+0xd9)[0x7fe91f62b897]\r\n/lib64/libc.so.6(+0x27611)[0x7fe91f62c611]\r\n/lib64/libc.so.6(+0x125e9b)[0x7fe91f72ae9b]\r\n/lib64/libc.so.6(+0x124316)[0x7fe91f729316]\r\n/usr/sbin/redis-server 127.0.0.1:6379(+0xbaa79)[0x5568bf68aa79]\r\n/usr/sbin/redis-server 127.0.0.1:6379(feedReplicationBufferWithObject+0xa2)[0x5568bf68ae32]\r\n/usr/sbin/redis-server 127.0.0.1:6379(replicationFeedSlaves+0x19c)[0x5568bf68b08c]\r\n/usr/sbin/redis-server 127.0.0.1:6379(propagatePendingCommands+0xfe)[0x5568bf65714e]\r\n/usr/sbin/redis-server 127.0.0.1:6379(call+0x6a7)[0x5568bf6578e7]\r\n/usr/sbin/redis-server 127.0.0.1:6379(processCommand+0x81d)[0x5568bf6584ad]\r\n/usr/sbin/redis-server 127.0.0.1:6379(processInputBuffer+0xeb)[0x5568bf671eeb]\r\n/usr/sbin/redis-server 127.0.0.1:6379(readQueryFromClient+0x2d8)[0x5568bf6723a8]\r\n/usr/sbin/redis-server 127.0.0.1:6379(+0x173d53)[0x5568bf743d53]\r\n/usr/sbin/redis-server 127.0.0.1:6379(+0x7e148)[0x5568bf64e148]\r\n/usr/sbin/redis-server 127.0.0.1:6379(aeMain+0x1d)[0x5568bf64e52d]\r\n/usr/sbin/redis-server 127.0.0.1:6379(main+0x352)[0x5568bf646662]\r\n/lib64/libc.so.6(+0x27bb0)[0x7fe91f62cbb0]\r\n/lib64/libc.so.6(__libc_start_main+0x8b)[0x7fe91f62cc79]\r\n/usr/sbin/redis-server 127.0.0.1:6379(_start+0x25)[0x5568bf646d35]\r\n\r\n------ REGISTERS ------\r\n20863:M 24 Mar 2023 03:36:14.931 # \r\nRAX:0000000000000000 RBX:000000000000517f\r\nRCX:00007fe91f694d7c RDX:0000000000000006\r\nRDI:000000000000517f RSI:000000000000517f\r\nRBP:00007fe91fc36040 RSP:00007ffe7b3ea9d0\r\nR8 :00000000ffffffff R9 :0000000000000000\r\nR10:0000000000000008 R11:0000000000000246\r\nR12:00007fe91ffd8000 R13:0000000000000006\r\nR14:0000000000001000 R15:00007fe91f7b02ef\r\nRIP:00007fe91f694d7c EFL:0000000000000246\r\nCSGSFS:002b000000000033\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9df) -> 00005568bf7da0b9\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9de) -> 00007ffe7b3eab67\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9dd) -> 0000000000000030\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9dc) -> 0000000000000000\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9db) -> 0000000000000040\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9da) -> 0000000000000020\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d9) -> 00007fe91f62b897\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d8) -> 00007fe91f7f2430\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d7) -> 00007fe91f643356\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d6) -> 0000000000001000\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d5) -> 00007ffe7b3eab10\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d4) -> 00007fe91ffd8000\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d3) -> 00007fe91fc36040\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d2) -> 0000000000000006\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d1) -> 59c14cc4e9038d00\r\n20863:M 24 Mar 2023 03:36:14.931 # (00007ffe7b3ea9d0) -> 00007fe91f2032e8\r\n\r\n------ INFO OUTPUT ------\r\n# Server\r\nredis_version:7.0.10\r\nredis_git_sha1:00000000\r\nredis_git_dirty:0\r\nredis_build_id:ce21150194f99eee\r\nredis_mode:standalone\r\nos:Linux 6.2.6-1-kvmsmall x86_64\r\narch_bits:64\r\nmonotonic_clock:POSIX clock_gettime\r\nmultiplexing_api:epoll\r\natomicvar_api:c11-builtin\r\ngcc_version:13.0.1\r\nprocess_id:20863\r\nprocess_supervised:systemd\r\nrun_id:df21e7e25b0f43cc9775520c2e446f315d348137\r\ntcp_port:6379\r\nserver_time_usec:1679628974929758\r\nuptime_in_seconds:0\r\nuptime_in_days:0\r\nhz:10\r\nconfigured_hz:10\r\nlru_clock:1907374\r\nexecutable:/usr/sbin/redis-server\r\nconfig_file:/etc/redis/[snip].conf\r\nio_threads_active:0\r\n\r\n# Clients\r\nconnected_clients:9\r\ncluster_connections:0\r\nmaxclients:10000\r\nclient_recent_max_input_buffer:20480\r\nclient_recent_max_output_buffer:0\r\nblocked_clients:0\r\ntracking_clients:0\r\nclients_in_timeout_table:0\r\n\r\n# Memory\r\nused_memory:64452528\r\nused_memory_human:61.47M\r\nused_memory_rss:75104256\r\nused_memory_rss_human:71.62M\r\nused_memory_peak:64452528\r\nused_memory_peak_human:61.47M\r\nused_memory_peak_perc:100.13%\r\nused_memory_overhead:2935188\r\nused_memory_startup:862328\r\nused_memory_dataset:61517340\r\nused_memory_dataset_perc:96.74%\r\nallocator_allocated:64412696\r\nallocator_active:64897024\r\nallocator_resident:69849088\r\ntotal_system_memory:25194160128\r\ntotal_system_memory_human:23.46G\r\nused_memory_lua:33792\r\nused_memory_vm_eval:33792\r\nused_memory_lua_human:33.00K\r\nused_memory_scripts_eval:232\r\nnumber_of_cached_scripts:1\r\nnumber_of_functions:0\r\nnumber_of_libraries:0\r\nused_memory_vm_functions:32768\r\nused_memory_vm_total:66560\r\nused_memory_vm_total_human:65.00K\r\nused_memory_functions:184\r\nused_memory_scripts:416\r\nused_memory_scripts_human:416B\r\nmaxmemory:0\r\nmaxmemory_human:0B\r\nmaxmemory_policy:noeviction\r\nallocator_frag_ratio:1.01\r\nallocator_frag_bytes:484328\r\nallocator_rss_ratio:1.08\r\nallocator_rss_bytes:4952064\r\nrss_overhead_ratio:1.08\r\nrss_overhead_bytes:5255168\r\nmem_fragmentation_ratio:1.17\r\nmem_fragmentation_bytes:10964992\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:20508\r\nmem_total_replication_buffers:20504\r\nmem_clients_slaves:0\r\nmem_clients_normal:191496\r\nmem_cluster_links:0\r\nmem_aof_buffer:0\r\nmem_allocator:jemalloc-5.2.1\r\nactive_defrag_running:0\r\nlazyfree_pending_objects:0\r\nlazyfreed_objects:0\r\n\r\n# Persistence\r\nloading:0\r\nasync_loading:0\r\ncurrent_cow_peak:0\r\ncurrent_cow_size:0\r\ncurrent_cow_size_age:0\r\ncurrent_fork_perc:0.00\r\ncurrent_save_keys_processed:0\r\ncurrent_save_keys_total:0\r\nrdb_changes_since_last_save:25\r\nrdb_bgsave_in_progress:0\r\nrdb_last_save_time:1679628974\r\nrdb_last_bgsave_status:ok\r\nrdb_last_bgsave_time_sec:-1\r\nrdb_current_bgsave_time_sec:-1\r\nrdb_saves:0\r\nrdb_last_cow_size:0\r\nrdb_last_load_keys_expired:13\r\nrdb_last_load_keys_loaded:30886\r\naof_enabled:0\r\naof_rewrite_in_progress:0\r\naof_rewrite_scheduled:0\r\naof_last_rewrite_time_sec:-1\r\naof_current_rewrite_time_sec:-1\r\naof_last_bgrewrite_status:ok\r\naof_rewrites:0\r\naof_rewrites_consecutive_failures:0\r\naof_last_write_status:ok\r\naof_last_cow_size:0\r\nmodule_fork_in_progress:0\r\nmodule_fork_last_cow_size:0\r\n\r\n# Stats\r\ntotal_connections_received:9\r\ntotal_commands_processed:64\r\ninstantaneous_ops_per_sec:34\r\ntotal_net_input_bytes:95420\r\ntotal_net_output_bytes:246502\r\ntotal_net_repl_input_bytes:0\r\ntotal_net_repl_output_bytes:0\r\ninstantaneous_input_kbps:5.76\r\ninstantaneous_output_kbps:150.31\r\ninstantaneous_input_repl_kbps:0.00\r\ninstantaneous_output_repl_kbps:0.00\r\nrejected_connections:0\r\nsync_full:0\r\nsync_partial_ok:0\r\nsync_partial_err:0\r\nexpired_keys:0\r\nexpired_stale_perc:0.00\r\nexpired_time_cap_reached_count:0\r\nexpire_cycle_cpu_milliseconds:0\r\nevicted_keys:0\r\nevicted_clients:0\r\ntotal_eviction_exceeded_time:0\r\ncurrent_eviction_exceeded_time:0\r\nkeyspace_hits:39\r\nkeyspace_misses:48\r\npubsub_channels:0\r\npubsub_patterns:0\r\npubsubshard_channels:0\r\nlatest_fork_usec:0\r\ntotal_forks:0\r\nmigrate_cached_sockets:0\r\nslave_expires_tracked_keys:0\r\nactive_defrag_hits:0\r\nactive_defrag_misses:0\r\nactive_defrag_key_hits:0\r\nactive_defrag_key_misses:0\r\ntotal_active_defrag_time:0\r\ncurrent_active_defrag_time:0\r\ntracking_total_keys:0\r\ntracking_total_items:0\r\ntracking_total_prefixes:0\r\nunexpected_error_replies:0\r\ntotal_error_replies:3\r\ndump_payload_sanitizations:0\r\ntotal_reads_processed:62\r\ntotal_writes_processed:59\r\nio_threaded_reads_processed:0\r\nio_threaded_writes_processed:0\r\nreply_buffer_shrinks:6\r\nreply_buffer_expands:0\r\n\r\n# Replication\r\nrole:master\r\nconnected_slaves:0\r\nmaster_failover_state:no-failover\r\nmaster_replid:8fd1dc32b44953bf7a850a0e697b29ee40d52ed4\r\nmaster_replid2:edb552d6b5a80e2cb3fb92c1d963ddda31111ce5\r\nmaster_repl_offset:34288358\r\nsecond_repl_offset:34267919\r\nrepl_backlog_active:1\r\nrepl_backlog_size:1048576\r\nrepl_backlog_first_byte_offset:34267919\r\nrepl_backlog_histlen:20440\r\n\r\n# CPU\r\nused_cpu_sys:0.088843\r\nused_cpu_user:0.114109\r\nused_cpu_sys_children:0.000000\r\nused_cpu_user_children:0.000000\r\nused_cpu_sys_main_thread:0.095072\r\nused_cpu_user_main_thread:0.106956\r\n\r\n# Modules\r\n\r\n# Commandstats\r\ncmdstat_eval:calls=1,usec=61,usec_per_call=61.00,rejected_calls=0,failed_calls=0\r\ncmdstat_multi:calls=3,usec=0,usec_per_call=0.00,rejected_calls=0,failed_calls=0\r\ncmdstat_get:calls=22,usec=54,usec_per_call=2.45,rejected_calls=1,failed_calls=0\r\ncmdstat_setex:calls=1,usec=6,usec_per_call=6.00,rejected_calls=0,failed_calls=0\r\ncmdstat_ltrim:calls=3,usec=6,usec_per_call=2.00,rejected_calls=0,failed_calls=0\r\ncmdstat_mget:calls=5,usec=237,usec_per_call=47.40,rejected_calls=1,failed_calls=0\r\ncmdstat_exec:calls=3,usec=57,usec_per_call=19.00,rejected_calls=0,failed_calls=0\r\ncmdstat_exists:calls=3,usec=8,usec_per_call=2.67,rejected_calls=0,failed_calls=0\r\ncmdstat_hset:calls=1,usec=1,usec_per_call=1.00,rejected_calls=0,failed_calls=0\r\ncmdstat_llen:calls=3,usec=3,usec_per_call=1.00,rejected_calls=0,failed_calls=0\r\ncmdstat_expire:calls=4,usec=12,usec_per_call=3.00,rejected_calls=0,failed_calls=0\r\ncmdstat_incr:calls=3,usec=17,usec_per_call=5.67,rejected_calls=0,failed_calls=0\r\ncmdstat_setnx:calls=1,usec=2,usec_per_call=2.00,rejected_calls=0,failed_calls=0\r\ncmdstat_lpush:calls=1,usec=3,usec_per_call=3.00,rejected_calls=0,failed_calls=0\r\ncmdstat_rpush:calls=1,usec=0,usec_per_call=0.00,rejected_calls=0,failed_calls=0\r\ncmdstat_evalsha:calls=3,usec=68,usec_per_call=22.67,rejected_calls=0,failed_calls=1\r\ncmdstat_lrange:calls=2,usec=9,usec_per_call=4.50,rejected_calls=0,failed_calls=0\r\ncmdstat_hget:calls=2,usec=9,usec_per_call=4.50,rejected_calls=0,failed_calls=0\r\ncmdstat_lrem:calls=1,usec=3,usec_per_call=3.00,rejected_calls=0,failed_calls=0\r\ncmdstat_hexists:calls=1,usec=0,usec_per_call=0.00,rejected_calls=0,failed_calls=0\r\n\r\n# Errorstats\r\nerrorstat_LOADING:count=2\r\nerrorstat_NOSCRIPT:count=1\r\n\r\n# Latencystats\r\nlatency_percentiles_usec_eval:p50=61.183,p99=61.183,p99.9=61.183\r\nlatency_percentiles_usec_multi:p50=0.001,p99=0.001,p99.9=0.001\r\nlatency_percentiles_usec_get:p50=2.007,p99=14.015,p99.9=14.015\r\nlatency_percentiles_usec_setex:p50=6.015,p99=6.015,p99.9=6.015\r\nlatency_percentiles_usec_ltrim:p50=2.007,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_mget:p50=45.055,p99=81.407,p99.9=81.407\r\nlatency_percentiles_usec_exec:p50=25.087,p99=27.007,p99.9=27.007\r\nlatency_percentiles_usec_exists:p50=3.007,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_hset:p50=1.003,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_llen:p50=1.003,p99=2.007,p99.9=2.007\r\nlatency_percentiles_usec_expire:p50=3.007,p99=4.015,p99.9=4.015\r\nlatency_percentiles_usec_incr:p50=6.015,p99=6.015,p99.9=6.015\r\nlatency_percentiles_usec_setnx:p50=2.007,p99=2.007,p99.9=2.007\r\nlatency_percentiles_usec_lpush:p50=3.007,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_rpush:p50=0.001,p99=0.001,p99.9=0.001\r\nlatency_percentiles_usec_evalsha:p50=30.079,p99=31.103,p99.9=31.103\r\nlatency_percentiles_usec_lrange:p50=3.007,p99=6.015,p99.9=6.015\r\nlatency_percentiles_usec_hget:p50=4.015,p99=5.023,p99.9=5.023\r\nlatency_percentiles_usec_lrem:p50=3.007,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_hexists:p50=0.001,p99=0.001,p99.9=0.001\r\n\r\n# Cluster\r\ncluster_enabled:0\r\n\r\n# Keyspace\r\ndb0:keys=30890,expires=9651,avg_ttl=33727081572\r\n\r\n------ CLIENT LIST OUTPUT ------\r\nid=8 addr=127.0.0.1:56672 laddr=127.0.0.1:6379 fd=12 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=22272 events=r cmd=mget user=default redir=-1 resp=2\r\nid=9 addr=127.0.0.1:56678 laddr=127.0.0.1:6379 fd=13 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=1024 rbp=0 obl=0 oll=0 omem=0 tot-mem=22272 events=r cmd=get user=default redir=-1 resp=2\r\nid=3 addr=127.0.0.1:56630 laddr=127.0.0.1:6379 fd=8 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=1024 rbp=12 obl=0 oll=0 omem=0 tot-mem=22272 events=r cmd=get user=default redir=-1 resp=2\r\nid=4 addr=127.0.0.1:56636 laddr=127.0.0.1:6379 fd=9 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=37632 events=r cmd=get user=default redir=-1 resp=2\r\nid=10 addr=127.0.0.1:56690 laddr=127.0.0.1:6379 fd=14 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=16384 rbp=5 obl=0 oll=0 omem=0 tot-mem=37632 events=r cmd=get user=default redir=-1 resp=2\r\nid=5 addr=127.0.0.1:56646 laddr=127.0.0.1:6379 fd=7 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=4096 rbp=3851 obl=0 oll=0 omem=0 tot-mem=25344 events=r cmd=exec user=default redir=-1 resp=2\r\nid=6 addr=127.0.0.1:56662 laddr=127.0.0.1:6379 fd=10 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=98294 argv-mem=84105 multi-mem=0 rbs=1024 rbp=1024 obl=5 oll=0 omem=0 tot-mem=184241 events=r cmd=setex user=default redir=-1 resp=2\r\nid=7 addr=127.0.0.1:56664 laddr=127.0.0.1:6379 fd=11 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=1024 rbp=12 obl=0 oll=0 omem=0 tot-mem=22272 events=r cmd=get user=default redir=-1 resp=2\r\nid=11 addr=127.0.0.1:56700 laddr=127.0.0.1:6379 fd=15 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=20474 argv-mem=0 multi-mem=0 rbs=16384 rbp=16384 obl=0 oll=0 omem=0 tot-mem=37632 events=r cmd=mget user=default redir=-1 resp=2\r\n\r\n------ CURRENT CLIENT INFO ------\r\nid=6 addr=127.0.0.1:56662 laddr=127.0.0.1:6379 fd=10 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=98294 argv-mem=84105 multi-mem=0 rbs=1024 rbp=1024 obl=5 oll=0 omem=0 tot-mem=184241 events=r cmd=setex user=default redir=-1 resp=2\r\nargv[0]: '\"SET\"'\r\nargv[1]: '\"default:ANON_CACHE_text/html_[snip]/|m=false|c=true|o=false|d=false|b=false|t=|ca=|l=_body\"'\r\nargv[2]: '\"[snip]\"'\r\nargv[3]: '\"PXAT\"'\r\nargv[4]: '\"1679629034929\"'\r\n20863:M 24 Mar 2023 03:36:14.931 # key 'default:ANON_CACHE_text/html_[snip]/|m=false|c=true|o=false|d=false|b=false|t=|ca=|l=_body' found in DB containing the following object:\r\n20863:M 24 Mar 2023 03:36:14.931 # Object type: 0\r\n20863:M 24 Mar 2023 03:36:14.931 # Object encoding: 0\r\n20863:M 24 Mar 2023 03:36:14.931 # Object refcount: 3\r\n\r\n------ MODULES INFO OUTPUT ------\r\n\r\n------ CONFIG DEBUG OUTPUT ------\r\nlazyfree-lazy-user-del no\r\nio-threads-do-reads no\r\nlist-compress-depth 0\r\nlazyfree-lazy-server-del no\r\nactivedefrag no\r\nlazyfree-lazy-expire no\r\nrepl-diskless-load disabled\r\nlazyfree-lazy-user-flush no\r\nslave-read-only yes\r\nreplica-read-only yes\r\nsanitize-dump-payload no\r\nlazyfree-lazy-eviction no\r\nproto-max-bulk-len 512mb\r\nclient-query-buffer-limit 1gb\r\nio-threads 1\r\nrepl-diskless-sync no\r\n\r\n------ FAST MEMORY TEST ------\r\n20863:M 24 Mar 2023 03:36:14.932 # Bio thread for job type #0 terminated\r\n20863:M 24 Mar 2023 03:36:14.932 # Bio thread for job type #1 terminated\r\n20863:M 24 Mar 2023 03:36:14.932 # Bio thread for job type #2 terminated\r\n*** Preparing to test memory region 5568bf8f3000 (2306048 bytes)\r\n*** Preparing to test memory region 5568c0c93000 (270336 bytes)\r\n*** Preparing to test memory region 7fe918efc000 (63963136 bytes)\r\n*** Preparing to test memory region 7fe91cbfd000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91d3fe000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91dbff000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91e400000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91ec00000 (8388608 bytes)\r\n*** Preparing to test memory region 7fe91f604000 (4096 bytes)\r\n*** Preparing to test memory region 7fe91f7f2000 (57344 bytes)\r\n*** Preparing to test memory region 7fe91fc25000 (12288 bytes)\r\n*** Preparing to test memory region 7fe91fc34000 (24576 bytes)\r\n*** Preparing to test memory region 7fe91fc78000 (8192 bytes)\r\n*** Preparing to test memory region 7fe91fd72000 (8192 bytes)\r\n*** Preparing to test memory region 7fe91feeb000 (4096 bytes)\r\n*** Preparing to test memory region 7fe91ffd8000 (12288 bytes)\r\n.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O\r\nFast memory test PASSED, however your memory can still be broken. Please run a memory test for several hours if possible.\r\n\r\n------ DUMPING CODE AROUND EIP ------\r\nSymbol: (null) (base: (nil))\r\nModule: /lib64/libc.so.6 (base 0x7fe91f605000)\r\n$ xxd -r -p /tmp/dump.hex /tmp/dump.bin\r\n$ objdump --adjust-vma=(nil) -D -b binary -m i386:x86-64 /tmp/dump.bin\r\n------\r\n\r\n=== REDIS BUG REPORT END. Make sure to include from START to END. ===\r\n```"
    },
    {
      "id": 1483222382,
      "user": "darix",
      "created_at": "2023-03-24T18:12:49Z",
      "body": "now running with:\r\n\r\n```\r\ncat get-old-size-calculations.patch \r\ndiff --git a/src/replication.c b/src/replication.c\r\nindex e86aa4b59..2e6f49af3 100644\r\n--- a/src/replication.c\r\n+++ b/src/replication.c\r\n@@ -354,8 +354,11 @@ void feedReplicationBuffer(char *s, size_t len) {\r\n             /* Avoid creating nodes smaller than PROTO_REPLY_CHUNK_BYTES, so that we can append more data into them,\r\n              * and also avoid creating nodes bigger than repl_backlog_size / 16, so that we won't have huge nodes that can't\r\n              * trim when we only still need to hold a small portion from them. */\r\n+            /*\r\n             size_t limit = max((size_t)server.repl_backlog_size / 16, (size_t)PROTO_REPLY_CHUNK_BYTES);\r\n             size_t size = min(max(len, (size_t)PROTO_REPLY_CHUNK_BYTES), limit);\r\n+            */\r\n+            size_t size = (len < PROTO_REPLY_CHUNK_BYTES) ? PROTO_REPLY_CHUNK_BYTES : len;\r\n             tail = zmalloc_usable(size + sizeof(replBufBlock), &usable_size);\r\n             /* Take over the allocation's internal fragmentation */\r\n             tail->size = usable_size - sizeof(replBufBlock);\r\n\r\n```"
    },
    {
      "id": 1483400316,
      "user": "hwware",
      "created_at": "2023-03-24T21:00:00Z",
      "body": "@darix Hi you said this crash happens in a standlone mode redis, could you please under which situation it crash? such as enable RDB, AOF or no persist, or provide us the config parameter?  \r\nBTW, can I understand this crash happen in the openSUSE  platform?\r\n\r\nThanks"
    },
    {
      "id": 1483471256,
      "user": "darix",
      "created_at": "2023-03-24T21:56:35Z",
      "body": "isnt the config part of the crash report output on top?  and yes it is on openSUSE Tumbleweed. but the package is not yet in the main distro only in the devel project so far. https://build.opensuse.org/package/show/server:database/redis\r\n\r\nand the server started crashing during the night. once I switched to the version with the patch above. it is stable again."
    },
    {
      "id": 1484085177,
      "user": "oranagra",
      "created_at": "2023-03-26T12:41:14Z",
      "body": "i was puzzled as to why would memcpy throw a SIGABRT, (and not a SIGSEGV).\r\nfrom looking at the gdb stack trace and sniffing in the code, it seems like some voluntary overflow protection implemented by the toolchain (`__builtin___memcpy_chk` calls ` __glibc_objsize0 (__dest_)`), but i don't think that in our case it can do the right thing (since we over allocate replBufBlock on purpose, and use an allocator that's not the default one).\r\n\r\nmy guess is that for some reason, the change we did in the code caused the compiler to make some wrong assumption, and changing it back avoid that false assumption, when in fact we have no bug.\r\n\r\nmore research is needed.\r\n@tezc @yossigo maybe you have something to add."
    },
    {
      "id": 1484100728,
      "user": "darix",
      "created_at": "2023-03-26T13:41:26Z",
      "body": "1. This is fortify_source in glibc. most linux distributions will have turned this on as it will make the impact of security bugs less severe.\r\n2. as you see above when i changed the size calculation the crash goes away. "
    },
    {
      "id": 1484108117,
      "user": "oranagra",
      "created_at": "2023-03-26T14:11:02Z",
      "body": "you make it sound so simple and clear, but i don't think that's the case.\r\n\r\n1. we haven't seen this problem elsewhere yet, and not in our CI, so i think the it may not be as simple as that (i.e. always fail with fortify_source)\r\n2. reviewing the code, i don't see any miscalculation of the buffer or copy size, and i suspect your change just has some side effect of hiding the problem or confusing the compiler enough to avoid that check). i don't think it solves a bug.\r\n\r\ni'll also add that:\r\n1. if i understand correctly, __glibc_objsize0 returns the size when it is known in compile time (size of a struct), so it looks inappropriate for our case (where we allocate a big buffer, and even query the size of the allocation to make sure of the internal fragmentation).\r\n2. in your specific case it looks related a keys being expired during restart from RDB (arguably rare case), but i suspect that if you simply run the redis test suite you'll see it reproduces quite quickly in many tests."
    },
    {
      "id": 1484294090,
      "user": "darix",
      "created_at": "2023-03-27T00:30:02Z",
      "body": "sadly i do not have the original coredump anymore because redis crashed 557 times before i stopped the auto restart. so i can not tell you what the original crash cause was."
    },
    {
      "id": 1484519164,
      "user": "oranagra",
      "created_at": "2023-03-27T05:27:37Z",
      "body": "@darix can you run the redis test suite on a vanilla 7.0.10 on your system?"
    },
    {
      "id": 1484682643,
      "user": "tezc",
      "created_at": "2023-03-27T08:02:15Z",
      "body": "```c\r\n#include <stdio.h>\r\n#include <malloc.h>\r\n#include <string.h>\r\n\r\nstruct a {\r\n    char c;\r\n    char buf[];\r\n};\r\n\r\nint main() {\r\n    const int BUFSIZE = 5;\r\n\r\n    struct a *a = malloc(sizeof(*a) + BUFSIZE);\r\n    size_t n = malloc_usable_size(a);\r\n    printf(\"usable size: %zu \\n\", n);\r\n\r\n    // Dummy condition to prevent compiler throw warning on compile time\r\n    // n will always be n >= BUFSIZE\r\n    size_t copy = n >= BUFSIZE ? BUFSIZE + 1 : BUFSIZE;\r\n\r\n    memcpy(a->buf, \"ozanozan\", copy);\r\n    printf(\"%.*s \\n\", (int) copy, (char*) a->buf);\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\n```\r\ngcc -D_FORTIFY_SOURCE=1 -O3 main.c \r\n./a.out \r\n\r\nusable size: 24 \r\n*** buffer overflow detected ***: terminated\r\n```\r\n\r\n@oranagra I think your analysis correct. Looks like _FORTIFY_SOURCE=1 works with allocated size, not with \"usable size\". \r\nMaybe we don't have a test to trigger \"memcpy of larger than allocated size\" here so we didn't see this issue before? \r\n\r\n\r\n"
    },
    {
      "id": 1484706589,
      "user": "sundb",
      "created_at": "2023-03-27T08:17:45Z",
      "body": "By disassembling the binary of https://build.opensuse.org/package/show/server:database/redis, we can see that it does use `__memcpy_chk`.\r\n![image](https://user-images.githubusercontent.com/965798/227882092-5b61d99c-5c17-4263-941f-ad7c98084e03.png)"
    },
    {
      "id": 1484849686,
      "user": "sundb",
      "created_at": "2023-03-27T09:57:28Z",
      "body": "Reproduction steps:\r\n1. Install Redis 7.0.10 in openSUSE Tumbleweed (https://software.opensuse.org//download.html?project=server%3Adatabase&package=redis)\r\n\r\n2. Start Redis\r\n```sh\r\n# start redis\r\nSETEX k 3 v\r\n# stop redis and wait for 3 seconds (let redis create backlog due to expiration)\r\n# start redis\r\n```\r\n\r\n4. Feed backlog with various sizes of bigkey\r\n```sh\r\nfor((i=65698;i<=1000000;i++));\r\ndo   \r\ndd if=/dev/zero of=test bs=$i count=1\r\n./src/redis-cli -x set k < test\r\nif [ $? -ne 0 ]; then\r\n    echo \"failed\"\r\n    exit\r\nfi\r\ndone\r\n```"
    },
    {
      "id": 1484879581,
      "user": "oranagra",
      "created_at": "2023-03-27T10:14:46Z",
      "body": "@sundb can you run the redis test suite on that platform and report if it passes or fails?\r\ni did try to run your reproduction on my machine and it passes, so i assume the test suite will fail on openSUSE Tumbleweed.\r\n\r\ni can easily reproduce @tezc example on my Jammy Ubuntu (even without explicitly specifying _FORTIFY_SOURCE), and indeed it seems to use the allocated size (not the usable, and also not the `sizeof(a)`.\r\nso i wonder come come, despite our extensive use of this approach (writing into the extra allocated space, even before 7.0.10), we never saw any problems with this check...\r\n\r\nmy guess is that a newer compiler got \"smarter\" and can remember an allocation size for some cases, whereas if we store it for later and then re-use the allocation, the compiler doesn't do that validation."
    },
    {
      "id": 1484902669,
      "user": "cryptomilk",
      "created_at": "2023-03-27T10:32:36Z",
      "body": "openSUSE Tumbleweed moved to gcc 13 lately."
    },
    {
      "id": 1485016003,
      "user": "darix",
      "created_at": "2023-03-27T11:59:30Z",
      "body": "i just remembered that a lot of debug information is in the log file. so it seems the sigabrt was triggered during a restart and then trying to read some files again.\r\n\r\n```\r\n709:M 23 Mar 2023 11:05:50.030 * Background saving terminated with success\r\n709:signal-handler (1679569569) Received SIGTERM scheduling shutdown...\r\n709:M 23 Mar 2023 11:06:09.724 # User requested shutdown...\r\n709:M 23 Mar 2023 11:06:09.724 * Saving the final RDB snapshot before exiting.\r\n709:M 23 Mar 2023 11:06:10.530 * DB saved on disk\r\n709:M 23 Mar 2023 11:06:10.530 * Removing the pid file.\r\n709:M 23 Mar 2023 11:06:10.531 # Redis is now ready to exit, bye bye...\r\n24352:C 23 Mar 2023 11:06:10.646 * Supervised by systemd. Please make sure you set appropriate values for TimeoutStartSec and TimeoutStopSec in your service unit.\r\n24352:C 23 Mar 2023 11:06:10.646 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\r\n24352:C 23 Mar 2023 11:06:10.646 # Redis version=7.0.10, bits=64, commit=00000000, modified=0, pid=24352, just started\r\n24352:C 23 Mar 2023 11:06:10.646 # Configuration loaded\r\n24352:M 23 Mar 2023 11:06:10.646 * monotonic clock: POSIX clock_gettime\r\n24352:M 23 Mar 2023 11:06:10.647 # Server initialized\r\n24352:M 23 Mar 2023 11:06:10.647 * Loading RDB produced by version 7.0.10\r\n24352:M 23 Mar 2023 11:06:10.648 * RDB age 1 seconds\r\n24352:M 23 Mar 2023 11:06:10.648 * RDB memory usage when created 66.47 Mb\r\n24352:M 23 Mar 2023 11:06:10.882 * Done loading RDB, keys loaded: 34931, keys expired: 39.\r\n24352:M 23 Mar 2023 11:06:10.882 * DB loaded from disk: 0.235 seconds\r\n24352:M 23 Mar 2023 11:06:10.882 * Ready to accept connections\r\n\r\n\r\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\r\n24352:M 23 Mar 2023 11:06:58.981 # Redis 7.0.10 crashed by signal: 6, si_code: -6\r\n24352:M 23 Mar 2023 11:06:58.981 # Crashed running the instruction at: 0x7fa7abe94d7c\r\n\r\n------ STACK TRACE ------\r\nEIP:\r\n/lib64/libc.so.6(+0x8fd7c)[0x7fa7abe94d7c]\r\n\r\nBacktrace:\r\n/lib64/libc.so.6(+0x3e420)[0x7fa7abe43420]\r\n/lib64/libc.so.6(+0x8fd7c)[0x7fa7abe94d7c]\r\n/lib64/libc.so.6(gsignal+0x18)[0x7fa7abe43356]\r\n/lib64/libc.so.6(abort+0xd9)[0x7fa7abe2b897]\r\n/lib64/libc.so.6(+0x27611)[0x7fa7abe2c611]\r\n/lib64/libc.so.6(+0x125e9b)[0x7fa7abf2ae9b]\r\n/lib64/libc.so.6(+0x124316)[0x7fa7abf29316]\r\n/usr/sbin/redis-server 127.0.0.1:6379(+0xbaa79)[0x563ca5071a79]\r\n/usr/sbin/redis-server 127.0.0.1:6379(feedReplicationBufferWithObject+0xa2)[0x563ca5071e32]\r\n/usr/sbin/redis-server 127.0.0.1:6379(replicationFeedSlaves+0x19c)[0x563ca507208c]\r\n/usr/sbin/redis-server 127.0.0.1:6379(propagatePendingCommands+0xfe)[0x563ca503e14e]\r\n/usr/sbin/redis-server 127.0.0.1:6379(call+0x6a7)[0x563ca503e8e7]\r\n/usr/sbin/redis-server 127.0.0.1:6379(processCommand+0x81d)[0x563ca503f4ad]\r\n/usr/sbin/redis-server 127.0.0.1:6379(processInputBuffer+0xeb)[0x563ca5058eeb]\r\n/usr/sbin/redis-server 127.0.0.1:6379(readQueryFromClient+0x2d8)[0x563ca50593a8]\r\n/usr/sbin/redis-server 127.0.0.1:6379(+0x173d53)[0x563ca512ad53]\r\n/usr/sbin/redis-server 127.0.0.1:6379(+0x7e148)[0x563ca5035148]\r\n/usr/sbin/redis-server 127.0.0.1:6379(aeMain+0x1d)[0x563ca503552d]\r\n/usr/sbin/redis-server 127.0.0.1:6379(main+0x352)[0x563ca502d662]\r\n/lib64/libc.so.6(+0x27bb0)[0x7fa7abe2cbb0]\r\n/lib64/libc.so.6(__libc_start_main+0x8b)[0x7fa7abe2cc79]\r\n/usr/sbin/redis-server 127.0.0.1:6379(_start+0x25)[0x563ca502dd35]\r\n```"
    },
    {
      "id": 1485022092,
      "user": "tezc",
      "created_at": "2023-03-27T12:03:18Z",
      "body": "```c\r\n#include <stdio.h>\r\n#include <malloc.h>\r\n#include <string.h>\r\n\r\nstruct a {\r\n    char c;\r\n    char buf[];\r\n};\r\n\r\nvoid* test()\r\n{\r\n    const int BUFSIZE = 5;\r\n    struct a *a = malloc(sizeof(*a) + BUFSIZE);\r\n    size_t n = malloc_usable_size(a);\r\n    printf(\"usable size: %zu \\n\", n);\r\n\r\n    return a;\r\n}\r\n\r\nint main() {\r\n    struct a *a = test();\r\n\r\n    memcpy(a->buf, \"ozanozan\", 6);\r\n    printf(\"%.*s \\n\", (int) 6, (char*) a->buf);\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\nI think compiler won't ever store allocation size on heap for these checks. If allocation & usage happens in the same stack (as it happens here in replication.c), it can perform this analysis without using heap. Maybe this is the new thing in the latest gcc. \r\nSo, for example, the above example won't abort on my local. (Adding -flto  to compile flags will make it abort, I guess because -flto inlines the function and then fortify stuff can inject its checks)  \r\n"
    },
    {
      "id": 1485023830,
      "user": "marxin",
      "created_at": "2023-03-27T12:04:20Z",
      "body": "Hey guys, here is a GCC developer. Yes, it's a known issue that _FORTIFY_SOURCE does not work with `malloc_usable_size`."
    },
    {
      "id": 1485025325,
      "user": "marxin",
      "created_at": "2023-03-27T12:05:12Z",
      "body": "Here is an intensive discussion with the fortification developer and systemd project where they also use it:\r\nhttps://github.com/systemd/systemd/issues/22801."
    },
    {
      "id": 1485025394,
      "user": "darix",
      "created_at": "2023-03-27T12:05:15Z",
      "body": "For the sake of easier testing:\r\n\r\n```\r\n'CFLAGS=-O2 -Wall -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=3 -fstack-protector-strong -funwind-tables -fasynchronous-unwind-tables -fstack-clash-protection -Werror=return-type -flto=auto -g'\r\n```"
    },
    {
      "id": 1485027274,
      "user": "sundb",
      "created_at": "2023-03-27T12:06:18Z",
      "body": "@oranagra test suite also failed.\r\n\r\n```\r\n[exception]: Executing test client: I/O error reading reply.\r\nI/O error reading reply\r\n    while executing\r\n\"[srv $level \"client\"] {*}$args\"\r\n    (procedure \"r\" line 7)\r\n    invoked from within\r\n\"r set key [string repeat A 100000] \"\r\n    (\"uplevel\" body line 3)\r\n    invoked from within\r\n\"uplevel 1 $code\"\r\n    (procedure \"test\" line 51)\r\n    invoked from within\r\n\"test {trim on SET with big value} {\r\n        # set a big value to trigger increasing the query buf\r\n        r set key [string repeat A 100000] \r\n        ...\"\r\n    (\"uplevel\" body line 480)\r\n    invoked from within\r\n\"uplevel 2 $code\"\r\n    (procedure \"run_external_server_test\" line 41)\r\n    invoked from within\r\n\"run_external_server_test $code $overrides\"\r\n    (procedure \"start_server\" line 55)\r\n    invoked from within\r\n\"start_server {tags {\"string\"}} {\r\n    test {SET and GET an item} {\r\n        r set x foobar\r\n        r get x\r\n    } {foobar}\r\n\r\n    test {SET and GET an empt...\"\r\n    (file \"tests/unit/type/string.tcl\" line 1)\r\n    invoked from within\r\n\"source $path\"\r\n    (procedure \"execute_test_file\" line 4)\r\n    invoked from within\r\n\"execute_test_file $data\"\r\n    (procedure \"test_client_main\" line 10)\r\n    invoked from within\r\n\"test_client_main $::test_server_port \"\r\n```\r\n\r\n```\r\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\r\n14921:M 27 Mar 2023 19:54:59.302 # Redis 7.0.10 crashed by signal: 6, si_code: -6\r\n14921:M 27 Mar 2023 19:54:59.302 # Crashed running the instruction at: 0x7f9b79e94d7c\r\n\r\n------ STACK TRACE ------\r\nEIP:\r\n/lib64/libc.so.6(+0x8fd7c)[0x7f9b79e94d7c]\r\n\r\nBacktrace:\r\n/lib64/libc.so.6(+0x3e420)[0x7f9b79e43420]\r\n/lib64/libc.so.6(+0x8fd7c)[0x7f9b79e94d7c]\r\n/lib64/libc.so.6(gsignal+0x18)[0x7f9b79e43356]\r\n/lib64/libc.so.6(abort+0xd9)[0x7f9b79e2b897]\r\n/lib64/libc.so.6(+0x27611)[0x7f9b79e2c611]\r\n/lib64/libc.so.6(+0x125e9b)[0x7f9b79f2ae9b]\r\n/lib64/libc.so.6(+0x124316)[0x7f9b79f29316]\r\n./src/redis-server 127.0.0.1:6379(+0xbaa79)[0x55e585223a79]\r\n./src/redis-server 127.0.0.1:6379(feedReplicationBufferWithObject+0xa2)[0x55e585223e32]\r\n./src/redis-server 127.0.0.1:6379(replicationFeedSlaves+0x19c)[0x55e58522408c]\r\n./src/redis-server 127.0.0.1:6379(propagatePendingCommands+0xfe)[0x55e5851f014e]\r\n./src/redis-server 127.0.0.1:6379(call+0x6a7)[0x55e5851f08e7]\r\n./src/redis-server 127.0.0.1:6379(processCommand+0x81d)[0x55e5851f14ad]\r\n./src/redis-server 127.0.0.1:6379(processInputBuffer+0xeb)[0x55e58520aeeb]\r\n./src/redis-server 127.0.0.1:6379(readQueryFromClient+0x2d8)[0x55e58520b3a8]\r\n./src/redis-server 127.0.0.1:6379(+0x173d53)[0x55e5852dcd53]\r\n./src/redis-server 127.0.0.1:6379(+0x7e148)[0x55e5851e7148]\r\n./src/redis-server 127.0.0.1:6379(aeMain+0x1d)[0x55e5851e752d]\r\n./src/redis-server 127.0.0.1:6379(main+0x352)[0x55e5851df662]\r\n/lib64/libc.so.6(+0x27bb0)[0x7f9b79e2cbb0]\r\n/lib64/libc.so.6(__libc_start_main+0x8b)[0x7f9b79e2cc79]\r\n./src/redis-server 127.0.0.1:6379(_start+0x25)[0x55e5851dfd35]\r\n\r\n------ REGISTERS ------\r\n14921:M 27 Mar 2023 19:54:59.303 # \r\nRAX:0000000000000000 RBX:0000000000003a49\r\nRCX:00007f9b79e94d7c RDX:0000000000000006\r\nRDI:0000000000003a49 RSI:0000000000003a49\r\nRBP:00007f9b7a41a040 RSP:00007fff51b31430\r\nR8 :00000000ffffffff R9 :0000000000000000\r\nR10:0000000000000008 R11:0000000000000246\r\nR12:00007f9b7a7a5000 R13:0000000000000006\r\nR14:0000000000001000 R15:00007f9b79fb02ef\r\nRIP:00007f9b79e94d7c EFL:0000000000000246\r\nCSGSFS:002b000000000033\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b3143f) -> 000055e5853730b9\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b3143e) -> 00007fff51b315c7\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b3143d) -> 0000000000000030\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b3143c) -> 0000000000000000\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b3143b) -> 0000000000000040\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b3143a) -> 0000000000000020\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31439) -> 00007f9b79e2b897\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31438) -> 00007f9b79ff2430\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31437) -> 00007f9b79e43356\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31436) -> 0000000000001000\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31435) -> 00007fff51b31570\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31434) -> 00007f9b7a7a5000\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31433) -> 00007f9b7a41a040\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31432) -> 0000000000000006\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31431) -> 0183a3ec6e879b00\r\n14921:M 27 Mar 2023 19:54:59.303 # (00007fff51b31430) -> 00007f9b79a032e8\r\n\r\n------ INFO OUTPUT ------\r\n# Server\r\nredis_version:7.0.10\r\nredis_git_sha1:00000000\r\nredis_git_dirty:0\r\nredis_build_id:ce21150194f99eee\r\nredis_mode:standalone\r\nos:Linux 6.2.6-1-default x86_64\r\narch_bits:64\r\nmonotonic_clock:POSIX clock_gettime\r\nmultiplexing_api:epoll\r\natomicvar_api:c11-builtin\r\ngcc_version:13.0.1\r\nprocess_id:14921\r\nprocess_supervised:no\r\nrun_id:de6f9de26153a322a4978d312f23bc8e21dfd184\r\ntcp_port:6379\r\nserver_time_usec:1679918099302699\r\nuptime_in_seconds:35\r\nuptime_in_days:0\r\nhz:10\r\nconfigured_hz:10\r\nlru_clock:2196499\r\nexecutable:/home/sundb/redis/./src/redis-server\r\nconfig_file:/home/sundb/redis/redis.conf\r\nio_threads_active:0\r\n\r\n# Clients\r\nconnected_clients:1\r\ncluster_connections:0\r\nmaxclients:10000\r\nclient_recent_max_input_buffer:20480\r\nclient_recent_max_output_buffer:0\r\nblocked_clients:0\r\ntracking_clients:0\r\nclients_in_timeout_table:0\r\n\r\n# Memory\r\nused_memory:3409408\r\nused_memory_human:3.25M\r\nused_memory_rss:17129472\r\nused_memory_rss_human:16.34M\r\nused_memory_peak:34617064\r\nused_memory_peak_human:33.01M\r\nused_memory_peak_perc:9.85%\r\nused_memory_overhead:1459588\r\nused_memory_startup:862328\r\nused_memory_dataset:1949820\r\nused_memory_dataset_perc:76.55%\r\nallocator_allocated:3136952\r\nallocator_active:4173824\r\nallocator_resident:8216576\r\ntotal_system_memory:8316571648\r\ntotal_system_memory_human:7.75G\r\nused_memory_lua:31744\r\nused_memory_vm_eval:31744\r\nused_memory_lua_human:31.00K\r\nused_memory_scripts_eval:0\r\nnumber_of_cached_scripts:0\r\nnumber_of_functions:0\r\nnumber_of_libraries:0\r\nused_memory_vm_functions:32768\r\nused_memory_vm_total:64512\r\nused_memory_vm_total_human:63.00K\r\nused_memory_functions:184\r\nused_memory_scripts:184\r\nused_memory_scripts_human:184B\r\nmaxmemory:0\r\nmaxmemory_human:0B\r\nmaxmemory_policy:noeviction\r\nallocator_frag_ratio:1.33\r\nallocator_frag_bytes:1036872\r\nallocator_rss_ratio:1.97\r\nallocator_rss_bytes:4042752\r\nrss_overhead_ratio:2.08\r\nrss_overhead_bytes:8912896\r\nmem_fragmentation_ratio:5.54\r\nmem_fragmentation_bytes:14038000\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:574116\r\nmem_total_replication_buffers:574112\r\nmem_clients_slaves:0\r\nmem_clients_normal:22272\r\nmem_cluster_links:0\r\nmem_aof_buffer:0\r\nmem_allocator:jemalloc-5.2.1\r\nactive_defrag_running:0\r\nlazyfree_pending_objects:0\r\nlazyfreed_objects:0\r\n\r\n# Persistence\r\nloading:0\r\nasync_loading:0\r\ncurrent_cow_peak:0\r\ncurrent_cow_size:0\r\ncurrent_cow_size_age:0\r\ncurrent_fork_perc:0.00\r\ncurrent_save_keys_processed:0\r\ncurrent_save_keys_total:0\r\nrdb_changes_since_last_save:22069\r\nrdb_bgsave_in_progress:0\r\nrdb_last_save_time:1679918098\r\nrdb_last_bgsave_status:ok\r\nrdb_last_bgsave_time_sec:0\r\nrdb_current_bgsave_time_sec:-1\r\nrdb_saves:2\r\nrdb_last_cow_size:761856\r\nrdb_last_load_keys_expired:0\r\nrdb_last_load_keys_loaded:1\r\naof_enabled:0\r\naof_rewrite_in_progress:0\r\naof_rewrite_scheduled:0\r\naof_last_rewrite_time_sec:-1\r\naof_current_rewrite_time_sec:-1\r\naof_last_bgrewrite_status:ok\r\naof_rewrites:0\r\naof_rewrites_consecutive_failures:0\r\naof_last_write_status:ok\r\naof_last_cow_size:0\r\nmodule_fork_in_progress:0\r\nmodule_fork_last_cow_size:0\r\n\r\n# Stats\r\ntotal_connections_received:199\r\ntotal_commands_processed:102586\r\ninstantaneous_ops_per_sec:3867\r\ntotal_net_input_bytes:33979463\r\ntotal_net_output_bytes:255961332\r\ntotal_net_repl_input_bytes:0\r\ntotal_net_repl_output_bytes:637794\r\ninstantaneous_input_kbps:429.31\r\ninstantaneous_output_kbps:757.18\r\ninstantaneous_input_repl_kbps:0.00\r\ninstantaneous_output_repl_kbps:383.53\r\nrejected_connections:0\r\nsync_full:2\r\nsync_partial_ok:0\r\nsync_partial_err:0\r\nexpired_keys:2\r\nexpired_stale_perc:0.00\r\nexpired_time_cap_reached_count:0\r\nexpire_cycle_cpu_milliseconds:0\r\nevicted_keys:0\r\nevicted_clients:0\r\ntotal_eviction_exceeded_time:0\r\ncurrent_eviction_exceeded_time:0\r\nkeyspace_hits:19096\r\nkeyspace_misses:27\r\npubsub_channels:0\r\npubsub_patterns:0\r\npubsubshard_channels:0\r\nlatest_fork_usec:322\r\ntotal_forks:2\r\nmigrate_cached_sockets:0\r\nslave_expires_tracked_keys:0\r\nactive_defrag_hits:0\r\nactive_defrag_misses:0\r\nactive_defrag_key_hits:0\r\nactive_defrag_key_misses:0\r\ntotal_active_defrag_time:0\r\ncurrent_active_defrag_time:0\r\ntracking_total_keys:0\r\ntracking_total_items:0\r\ntracking_total_prefixes:0\r\nunexpected_error_replies:0\r\ntotal_error_replies:34\r\ndump_payload_sanitizations:0\r\ntotal_reads_processed:105695\r\ntotal_writes_processed:101880\r\nio_threaded_reads_processed:0\r\nio_threaded_writes_processed:0\r\nreply_buffer_shrinks:5\r\nreply_buffer_expands:4\r\n\r\n# Replication\r\nrole:master\r\nconnected_slaves:0\r\nmaster_failover_state:no-failover\r\nmaster_replid:f1ce9033f8b3adab3f701cf02d643bef8b689bab\r\nmaster_replid2:0000000000000000000000000000000000000000\r\nmaster_repl_offset:572320\r\nsecond_repl_offset:-1\r\nrepl_backlog_active:1\r\nrepl_backlog_size:1048576\r\nrepl_backlog_first_byte_offset:1\r\nrepl_backlog_histlen:572320\r\n\r\n# CPU\r\nused_cpu_sys:3.439076\r\nused_cpu_user:0.097839\r\nused_cpu_sys_children:0.014915\r\nused_cpu_user_children:0.008735\r\nused_cpu_sys_main_thread:3.437728\r\nused_cpu_user_main_thread:0.097557\r\n\r\n# Modules\r\n\r\n# Commandstats\r\ncmdstat_pttl:calls=5,usec=4,usec_per_call=0.80,rejected_calls=0,failed_calls=0\r\ncmdstat_set:calls=15453,usec=20013,usec_per_call=1.30,rejected_calls=0,failed_calls=0\r\ncmdstat_blpop:calls=2,usec=14,usec_per_call=7.00,rejected_calls=0,failed_calls=0\r\ncmdstat_getdel:calls=3,usec=8,usec_per_call=2.67,rejected_calls=0,failed_calls=0\r\ncmdstat_mset:calls=4,usec=710,usec_per_call=177.50,rejected_calls=0,failed_calls=1\r\ncmdstat_get:calls=13061,usec=33468,usec_per_call=2.56,rejected_calls=0,failed_calls=0\r\ncmdstat_rename:calls=8,usec=16,usec_per_call=2.00,rejected_calls=0,failed_calls=2\r\ncmdstat_zscan:calls=99,usec=1738,usec_per_call=17.56,rejected_calls=0,failed_calls=0\r\ncmdstat_move:calls=5,usec=7,usec_per_call=1.40,rejected_calls=0,failed_calls=1\r\ncmdstat_getex:calls=9,usec=33,usec_per_call=3.67,rejected_calls=1,failed_calls=1\r\ncmdstat_xreadgroup:calls=5,usec=43,usec_per_call=8.60,rejected_calls=0,failed_calls=0\r\ncmdstat_srem:calls=93,usec=4215,usec_per_call=45.32,rejected_calls=0,failed_calls=0\r\ncmdstat_xinfo|stream:calls=3,usec=45,usec_per_call=15.00,rejected_calls=0,failed_calls=0\r\ncmdstat_dump:calls=10,usec=32,usec_per_call=3.20,rejected_calls=0,failed_calls=0\r\ncmdstat_object|freq:calls=1,usec=1,usec_per_call=1.00,rejected_calls=0,failed_calls=0\r\ncmdstat_object|encoding:calls=27,usec=35,usec_per_call=1.30,rejected_calls=0,failed_calls=0\r\ncmdstat_object|idletime:calls=1,usec=2,usec_per_call=2.00,rejected_calls=0,failed_calls=0\r\ncmdstat_object|refcount:calls=18,usec=11,usec_per_call=0.61,rejected_calls=0,failed_calls=0\r\ncmdstat_hmset:calls=3,usec=1120,usec_per_call=373.33,rejected_calls=0,failed_calls=0\r\ncmdstat_select:calls=49,usec=34,usec_per_call=0.69,rejected_calls=0,failed_calls=0\r\ncmdstat_hello:calls=9,usec=17,usec_per_call=1.89,rejected_calls=0,failed_calls=0\r\ncmdstat_strlen:calls=3,usec=3,usec_per_call=1.00,rejected_calls=0,failed_calls=0\r\ncmdstat_rpush:calls=2,usec=7,usec_per_call=3.50,rejected_calls=0,failed_calls=0\r\ncmdstat_hscan:calls=98,usec=774,usec_per_call=7.90,rejected_calls=0,failed_calls=0\r\ncmdstat_getrange:calls=1013,usec=843,usec_per_call=0.83,rejected_calls=0,failed_calls=0\r\ncmdstat_restore:calls=11,usec=30,usec_per_call=2.73,rejected_calls=0,failed_calls=2\r\ncmdstat_info:calls=13,usec=1151,usec_per_call=88.54,rejected_calls=0,failed_calls=0\r\ncmdstat_multi:calls=1,usec=0,usec_per_call=0.00,rejected_calls=0,failed_calls=0\r\ncmdstat_sync:calls=2,usec=947,usec_per_call=473.50,rejected_calls=0,failed_calls=0\r\ncmdstat_getbit:calls=15,usec=22,usec_per_call=1.47,rejected_calls=0,failed_calls=0\r\ncmdstat_ping:calls=7,usec=6,usec_per_call=0.86,rejected_calls=0,failed_calls=1\r\ncmdstat_hset:calls=65,usec=93,usec_per_call=1.43,rejected_calls=0,failed_calls=0\r\ncmdstat_del:calls=182,usec=1280,usec_per_call=7.03,rejected_calls=0,failed_calls=0\r\ncmdstat_sscan:calls=1672,usec=7346,usec_per_call=4.39,rejected_calls=0,failed_calls=0\r\ncmdstat_randomkey:calls=102,usec=76,usec_per_call=0.75,rejected_calls=0,failed_calls=0\r\ncmdstat_setbit:calls=2012,usec=1762,usec_per_call=0.88,rejected_calls=0,failed_calls=7\r\ncmdstat_xadd:calls=1006,usec=2304,usec_per_call=2.29,rejected_calls=0,failed_calls=0\r\ncmdstat_ttl:calls=21,usec=26,usec_per_call=1.24,rejected_calls=0,failed_calls=0\r\ncmdstat_incrbyfloat:calls=2,usec=18,usec_per_call=9.00,rejected_calls=0,failed_calls=0\r\ncmdstat_config|set:calls=16,usec=43,usec_per_call=2.69,rejected_calls=0,failed_calls=0\r\ncmdstat_config|get:calls=4,usec=17,usec_per_call=4.25,rejected_calls=0,failed_calls=0\r\ncmdstat_xdel:calls=1,usec=3,usec_per_call=3.00,rejected_calls=0,failed_calls=0\r\ncmdstat_exec:calls=1,usec=7,usec_per_call=7.00,rejected_calls=0,failed_calls=0\r\ncmdstat_function|flush:calls=8,usec=16,usec_per_call=2.00,rejected_calls=0,failed_calls=0\r\ncmdstat_flushdb:calls=19,usec=4778,usec_per_call=251.47,rejected_calls=0,failed_calls=0\r\ncmdstat_dbsize:calls=9,usec=4,usec_per_call=0.44,rejected_calls=0,failed_calls=0\r\ncmdstat_scan:calls=680,usec=2431,usec_per_call=3.58,rejected_calls=0,failed_calls=0\r\ncmdstat_getset:calls=2,usec=8,usec_per_call=4.00,rejected_calls=0,failed_calls=0\r\ncmdstat_setrange:calls=15,usec=38,usec_per_call=2.53,rejected_calls=0,failed_calls=4\r\ncmdstat_substr:calls=3,usec=4,usec_per_call=1.33,rejected_calls=0,failed_calls=0\r\ncmdstat_setnx:calls=4,usec=34,usec_per_call=8.50,rejected_calls=0,failed_calls=0\r\ncmdstat_setex:calls=10000,usec=23563,usec_per_call=2.36,rejected_calls=0,failed_calls=0\r\ncmdstat_copy:calls=17,usec=98,usec_per_call=5.76,rejected_calls=0,failed_calls=1\r\ncmdstat_xgroup|setid:calls=1,usec=1,usec_per_call=1.00,rejected_calls=0,failed_calls=0\r\ncmdstat_xgroup|create:calls=2,usec=5,usec_per_call=2.50,rejected_calls=0,failed_calls=0\r\ncmdstat_flushall:calls=8,usec=14000,usec_per_call=1750.00,rejected_calls=0,failed_calls=0\r\ncmdstat_lpush:calls=4,usec=24,usec_per_call=6.00,rejected_calls=0,failed_calls=0\r\ncmdstat_keys:calls=8,usec=19,usec_per_call=2.38,rejected_calls=0,failed_calls=0\r\ncmdstat_renamenx:calls=3,usec=3,usec_per_call=1.00,rejected_calls=0,failed_calls=0\r\ncmdstat_sadd:calls=55815,usec=61813,usec_per_call=1.11,rejected_calls=0,failed_calls=0\r\ncmdstat_expire:calls=4,usec=11,usec_per_call=2.75,rejected_calls=0,failed_calls=0\r\ncmdstat_srandmember:calls=3,usec=5,usec_per_call=1.67,rejected_calls=0,failed_calls=0\r\ncmdstat_exists:calls=12,usec=7,usec_per_call=0.58,rejected_calls=0,failed_calls=0\r\ncmdstat_debug:calls=207,usec=15679,usec_per_call=75.74,rejected_calls=0,failed_calls=1\r\ncmdstat_mget:calls=6,usec=29,usec_per_call=4.83,rejected_calls=0,failed_calls=0\r\ncmdstat_msetnx:calls=5,usec=19,usec_per_call=3.80,rejected_calls=0,failed_calls=1\r\ncmdstat_zadd:calls=634,usec=4864,usec_per_call=7.67,rejected_calls=0,failed_calls=0\r\n\r\n# Errorstats\r\nerrorstat_BUSYKEY:count=1\r\nerrorstat_ERR:count=31\r\nerrorstat_WRONGTYPE:count=2\r\n\r\n# Latencystats\r\nlatency_percentiles_usec_pttl:p50=1.003,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_set:p50=1.003,p99=6.015,p99.9=16.063\r\nlatency_percentiles_usec_blpop:p50=2.007,p99=7.007,p99.9=7.007\r\nlatency_percentiles_usec_getdel:p50=3.007,p99=4.015,p99.9=4.015\r\nlatency_percentiles_usec_mset:p50=8.031,p99=692.223,p99.9=692.223\r\nlatency_percentiles_usec_get:p50=1.003,p99=34.047,p99.9=69.119\r\nlatency_percentiles_usec_rename:p50=2.007,p99=4.015,p99.9=4.015\r\nlatency_percentiles_usec_zscan:p50=15.039,p99=66.047,p99.9=71.167\r\nlatency_percentiles_usec_move:p50=1.003,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_getex:p50=2.007,p99=17.023,p99.9=17.023\r\nlatency_percentiles_usec_xreadgroup:p50=8.031,p99=12.031,p99.9=12.031\r\nlatency_percentiles_usec_srem:p50=55.039,p99=101.375,p99.9=103.423\r\nlatency_percentiles_usec_xinfo|stream:p50=15.039,p99=17.023,p99.9=17.023\r\nlatency_percentiles_usec_dump:p50=3.007,p99=5.023,p99.9=5.023\r\nlatency_percentiles_usec_object|freq:p50=1.003,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_object|encoding:p50=1.003,p99=2.007,p99.9=2.007\r\nlatency_percentiles_usec_object|idletime:p50=2.007,p99=2.007,p99.9=2.007\r\nlatency_percentiles_usec_object|refcount:p50=1.003,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_hmset:p50=14.015,p99=1097.727,p99.9=1097.727\r\nlatency_percentiles_usec_select:p50=1.003,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_hello:p50=2.007,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_strlen:p50=1.003,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_rpush:p50=3.007,p99=4.015,p99.9=4.015\r\nlatency_percentiles_usec_hscan:p50=7.007,p99=20.095,p99.9=22.015\r\nlatency_percentiles_usec_getrange:p50=1.003,p99=2.007,p99.9=3.007\r\nlatency_percentiles_usec_restore:p50=3.007,p99=4.015,p99.9=4.015\r\nlatency_percentiles_usec_info:p50=46.079,p99=335.871,p99.9=335.871\r\nlatency_percentiles_usec_multi:p50=0.001,p99=0.001,p99.9=0.001\r\nlatency_percentiles_usec_sync:p50=417.791,p99=532.479,p99.9=532.479\r\nlatency_percentiles_usec_getbit:p50=1.003,p99=10.047,p99.9=10.047\r\nlatency_percentiles_usec_ping:p50=1.003,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_hset:p50=1.003,p99=3.007,p99.9=4.015\r\nlatency_percentiles_usec_del:p50=7.007,p99=30.079,p99.9=48.127\r\nlatency_percentiles_usec_sscan:p50=4.015,p99=11.007,p99.9=19.071\r\nlatency_percentiles_usec_randomkey:p50=1.003,p99=2.007,p99.9=2.007\r\nlatency_percentiles_usec_setbit:p50=1.003,p99=2.007,p99.9=10.047\r\nlatency_percentiles_usec_xadd:p50=2.007,p99=5.023,p99.9=17.023\r\nlatency_percentiles_usec_ttl:p50=1.003,p99=2.007,p99.9=2.007\r\nlatency_percentiles_usec_incrbyfloat:p50=6.015,p99=12.031,p99.9=12.031\r\nlatency_percentiles_usec_config|set:p50=3.007,p99=5.023,p99.9=5.023\r\nlatency_percentiles_usec_config|get:p50=3.007,p99=9.023,p99.9=9.023\r\nlatency_percentiles_usec_xdel:p50=3.007,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_exec:p50=7.007,p99=7.007,p99.9=7.007\r\nlatency_percentiles_usec_function|flush:p50=2.007,p99=4.015,p99.9=4.015\r\nlatency_percentiles_usec_flushdb:p50=43.007,p99=2424.831,p99.9=2424.831\r\nlatency_percentiles_usec_dbsize:p50=0.001,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_scan:p50=3.007,p99=9.023,p99.9=16.063\r\nlatency_percentiles_usec_getset:p50=2.007,p99=6.015,p99.9=6.015\r\nlatency_percentiles_usec_setrange:p50=2.007,p99=10.047,p99.9=10.047\r\nlatency_percentiles_usec_substr:p50=1.003,p99=2.007,p99.9=2.007\r\nlatency_percentiles_usec_setnx:p50=1.003,p99=29.055,p99.9=29.055\r\nlatency_percentiles_usec_setex:p50=2.007,p99=10.047,p99.9=18.047\r\nlatency_percentiles_usec_copy:p50=3.007,p99=17.023,p99.9=17.023\r\nlatency_percentiles_usec_xgroup|setid:p50=1.003,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_xgroup|create:p50=2.007,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_flushall:p50=1196.031,p99=3571.711,p99.9=3571.711\r\nlatency_percentiles_usec_lpush:p50=5.023,p99=10.047,p99.9=10.047\r\nlatency_percentiles_usec_keys:p50=2.007,p99=4.015,p99.9=4.015\r\nlatency_percentiles_usec_renamenx:p50=1.003,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_sadd:p50=1.003,p99=3.007,p99.9=11.007\r\nlatency_percentiles_usec_expire:p50=3.007,p99=3.007,p99.9=3.007\r\nlatency_percentiles_usec_srandmember:p50=2.007,p99=2.007,p99.9=2.007\r\nlatency_percentiles_usec_exists:p50=1.003,p99=1.003,p99.9=1.003\r\nlatency_percentiles_usec_debug:p50=22.015,p99=3506.175,p99.9=3555.327\r\nlatency_percentiles_usec_mget:p50=2.007,p99=20.095,p99.9=20.095\r\nlatency_percentiles_usec_msetnx:p50=2.007,p99=10.047,p99.9=10.047\r\nlatency_percentiles_usec_zadd:p50=4.015,p99=33.023,p99.9=78.335\r\n\r\n# Cluster\r\ncluster_enabled:0\r\n\r\n# Keyspace\r\ndb9:keys=14,expires=0,avg_ttl=0\r\n\r\n------ CLIENT LIST OUTPUT ------\r\nid=143 addr=127.0.0.1:43419 laddr=127.0.0.1:6379 fd=8 name= age=8 idle=0 flags=N db=9 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=114678 argv-mem=100006 multi-mem=0 rbs=1024 rbp=1024 obl=5 oll=0 omem=0 tot-mem=216510 events=r cmd=set user=default redir=-1 resp=2\r\n\r\n------ CURRENT CLIENT INFO ------\r\nid=143 addr=127.0.0.1:43419 laddr=127.0.0.1:6379 fd=8 name= age=8 idle=0 flags=N db=9 sub=0 psub=0 ssub=0 multi=-1 qbuf=0 qbuf-free=114678 argv-mem=100006 multi-mem=0 rbs=1024 rbp=1024 obl=5 oll=0 omem=0 tot-mem=216510 events=r cmd=set user=default redir=-1 resp=2\r\nargv[0]: '\"set\"'\r\nargv[1]: '\"key\"'\r\nargv[2]: '\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\"'\r\n14921:M 27 Mar 2023 19:54:59.304 # key 'key' found in DB containing the following object:\r\n14921:M 27 Mar 2023 19:54:59.304 # Object type: 0\r\n14921:M 27 Mar 2023 19:54:59.304 # Object encoding: 0\r\n14921:M 27 Mar 2023 19:54:59.304 # Object refcount: 3\r\n\r\n------ MODULES INFO OUTPUT ------\r\n\r\n------ CONFIG DEBUG OUTPUT ------\r\nslave-read-only yes\r\nreplica-read-only yes\r\nio-threads-do-reads no\r\nlazyfree-lazy-expire no\r\nproto-max-bulk-len 512mb\r\nlazyfree-lazy-user-del no\r\nrepl-diskless-load disabled\r\nrepl-diskless-sync yes\r\nclient-query-buffer-limit 1gb\r\nsanitize-dump-payload no\r\nactivedefrag no\r\nlist-compress-depth 0\r\nio-threads 1\r\nlazyfree-lazy-eviction no\r\nlazyfree-lazy-server-del no\r\nlazyfree-lazy-user-flush no\r\n\r\n------ FAST MEMORY TEST ------\r\n14921:M 27 Mar 2023 19:54:59.305 # Bio thread for job type #0 terminated\r\n14921:M 27 Mar 2023 19:54:59.305 # Bio thread for job type #1 terminated\r\n14921:M 27 Mar 2023 19:54:59.305 # Bio thread for job type #2 terminated\r\n*** Preparing to test memory region 55e58548c000 (2306048 bytes)\r\n*** Preparing to test memory region 55e5857e2000 (270336 bytes)\r\n*** Preparing to test memory region 7f9b74d7c000 (40370176 bytes)\r\n*** Preparing to test memory region 7f9b773fd000 (8388608 bytes)\r\n*** Preparing to test memory region 7f9b77bfe000 (8388608 bytes)\r\n*** Preparing to test memory region 7f9b783ff000 (8388608 bytes)\r\n*** Preparing to test memory region 7f9b78c00000 (8388608 bytes)\r\n*** Preparing to test memory region 7f9b79400000 (8388608 bytes)\r\n*** Preparing to test memory region 7f9b79e04000 (4096 bytes)\r\n*** Preparing to test memory region 7f9b79ff2000 (57344 bytes)\r\n*** Preparing to test memory region 7f9b7a411000 (12288 bytes)\r\n*** Preparing to test memory region 7f9b7a418000 (24576 bytes)\r\n*** Preparing to test memory region 7f9b7a442000 (8192 bytes)\r\n*** Preparing to test memory region 7f9b7a533000 (8192 bytes)\r\n*** Preparing to test memory region 7f9b7a6ac000 (4096 bytes)\r\n*** Preparing to test memory region 7f9b7a7a5000 (12288 bytes)\r\n.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O\r\nFast memory test PASSED, however your memory can still be broken. Please run a memory test for several hours if possible.\r\n```"
    },
    {
      "id": 1485036271,
      "user": "marxin",
      "created_at": "2023-03-27T12:12:15Z",
      "body": "CCing glibc maintainer of the functionality: @siddhesh. So basically the function `malloc_usable_size` is a diagnostics function of glibc and should not be used in production:\r\n\r\nhttps://man7.org/linux/man-pages/man3/malloc_usable_size.3.html:\r\n```\r\nNOTES\r\n...\r\n\r\n       The main use of this function is for debugging and introspection.\r\n```"
    },
    {
      "id": 1485655513,
      "user": "siddhesh",
      "created_at": "2023-03-27T18:26:21Z",
      "body": "Thanks @marxin!\r\n\r\nRight, the problem is with the usable size function returning a different value than what is allocated, thus breaking the compiler's assumption that the sizes ought to be the same. We (i.e. the glibc community) have been considering deprecating `malloc_usable_size` because it's being used (and other allocators growing compatible interfaces) for non-diagnostic uses despite it being clearly mentioned as being a diagnostic-only interface.  Accessing the extra memory continues to violate the C standard, so the pattern continues to be unsafe.\r\n\r\nThe reason why redis is running into this now and didn't before is in fact because the compiler now has more fortification coverage with `_FORTIFY_SOURCE=3` and can see this inconsistencies better.\r\n\r\nThe ideal fix for this should be to have the size returned from the allocator be consistent with the requested size, but if that's not possible (as it seems to me from a quick peek at the allocator; it seems to do a lot of things, including wrapping around external allocators), then the fix may be the same as systemd, i.e. to wrap the `zmalloc_usable_size` and `zmalloc_size` calls with a call to a dummy realloc that hints to the compiler that the block is larger.\r\n\r\nSomething like this:\r\n\r\n```\r\nzmalloc.h:\r\n...\r\nextern void *extend_to_usable (void *, size_t) __attribute__((alloc_size, 2)) __attribute__((noinline)) __attribute__((__returns_nonnull__));\r\n\r\n#define zmalloc_size(_p) \\\r\n({ \\\r\n  size_t ret = real_zmalloc_size (_p); \\\r\n  _p = extend_to_usable (p, ret); \\\r\n  ret; \\\r\n})\r\n```\r\n\r\n```\r\nzmalloc.c:\r\n...\r\nvoid *extend_to_usable (void *p, size_t sz __attribute__((unused)))\r\n{\r\n  return p;\r\n}\r\n```\r\n\r\nAlternatively, you could do this during allocation, by extending the `zmalloc` call to `zmalloc() + zmalloc_size() + extend_to_usable()`, likewise for `zcalloc`, `zrealloc`, etc. But I reckon the usable_size hack is easier..."
    },
    {
      "id": 1486374997,
      "user": "oranagra",
      "created_at": "2023-03-28T07:47:07Z",
      "body": "Thanks to all the GCC and glibc developers for stepping in to clear this up.\r\nI think Redis will continue using malloc_usable_size to remain memory efficient, despite violating the standard.\r\n\r\n> i.e. to wrap the zmalloc_usable_size and zmalloc_size calls with a call to a dummy realloc that hints to the compiler that the block is larger\r\n\r\n@siddhesh by dummy realloc you mean actually calling realloc to request the allocation to be resized to the size we already know it has, or did you mean an empty function like in your example above which just returns the pointer blindly?\r\n\r\nplease correct me if i'm wrong, won't that (the second approach) completely disable the fortification checks (the compiler will be completely unaware of the size of the allocation and won't do any checks)? maybe instead we can disable part of the fortification checks?\r\n\r\n@sundb can you try that suggestion to make sure it works and also check if it has any impact on performance?"
    },
    {
      "id": 1486382337,
      "user": "sundb",
      "created_at": "2023-03-28T07:53:08Z",
      "body": "@oranagra I will try it."
    },
    {
      "id": 1486423117,
      "user": "cryptomilk",
      "created_at": "2023-03-28T08:20:58Z",
      "body": "talloc provides functions to get the size of talloc chunk even including children.\r\n\r\n"
    },
    {
      "id": 1486615428,
      "user": "siddhesh",
      "created_at": "2023-03-28T10:36:10Z",
      "body": "> Thanks to all the GCC and glibc developers for stepping in to clear this up.\r\n> I think Redis will continue using malloc_usable_size to remain memory efficient, despite violating the standard.\r\n\r\nSo to be clear, with the workaround I suggested, the code will actually become compliant. However, there's a good chance that glibc will deprecate `malloc_usable_size` in future and maybe provide a different interface to query the usable size in a manner that is safe.\r\n\r\nAlso, the risk is not just limited to such usage being standards-unsafe; there's also no guarantee that the size is consistent.  That is, the underlying allocator is free to grow that chunk at any time, making the return value unstable and actual usage unsafe.  None of the allocator implementations do that at the moment, but there's nothing stopping them from doing that if they find it to be somehow more performant.  That's really what makes it a very bad interface to actually use the extra size.\r\n\r\nThere are [standards discussions](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p0401r6.html) to provide safer interfaces to do something like this, which may be a better fit for the redis (and systemd) use case and the workaround I suggested basically tries to get the usage closer to something like that.\r\n\r\n> @siddhesh by dummy realloc you mean actually calling realloc to request the allocation to be resized to the size we already know it has, or did you mean an empty function like in your example above which just returns the pointer blindly?\r\n\r\nI did mean an empty function like the example I wrote above; I wrote a workaround like that for systemd; see  https://github.com/systemd/systemd/commit/7929e180aa47a2692ad4f053afac2857d7198758 and https://github.com/systemd/systemd/commit/4f79f545b3c46c358666c9f5f2b384fe50aac4b4\r\n\r\n> please correct me if i'm wrong, won't that (the second approach) completely disable the fortification checks (the compiler will be completely unaware of the size of the allocation and won't do any checks)? maybe instead we can disable part of the fortification checks?\r\n\r\nOn the contrary, the compiler will be able to see the new size and do the right thing for your code base.  For the compiler, the code will look like this:\r\n\r\n```\r\nptr = zmalloc (sz); // Compiler sees SZ as the size of PTR.\r\nusable_sz = zmalloc_usable_size (ptr);\r\nptr = extend_to_usable (ptr, usable_sz); // Compiler sees that the size of PTR is now USABLE_SZ\r\nmemcpy (ptr, src, usable_sz);  // Compiler will generate __memcpy_chk (ptr, src, usable_sz, usable_sz) \r\n                               // and then optimize it to memcpy (ptr, src, usable_sz) since it knows\r\n                               // at compile time that the access is safe.\r\n```\r\n\r\n> @sundb can you try that suggestion to make sure it works and also check if it has any impact on performance?\r\n\r\nIf needed, I'll be happy to help with review to verify that it matches what I suggested (I obviously won't be very useful with nuances of the code base), please feel free to tag me into the PR."
    },
    {
      "id": 1486677701,
      "user": "oranagra",
      "created_at": "2023-03-28T11:21:55Z",
      "body": "@siddhesh thank you.\r\ni'm curious to understand why the compiler think the size of `ptr` was changed to `usable_sz`, does it consider the `extend_to_usable` a realloc function? is it just because it's interface it to take a `size_t` and return a `void*`?\r\n\r\nalso, am i correct to understand that extra call will be optimized out and this change have zero impact on our performance?\r\nand that it relies on the fact that the fortification decisions are taken before optimization (for a moment i thought that maybe because we're now using `-flto` the fortification can maybe reach better conclusions than before).\r\n\r\n[Edit] I now see `_noinline_` in the second commit you referred to, so i suppose my above paragraph is wrong, would love to get confirmation / clarification.\r\n\r\n[Edit] i now see the `_alloc_(2)` attribute, so that answers my first question. sorry for missing them in your initial code snippet."
    },
    {
      "id": 1486762871,
      "user": "siddhesh",
      "created_at": "2023-03-28T12:09:41Z",
      "body": "> [Edit] I now see `_noinline_` in the second commit you referred to, so i suppose my above paragraph is wrong, would love to get confirmation / clarification.\r\n\r\nyeah we can't let the function get optimized away yet because gcc (atleast, maybe even clang but I haven't checked) loses attributes whenever a function is inlined, so the `_alloc_(2)` is missed and the compiler no longer sees it as an allocator function and simply optimizes it away.  It's being tracked here: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=96503\r\n\r\nSo the impact is a function call overhead for now, hopefully we'll claw it back soon in gcc with a fix to that bug.\r\n\r\n> [Edit] i now see the `_alloc_(2)` attribute, so that answers my first question. sorry for missing them in your initial code snippet.\r\n\r\nCorrect too :)"
    },
    {
      "id": 1486962565,
      "user": "sundb",
      "created_at": "2023-03-28T14:06:39Z",
      "body": "@siddhesh I tried to make some changes(https://github.com/sundb/redis/commit/19ed6a4f9543ed1091a633167a5232d476aa07d9) in redis, but ran into a strange problem.\r\n\r\nCalling `extend_to_usable()` after `zmalloc_usable()` is fine.\r\n```\r\ntail = zmalloc_usable(size + sizeof(replBufBlock), &usable_size).\r\ntail = extend_to_usable(tail, usable_size); /* gcc can see it */\r\n```\r\n\r\nBut when I move `extend_to_usable()` in to `ztrymalloc_usable()`, gcc doesn't see the new size.\r\n```\r\nzmalloc_usable\r\n    -> ztrymalloc_usable\r\n        -> size = zmalloc_size(ptr).\r\n           ptr = extend_to_usable(ptr, size).\r\n```\r\n\r\nI am not sure what is the right behavior."
    },
    {
      "id": 1486983245,
      "user": "siddhesh",
      "created_at": "2023-03-28T14:17:38Z",
      "body": "Calling extend_to_usable *inside* `ztrymalloc_usable` is not going to work because the function itself is declared with `alloc_size(1)`, indicating that the size of the returned block is argument 1 of the call.\r\n\r\nBasically, the `extend_to_usable` call has to follow all calls to `*_usable` functions with the returned usable size."
    },
    {
      "id": 1487003199,
      "user": "sundb",
      "created_at": "2023-03-28T14:28:50Z",
      "body": "@siddhesh Thanks for your help."
    },
    {
      "id": 1502968380,
      "user": "darix",
      "created_at": "2023-04-11T09:15:08Z",
      "body": "do we have an ETA for the release?"
    },
    {
      "id": 1502974635,
      "user": "oranagra",
      "created_at": "2023-04-11T09:19:16Z",
      "body": "i suppose that since you indicated a recent change is what caused this (old) issue to get exposed, then we should release soon.\r\nstill, i'd like to let the change mature for a while in unstable, considering it's not very small.\r\ni think i'll aim for next week."
    },
    {
      "id": 1506636699,
      "user": "oranagra",
      "created_at": "2023-04-13T09:21:55Z",
      "body": "I noticed that on 7.0.x we didn't have any `alloc_size` attributes in zmalloc.h, and we're also not using `-lto`, so i wonder how come it crashed in the initial report of this issue.\r\nas far as i can tell the Makefile is unmodified.\r\n@siddhesh is gcc 13 able to somehow track these attributes even from other object files?"
    },
    {
      "id": 1506638691,
      "user": "darix",
      "created_at": "2023-04-13T09:23:23Z",
      "body": "distros started to enable -lto via CFLAGS "
    }
  ]
}