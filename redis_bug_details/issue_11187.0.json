{
  "issue_number": 11187.0,
  "title": "[CRASH] Redis server 6.2.6 crashed by signal: 7, si_code: 2",
  "body": "**Crash report**\r\n\r\nPaste the complete crash log between the quotes below. Please include a few lines from the log preceding the crash report to provide some context.\r\n\r\n```\r\n1436:M 24 Aug 2022 06:22:05.613 # Redis 6.2.6 crashed by signal: 7, si_code: 2\r\n61436:M 24 Aug 2022 06:22:05.614 # Accessing address: 0x7f9ad5be2000\r\n61436:M 24 Aug 2022 06:22:05.614 # Crashed running the instruction at: 0x7f9ad5be1fff\r\n191897:C 24 Aug 2022 06:47:41.689 # Write error writing append only file on disk: Connection timed out\r\n\r\n```\r\n\r\n**Additional information**\r\n```\r\n1. OS distribution and version\r\n\r\nuname -a\r\nLinux dc6-cdb-001 3.10.0-1127.el7.x86_64 #1 SMP Tue Mar 31 23:36:51 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n2. core file was dumped. adding the debugger to the core file, it seems the crash occurred in loadAppendOnl;yFile, which seems to get the wrong file name\r\n\r\nCore was generated by `/home/ip/shared/inf/crystal/1.0/63730111/bin/crs --lua_path /home/ip/shared/inf'.\r\nProgram terminated with signal 7, Bus error.\r\n#0  0x0000000000482910 in loadAppendOnlyFile (filename=0x4000000000000000 <Address 0x4000000000000000 out of bounds>) at aof.c:883\r\n883     aof.c: No such file or directory.\r\n(gdb) info threads\r\n  Id   Target Id         Frame \r\n  18   LWP 246709        0x00007f216ae06eb3 in ?? ()\r\n  17   LWP 246716        0x00007f216bbd8de2 in ?? ()\r\n  16   LWP 246720        0x00007f216bbd8de2 in ?? ()\r\n  15   LWP 246715        0x00007f216bbd8de2 in ?? ()\r\n  14   LWP 246707        0x00007f216bbd8a35 in ?? ()\r\n  13   LWP 246708        0x00007f216bbd8a35 in ?? ()\r\n  12   LWP 246705        0x00007f216ad3f58a in ?? ()\r\n  11   LWP 246714        0x00007f216bbd8de2 in ?? ()\r\n  10   LWP 246706        0x00007f216bbd8a35 in ?? ()\r\n  9    LWP 209289        0x00007f216ae06eb3 in ?? ()\r\n  8    LWP 246722        0x00007f216bbd8de2 in ?? ()\r\n  7    LWP 246721        0x00007f216bbd8de2 in ?? ()\r\n  6    LWP 246718        0x00007f216bbd8de2 in ?? ()\r\n  5    LWP 246717        0x00007f216bbd8de2 in ?? ()\r\n  4    LWP 246719        0x00007f216bbd8de2 in ?? ()\r\n  3    LWP 246713        0x00007f216bbd8de2 in ?? ()\r\n  2    LWP 246712        0x00007f216adfd9a3 in ?? ()\r\n* 1    LWP 246711        0x0000000000482910 in loadAppendOnlyFile (filename=0x4000000000000000 <Address 0x4000000000000000 out of bounds>) at aof.c:883\r\n(gdb) bt\r\n#0  0x0000000000482910 in loadAppendOnlyFile (filename=0x4000000000000000 <Address 0x4000000000000000 out of bounds>) at aof.c:883\r\n#1  0x00007f215ebd1da0 in ?? ()\r\n#2  0x00007f216bdf74d8 in ?? ()\r\n#3  0x9555a74d00000000 in ?? ()\r\n#4  0x0000000000000000 in ?? ()\r\n(gdb) \r\n\r\n```",
  "state": "closed",
  "created_at": "2022-08-24T14:42:17Z",
  "updated_at": "2022-09-05T06:26:38Z",
  "closed_at": "2022-09-05T06:26:38Z",
  "labels": [],
  "comments_data": [
    {
      "id": 1225893445,
      "user": "oranagra",
      "created_at": "2022-08-24T15:37:25Z",
      "body": "@chenyang8094 can you please have a look?"
    },
    {
      "id": 1226748389,
      "user": "ambarsarkar",
      "created_at": "2022-08-25T04:06:21Z",
      "body": "Apologies for the item #2 in the Additional Information. While related, that core file is NOT from redis-server, but a application of the cpp_redis::client (a c++ client for redis).  \r\n\r\nIt still is not clear why the redis server crash was seen in the original report and would highly appreciate any hints on why the redis-server crashed at the specific instruction. "
    },
    {
      "id": 1226758865,
      "user": "oranagra",
      "created_at": "2022-08-25T04:26:12Z",
      "body": "@ambarsarkar so did redis at all crash? \r\nCan you provide evidence from the log file? \r\nIs what you posted is the entire log file? \r\nAll I can see is that the fork child doing an AOF rewrite had a timeout writing to the disk.\r\nBut I don't see any crash or error message from Redis's main process. "
    },
    {
      "id": 1227125754,
      "user": "ambarsarkar",
      "created_at": "2022-08-25T11:20:35Z",
      "body": "Hi @oranagra thanks for responding. \r\n\r\nThe main redis-server thread did crash.\r\n\r\n1. A corefile was created, and the main server process (**61436**) has disappeared. The core file is too small unfortunately.\r\n-rw------- 1 svc_crystal hardware      1024 Aug 24 16:14 core.61436\r\n\r\n3. You can see the log file dumped by Redis below, It shows the PID (61436) on the top as well as a crash report in the bottom\r\n```\r\n1436:C 31 May 2022 09:29:26.031 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\r\n61436:C 31 May 2022 09:29:26.031 # Redis version=6.2.6, bits=64, commit=00000000, modified=0, pid=61436, just started\r\n61436:C 31 May 2022 09:29:26.032 # Configuration loaded\r\n61436:M 31 May 2022 09:29:26.034 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.\r\n61436:M 31 May 2022 09:29:26.034 # Server can't set maximum open files to 10032 because of OS error: Operation not permitted.\r\n61436:M 31 May 2022 09:29:26.035 # Current maximum open files is 8192. maxclients has been reduced to 8160 to compensate for low ulimit. If you need higher maxclients increase 'ulimit -n'.\r\n61436:M 31 May 2022 09:29:26.036 * monotonic clock: POSIX clock_gettime\r\n                _._\r\n           _.-``__ ''-._\r\n      _.-``    `.  `_.  ''-._           Redis 6.2.6 (00000000/0) 64 bit\r\n  .-`` .-```.  ```\\/    _.,_ ''-._\r\n (    '      ,       .-`  | `,    )     Running in standalone mode\r\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6382\r\n |    `-._   `._    /     _.-'    |     **PID: 61436**\r\n  `-._    `-._  `-./  _.-'    _.-'\r\n |`-._`-._    `-.__.-'    _.-'_.-'|\r\n |    `-._`-._        _.-'_.-'    |           https://redis.io\r\n  `-._    `-._`-.__.-'_.-'    _.-'\r\n |`-._`-._    `-.__.-'    _.-'_.-'|\r\n |    `-._`-._        _.-'_.-'    |\r\n  `-._    `-._`-.__.-'_.-'    _.-'\r\n      `-._    `-.__.-'    _.-'\r\n          `-._        _.-'\r\n              `-.__.-'\r\n\r\n61436:M 31 May 2022 09:29:26.045 # Server initialized\r\n61436:M 31 May 2022 09:29:26.160 * Module 'CrystalUtils' loaded from /home/ip/shared/inf/crystal/1.0/62192159/bin/CrystalUtils.so\r\n61436:M 31 May 2022 09:29:26.168 * Module 'CrystalTransactions' loaded from /home/ip/shared/inf/crystal/1.0/62192159/bin/CrystalTransaction.so\r\n61436:M 31 May 2022 09:29:26.171 * Ready to accept connections\r\n61436:M 31 May 2022 09:51:03.287 * Starting automatic rewriting of AOF on 3356077900% growth\r\n61436:M 31 May 2022 09:51:03.289 * Background append only file rewriting started by pid 68245\r\n61436:M 31 May 2022 09:51:03.618 * AOF rewrite child asks to stop sending diffs.\r\n68245:C 31 May 2022 09:51:03.619 * Parent agreed to stop sending diffs. Finalizing AOF...\r\n68245:C 31 May 2022 09:51:03.619 * Concatenating 0.07 MB of AOF diff received from parent.\r\n68245:C 31 May 2022 09:51:03.622 * SYNC append only file rewrite performed\r\n68245:C 31 May 2022 09:51:03.624 * AOF rewrite: 2 MB of memory used by copy-on-write\r\n\r\n**<similar stuff deleted, no warnings or errors>**\r\n\r\n06168:C 24 Aug 2022 02:47:06.977 * AOF rewrite: 54245 MB of memory used by copy-on-write\r\n61436:M 24 Aug 2022 02:47:21.482 * Background AOF rewrite terminated with success\r\n61436:M 24 Aug 2022 02:47:21.483 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)\r\n61436:M 24 Aug 2022 02:47:21.485 * Background AOF rewrite finished successfully\r\n61436:M 24 Aug 2022 03:38:46.729 * Starting automatic rewriting of AOF on 10% growth\r\n61436:M 24 Aug 2022 03:38:52.930 * Background append only file rewriting started by pid 141211\r\n61436:M 24 Aug 2022 04:29:09.967 * AOF rewrite child asks to stop sending diffs.\r\n141211:C 24 Aug 2022 04:29:09.968 * Parent agreed to stop sending diffs. Finalizing AOF...\r\n141211:C 24 Aug 2022 04:29:09.969 * Concatenating 1746.95 MB of AOF diff received from parent.\r\n141211:C 24 Aug 2022 04:29:16.054 * SYNC append only file rewrite performed\r\n141211:C 24 Aug 2022 04:29:21.422 * AOF rewrite: 43253 MB of memory used by copy-on-write\r\n61436:M 24 Aug 2022 04:29:35.154 * Background AOF rewrite terminated with success\r\n61436:M 24 Aug 2022 04:29:35.204 * Residual parent diff successfully flushed to the rewritten AOF (53.20 MB)\r\n61436:M 24 Aug 2022 04:29:35.272 * Background AOF rewrite finished successfully\r\n61436:M 24 Aug 2022 05:53:09.142 * Starting automatic rewriting of AOF on 10% growth\r\n61436:M 24 Aug 2022 05:53:15.191 * Background append only file rewriting started by pid 191897\r\n\r\n\r\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\r\n61436:M 24 Aug 2022 06:22:05.613 # Redis 6.2.6 crashed by signal: 7, si_code: 2\r\n61436:M 24 Aug 2022 06:22:05.614 # Accessing address: 0x7f9ad5be2000\r\n**61436:M 24 Aug 2022 06:22:05.614 # Crashed running the instruction at: 0x7f9ad5be1fff**\r\n191897:C 24 Aug 2022 06:47:41.689 # Write error writing append only file on disk: Connection timed out\r\n```\r\n3. Fyi, I was able to restart the server from the last dumped aof, and be happy to provide any information from that. "
    },
    {
      "id": 1228086472,
      "user": "chenyang8094",
      "created_at": "2022-08-26T05:59:44Z",
      "body": "> === REDIS BUG REPORT START: Cut & paste starting from here ===\r\n61436:M 24 Aug 2022 06:22:05.613 # Redis 6.2.6 crashed by signal: 7, si_code: 2\r\n61436:M 24 Aug 2022 06:22:05.614 # Accessing address: 0x7f9ad5be2000\r\n61436:M 24 Aug 2022 06:22:05.614 # Crashed running the instruction at: 0x7f9ad5be1fff\r\n191897:C 24 Aug 2022 06:47:41.689 # Write error writing append only file on disk: Connection timed out\r\n\r\nI'm curious how the \"Connection timed out\" error occurs when AOFRW (It seems a tcp connect err)? I need more information.\r\n\r\nAnd the error code is `BUS_ADRERR`, it maybe `jemalloc` error (use mmap) ?\r\n```\r\n/* Codes for SIGBUS */\r\n#if !defined(_POSIX_C_SOURCE) || defined(_DARWIN_C_SOURCE)\r\n#define BUS_NOOP        0       /* if only I knew... */\r\n#endif\r\n#define BUS_ADRALN      1       /* [XSI] Invalid address alignment */\r\n#define BUS_ADRERR      2       /* [XSI] Nonexistent physical address -NOTIMP */\r\n#define BUS_OBJERR      3       /* [XSI] Object-specific HW error - NOTIMP */\r\n```\r\n\r\n"
    },
    {
      "id": 1228152570,
      "user": "oranagra",
      "created_at": "2022-08-26T07:29:37Z",
      "body": "I wonder why we don't have a proper crash log with stack trace... \r\nSince we don't have a stack trace, can you please upload your executable binary or check which function that address resides in.. "
    },
    {
      "id": 1229182483,
      "user": "ambarsarkar",
      "created_at": "2022-08-27T12:21:08Z",
      "body": "This is probably not a Redis issue unless it could have given more diagnostic information or handled the observed exception better.\r\n\r\nAppreciate any input you may have. \r\n\r\nIn our application, we load Redis modules as shared objects (.so). These modules work fine and do not have any known issues. These modules were already loaded in and had been working fine. It had been days since the modules were loaded. The db is very large (~100Gb).\r\n\r\nWhat happened was that the NFS filer mounts these .so objects reside on became suddenly inaccessible. We suspect that may have cause the redis server to quit midstream. The address involved seems to be in the range, though we do not know for sure as the original process is gone and the core file is insignificant.\r\n\r\nThe puzzling part is that the .so objects were already loaded using module load, so it is not fully clear why the .so objects becoming unavailable after the module was loaded should matter. We are suspecting it may have to do with how this object is actually paged in to memory. \r\n\r\nWe had also recently switched aof_use_rdb_preamble from no to yes, and wondering if it exposed some path not seen before by our runs. \r\n\r\nDo you have any ideas on how the filer being unavailable can cause a crash and share any recommendations?\r\n\r\nAs for the core being limited to 1K, it's likely due to the default coredumpsize of 1K , which makes sense as we do not wish to leave huge core dumps. We will consider increasing that. \r\n\r\nThanks for looking into this."
    },
    {
      "id": 1229381549,
      "user": "oranagra",
      "created_at": "2022-08-28T05:41:20Z",
      "body": "AFAIR linux can execute files from loading them into the file system cache, so a portion of the executable code can be paged out and that can lead to issues if it can't be re-loaded.\r\n\r\nhowever, i don't understand why the crash log is missing, we do see the first line (`crashed by signal`), but not any other lines, which should have been printed regardless of that code being available (at least the stack trace).\r\n\r\nI generally don't recommend using core-dumps on redis, and i don't see why aof_use_rdb_preamble could be related to this."
    },
    {
      "id": 1229478943,
      "user": "ambarsarkar",
      "created_at": "2022-08-28T14:57:52Z",
      "body": "Okay, thanks for additional validation on how fs issues can get us here. \r\n\r\nIs there anything we can do to help with the missing crash log issue? \r\nWe agree as well, we do not wish to use core_dumps here in general, and do not think rdb_preamble caused the issue.  "
    },
    {
      "id": 1229481606,
      "user": "oranagra",
      "created_at": "2022-08-28T15:09:30Z",
      "body": "can you try to spin up another redis instance on the same infra and use `DEBUG SEGFAULT` to see if the crash log is printed?"
    },
    {
      "id": 1234986418,
      "user": "ambarsarkar",
      "created_at": "2022-09-02T02:07:54Z",
      "body": "Fyi, DEBUG SEGFAULT did print the crash log on a similar infra/setup. So the question remains why it was not dumped in case of the reported exception. \r\n\r\n === REDIS BUG REPORT START: Cut & paste starting from here ===\r\n22574:M 29 Aug 2022 07:18:56.785 # Redis 6.2.6 crashed by signal: 11, si_code: 1\r\n22574:M 29 Aug 2022 07:18:56.786 # Accessing address: 0xffffffffffffffff\r\n22574:M 29 Aug 2022 07:18:56.786 # Crashed running the instruction at: 0x48a9c8\r\n\r\n------ STACK TRACE ------\r\nEIP:\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888(debugCommand+0x1a8)[0x48a9c8]\r\n\r\nBacktrace:\r\n/lib64/libpthread.so.0(+0xf630)[0x7f7813f3b630]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888(debugCommand+0x1a8)[0x48a9c8]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888(call+0x9f)[0x43930f]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888(processCommand+0x89d)[0x43df3d]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888(processCommandAndResetClient+0x24)[0x44ddc4]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888(processInputBuffer+0xd5)[0x4522c5]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888[0x4de5db]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888(aeProcessEvents+0x258)[0x4327d8]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888(aeMain+0x1d)[0x432a7d]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888(main+0x447)[0x440587]\r\n/lib64/libc.so.6(__libc_start_main+0xf5)[0x7f7813b80555]\r\n/home/utils/redis-6.2.6/bin/redis-server *:8888[0x42fae9]\r\n\r\n------ REGISTERS ------\r\n22574:M 29 Aug 2022 07:18:56.789 # \r\nRAX:0000000000000000 RBX:00007f781372a380\r\nRCX:0000000000000010 RDX:0000000000000010\r\nRDI:00007f66a3bbb8b0 RSI:000000000056ad80\r\nRBP:00007f778b70b220 RSP:00007ffcc7fe9e70\r\nR8 :0000000000000000 R9 :000000000000000a\r\nR10:fffffffffffff8ca R11:0011e144f5c50b52\r\nR12:00007f66a3bbb8b3 R13:0000000000000002\r\nR14:0000000000000000 R15:0000000000000000\r\nRIP:000000000048a9c8 EFL:0000000000010246\r\nCSGSFS:0000000000000033\r\n22574:M 29 Aug 2022 07:18:56.790 # (00007ffcc7fe9e7f) -> 00007f7813c25705\r\n22574:M 29 Aug 2022 07:18:56.791 # (00007ffcc7fe9e7e) -> 0000000000000000\r\n22574:M 29 Aug 2022 07:18:56.791 # (00007ffcc7fe9e7d) -> 00007ffcc7fea110\r\n22574:M 29 Aug 2022 07:18:56.792 # (00007ffcc7fe9e7c) -> 00007ffcc7fea100\r\n22574:M 29 Aug 2022 07:18:56.793 # (00007ffcc7fe9e7b) -> 00007ffcc7fe9f50\r\n22574:M 29 Aug 2022 07:18:56.794 # (00007ffcc7fe9e7a) -> 00007ffcc7fe9f40\r\n22574:M 29 Aug 2022 07:18:56.794 # (00007ffcc7fe9e79) -> 0000000000000000\r\n22574:M 29 Aug 2022 07:18:56.795 # (00007ffcc7fe9e78) -> 0000000000000000\r\n22574:M 29 Aug 2022 07:18:56.796 # (00007ffcc7fe9e77) -> 0000000000000001\r\n22574:M 29 Aug 2022 07:18:56.796 # (00007ffcc7fe9e76) -> 0000000000000000\r\n22574:M 29 Aug 2022 07:18:56.798 # (00007ffcc7fe9e75) -> 000000000000582e\r\n22574:M 29 Aug 2022 07:18:56.798 # (00007ffcc7fe9e74) -> 00007ffcc7fe9f30\r\n22574:M 29 Aug 2022 07:18:56.799 # (00007ffcc7fe9e73) -> 00007ffcc7fea784\r\n22574:M 29 Aug 2022 07:18:56.800 # (00007ffcc7fe9e72) -> 0000000000000000\r\n22574:M 29 Aug 2022 07:18:56.801 # (00007ffcc7fe9e71) -> 00007ffcc7fe9e80\r\n22574:M 29 Aug 2022 07:18:56.801 # (00007ffcc7fe9e70) -> 00007ffcc7fe9f40\r\n\r\n------ INFO OUTPUT ------\r\n# Server\r\n\r\nredis_version:6.2.6\r\n\r\nredis_git_sha1:00000000\r\n\r\nredis_git_dirty:0\r\n\r\nredis_build_id:b0a4475eea151e9d\r\n\r\nredis_mode:standalone\r\n\r\nos:Linux 3.10.0-1127.el7.x86_64 x86_64\r\n\r\narch_bits:64\r\n\r\nmultiplexing_api:epoll\r\n\r\natomicvar_api:sync-builtin\r\n\r\ngcc_version:4.4.7\r\n\r\nprocess_id:22574\r\n\r\nprocess_supervised:no\r\n\r\nrun_id:e6a730ac3a14233ea1d1713db18441a0d2c76184\r\n\r\ntcp_port:8888\r\n\r\nserver_time_usec:1661782736783799\r\n\r\nuptime_in_seconds:5385\r\n\r\nuptime_in_days:0\r\n\r\nhz:10\r\n\r\nconfigured_hz:10\r\n\r\nlru_clock:838352\r\n\r\nexecutable:/home/utils/redis-6.2.6/bin/redis-server\r\n\r\nconfig_file:\r\n\r\nio_threads_active:0\r\n\r\n\r\n\r\n# Clients\r\n\r\nconnected_clients:1\r\n\r\ncluster_connections:0\r\n\r\nmaxclients:8160\r\n\r\nclient_recent_max_input_buffer:0\r\n\r\nclient_recent_max_output_buffer:0\r\n\r\nblocked_clients:0\r\n\r\ntracking_clients:0\r\n\r\nclients_in_timeout_table:0\r\n\r\n\r\n\r\n# Memory\r\n\r\nused_memory:136693110760\r\n\r\nused_memory_human:127.31G\r\n\r\nused_memory_rss:139600097280\r\n\r\nused_memory_rss_human:130.01G\r\n\r\nused_memory_peak:137634707760\r\n\r\nused_memory_peak_human:128.18G\r\n\r\nused_memory_peak_perc:99.32%\r\n\r\nused_memory_overhead:44527328048\r\n\r\nused_memory_startup:794432\r\n\r\nused_memory_dataset:92165782712\r\n\r\nused_memory_dataset_perc:67.43%\r\n\r\nallocator_allocated:136693137432\r\n\r\nallocator_active:138115117056\r\n\r\nallocator_resident:139607891968\r\n\r\ntotal_system_memory:1621650100224\r\n\r\ntotal_system_memory_human:1.47T\r\n\r\nused_memory_lua:37888\r\n\r\nused_memory_lua_human:37.00K\r\n\r\nused_memory_scripts:0\r\n\r\nused_memory_scripts_human:0B\r\n\r\nnumber_of_cached_scripts:0\r\n\r\nmaxmemory:0\r\n\r\nmaxmemory_human:0B\r\n\r\nmaxmemory_policy:noeviction\r\n\r\nallocator_frag_ratio:1.01\r\n\r\nallocator_frag_bytes:1421979624\r\n\r\nallocator_rss_ratio:1.01\r\n\r\nallocator_rss_bytes:1492774912\r\n\r\nrss_overhead_ratio:1.00\r\n\r\nrss_overhead_bytes:-7794688\r\n\r\nmem_fragmentation_ratio:1.02\r\n\r\nmem_fragmentation_bytes:2907050280\r\n\r\nmem_not_counted_for_evict:108\r\n\r\nmem_replication_backlog:0\r\n\r\nmem_clients_slaves:0\r\n\r\nmem_clients_normal:0\r\n\r\nmem_aof_buffer:112\r\n\r\nmem_allocator:jemalloc-5.1.0\r\n\r\nactive_defrag_running:0\r\n\r\nlazyfree_pending_objects:0\r\n\r\nlazyfreed_objects:0\r\n\r\n\r\n\r\n# Persistence\r\n\r\nloading:0\r\n\r\ncurrent_cow_size:0\r\n\r\ncurrent_cow_size_age:0\r\n\r\ncurrent_fork_perc:0.00\r\n\r\ncurrent_save_keys_processed:0\r\n\r\ncurrent_save_keys_total:0\r\n\r\nrdb_changes_since_last_save:1\r\n\r\nrdb_bgsave_in_progress:0\r\n\r\nrdb_last_save_time:1661781705\r\n\r\nrdb_last_bgsave_status:ok\r\n\r\nrdb_last_bgsave_time_sec:2723\r\n\r\nrdb_current_bgsave_time_sec:-1\r\n\r\nrdb_last_cow_size:3362816\r\n\r\naof_enabled:1\r\n\r\naof_rewrite_in_progress:0\r\n\r\naof_rewrite_scheduled:0\r\n\r\naof_last_rewrite_time_sec:-1\r\n\r\naof_current_rewrite_time_sec:-1\r\n\r\naof_last_bgrewrite_status:ok\r\n\r\naof_last_write_status:ok\r\n\r\naof_last_cow_size:0\r\n\r\nmodule_fork_in_progress:0\r\n\r\nmodule_fork_last_cow_size:0\r\n\r\naof_current_size:92958209852\r\n\r\naof_base_size:92958209800\r\n\r\naof_pending_rewrite:0\r\n\r\naof_buffer_length:0\r\n\r\naof_rewrite_buffer_length:0\r\n\r\naof_pending_bio_fsync:0\r\n\r\naof_delayed_fsync:0\r\n\r\n\r\n\r\n# Stats\r\n\r\ntotal_connections_received:531\r\n\r\ntotal_commands_processed:200709983\r\n\r\ninstantaneous_ops_per_sec:0\r\n\r\ntotal_net_input_bytes:7464\r\n\r\ntotal_net_output_bytes:10176\r\n\r\ninstantaneous_input_kbps:0.00\r\n\r\ninstantaneous_output_kbps:0.00\r\n\r\nrejected_connections:0\r\n\r\nsync_full:0\r\n\r\nsync_partial_ok:0\r\n\r\nsync_partial_err:0\r\n\r\nexpired_keys:0\r\n\r\nexpired_stale_perc:0.00\r\n\r\nexpired_time_cap_reached_count:0\r\n\r\nexpire_cycle_cpu_milliseconds:45\r\n\r\nevicted_keys:0\r\n\r\nkeyspace_hits:0\r\n\r\nkeyspace_misses:0\r\n\r\npubsub_channels:0\r\n\r\npubsub_patterns:0\r\n\r\nlatest_fork_usec:3245448\r\n\r\ntotal_forks:1\r\n\r\nmigrate_cached_sockets:0\r\n\r\nslave_expires_tracked_keys:0\r\n\r\nactive_defrag_hits:0\r\n\r\nactive_defrag_misses:0\r\n\r\nactive_defrag_key_hits:0\r\n\r\nactive_defrag_key_misses:0\r\n\r\ntracking_total_keys:0\r\n\r\ntracking_total_items:0\r\n\r\ntracking_total_prefixes:0\r\n\r\nunexpected_error_replies:0\r\n\r\ntotal_error_replies:154\r\n\r\ndump_payload_sanitizations:0\r\n\r\ntotal_reads_processed:1061\r\n\r\ntotal_writes_processed:530\r\n\r\nio_threaded_reads_processed:0\r\n\r\nio_threaded_writes_processed:0\r\n\r\n\r\n\r\n# Replication\r\n\r\nrole:master\r\n\r\nconnected_slaves:0\r\n\r\nmaster_failover_state:no-failover\r\n\r\nmaster_replid:bbdd5eb7f1194f432407612743765299b4e35739\r\n\r\nmaster_replid2:0000000000000000000000000000000000000000\r\n\r\nmaster_repl_offset:0\r\n\r\nsecond_repl_offset:-1\r\n\r\nrepl_backlog_active:0\r\n\r\nrepl_backlog_size:1048576\r\n\r\nrepl_backlog_first_byte_offset:0\r\n\r\nrepl_backlog_histlen:0\r\n\r\n\r\n\r\n# CPU\r\n\r\nused_cpu_sys:237.454246\r\n\r\nused_cpu_user:1393.248767\r\n\r\nused_cpu_sys_children:939.101560\r\n\r\nused_cpu_user_children:1694.724304\r\n\r\nused_cpu_sys_main_thread:237.414281\r\n\r\nused_cpu_user_main_thread:1393.241446\r\n\r\n\r\n\r\n# Modules\r\n\r\nmodule:name=CrystalTransactions,ver=1,api=1,filters=0,usedby=[],using=[],options=[]\r\n\r\n\r\n\r\n# Commandstats\r\n\r\ncmdstat_set:calls=1,usec=6,usec_per_call=6.00,rejected_calls=0,failed_calls=0\r\n\r\ncmdstat_hset:calls=2,usec=29,usec_per_call=14.50,rejected_calls=0,failed_calls=0\r\n\r\ncmdstat_ping:calls=375,usec=5084,usec_per_call=13.56,rejected_calls=154,failed_calls=0\r\n\r\n\r\n\r\n# Errorstats\r\n\r\nerrorstat_LOADING:count=154\r\n\r\n\r\n\r\n# Cluster\r\n\r\ncluster_enabled:0\r\n\r\n\r\n\r\n# Keyspace\r\n\r\ndb0:keys=898414972,expires=0,avg_ttl=0\r\n\r\n\r\n------ CLIENT LIST OUTPUT ------\r\nid=534 addr=10.128.65.138:47370 laddr=10.128.65.138:8888 fd=9 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=29 qbuf-free=40925 argv-mem=13 obl=0 oll=0 omem=0 tot-mem=61469 events=r cmd=debug user=default redir=-1\r\n\r\n------ CURRENT CLIENT INFO ------\r\nid=534 addr=10.128.65.138:47370 laddr=10.128.65.138:8888 fd=9 name= age=0 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=29 qbuf-free=40925 argv-mem=13 obl=0 oll=0 omem=0 tot-mem=61469 events=r cmd=debug user=default redir=-1\r\nargv[0]: 'debug'\r\nargv[1]: 'segfault'\r\n\r\n------ MODULES INFO OUTPUT ------\r\n\r\n------ FAST MEMORY TEST ------\r\n22574:M 29 Aug 2022 07:18:56.809 # Bio thread for job type #0 terminated\r\n22574:M 29 Aug 2022 07:18:56.810 # Bio thread for job type #1 terminated\r\n22574:M 29 Aug 2022 07:18:56.810 # Bio thread for job type #2 terminated\r\n*** Preparing to test memory region 7cb000 (2281472 bytes)\r\n*** Preparing to test memory region 2902000 (266240 bytes)\r\n*** Preparing to test memory region 2943000 (262144 bytes)\r\n*** Preparing to test memory region 7f5098000000 (135168 bytes)\r\n*** Preparing to test memory region 7f509efc6000 (33792000 bytes)\r\n*** Preparing to test memory region 7f50a1000000 (2097152 bytes)\r\n*** Preparing to test memory region 7f50a1478000 (8192 bytes)\r\n*** Preparing to test memory region 7f50a1899000 (8192 bytes)\r\n*** Preparing to test memory region 7f50a1cb4000 (24576 bytes)\r\n*** Preparing to test memory region 7f50a232f000 (16384 bytes)\r\n*** Preparing to test memory region 7f50a344f000 (12288 bytes)\r\n*** Preparing to test memory region 7f50a3fe0000 (28672 bytes)\r\n*** Preparing to test memory region 7f50a47a6000 (40960 bytes)\r\n*** Preparing to test memory region 7f50a53ff000 (4096 bytes)\r\n*** Preparing to test memory region 7f50a5400000 (158464999424 bytes)\r\n*** Preparing to test memory region 7f758a9c5000 (10737418240 bytes)\r\n*** Preparing to test memory region 7f780a9c6000 (33792000 bytes)\r\n*** Preparing to test memory region 7f780ca00000 (6291456 bytes)\r\n*** Preparing to test memory region 7f780d150000 (33792000 bytes)\r\n*** Preparing to test memory region 7f7813200000 (8388608 bytes)\r\n*** Preparing to test memory region 7f7813f27000 (20480 bytes)\r\n*** Preparing to test memory region 7f7814144000 (16384 bytes)\r\n*** Preparing to test memory region 7f78145e4000 (16384 bytes)\r\n*** Preparing to test memory region 7f7815166000 (28672 bytes)\r\n*** Preparing to test memory region 7f781519f000 (4096 bytes)\r\n*** Preparing to test memory region 7f78151a0000 (4096 bytes)\r\n*** Preparing to test memory region 7f78151a3000 (4096 bytes)\r\n.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O.O\r\nFast memory test PASSED, however your memory can still be broken. Please run a memory test for several hours if possible.\r\n\r\n------ DUMPING CODE AROUND EIP ------\r\nSymbol: debugCommand (base: 0x48a820)\r\nModule: /home/utils/redis-6.2.6/bin/redis-server *:8888 (base 0x400000)\r\n$ xxd -r -p /tmp/dump.hex /tmp/dump.bin\r\n$ objdump --adjust-vma=0x48a820 -D -b binary -m i386:x86-64 /tmp/dump.bin\r\n------\r\n22574:M 29 Aug 2022 07:27:22.512 # dump of function (hexdump of 552 bytes):\r\n48895c24d048896c24d84889fb4c896424e04c896c24e84c897424f04c897c24f84881ec38110000448b6f484183fd020f8482010000488b6f50488b45084c8b6008be89ad56004c89e7e8a149faff85c00f8451010000be4b7c56004c89e7e88c49faff85c00f84e9110000be92ad56004c89e7e87749faff85c00f85870000004531e4837b480248c78424f8100000000000000f8f0e020000488b4508be92ad5600488b7808e84449faff83f8014c89e619ff83e703e8841dfbffbef0b856004889dfe87762fcff488b9c2408110000488bac24101100004c8ba424181100004c8bac24201100004c8bb424281100004c8bbc24301100004881c438110000c30f1f8000000000be9aad56004c89e7e8db48faff85c00f8464ffffffbee89a57004c89e7e8c648faff85c00f84ee020000beacad56004c89e7e8b148faff85c00f848c140000be598855004c89e7e89c48faff85c0750a4183fd030f840e020000be679458004c89e7e88148faff85c00f85890000004183fd030f857f000000488b4510488b7808e8926afbff6690488b35117b34004889dfe8c17bfcffe925ffffff0f1f4000c60425ffffffff78e914ffffff0f1f00488b6f50be7a7f5500488b45084c8b60084c89e7e81f48faff85c00f8569feffff488d7c2440bec0ca5600b94f000000f348a5488d7424404889dfe8285dfcffe9ccfeffff0f1f00bec8ad56004c89e7e8e347faff85c00f85cb0000004531e44183fd02c7442430010000000f8e8605\r\n=== REDIS BUG REPORT END. Make sure to include from START to END. ===\r\n\r\n       Please report the crash by opening an issue on github:\r\n\r\n           http://github.com/redis/redis/issues\r\n\r\n  Suspect RAM error? Use redis-server --test-memory to verify it.\r\n\r\n"
    },
    {
      "id": 1235439976,
      "user": "oranagra",
      "created_at": "2022-09-02T12:25:56Z",
      "body": "Ok, so the platform and build are ok, but there was something specific with that incident that made the process die before printing the stack trace. \r\nIf you still have access to the kernel's syslog, maybe there's a hint there. "
    },
    {
      "id": 1235723599,
      "user": "ambarsarkar",
      "created_at": "2022-09-02T16:59:54Z",
      "body": "All we see  in /var/log/messages is \r\nAug 24 06:22:15 <host> abrt-server: Executable '/home/utils/redis-6.2.6/bin/redis-server' doesn't belong to any package and ProcessUnpackaged is set to 'no'\r\nAug 26 11:12:06 <host> abrt-hook-ccpp: Process 269390 (redis-server) of user 28745 killed by SIGBUS - dumping core\r\nAug 26 11:12:10 <host> abrt-server: Executable '/home/utils/redis-6.2.6/bin/redis-server' doesn't belong to any package and ProcessUnpackaged is set to 'no'\r\n\r\nNote that the core-dump was not complete due to default limit of only 1K size. Is it possible that if the core-dump fails, the stack trace is not printed? The stack trace would definitely have been handy. \r\nThanks"
    },
    {
      "id": 1235755749,
      "user": "oranagra",
      "created_at": "2022-09-02T17:39:06Z",
      "body": "No, this is unrelated. First, redis catches the signal, and prints its crash report, and then it throws the signal again, which generated a core file. In this case I guess redis generated a sigbus while trying to print the stack trace. \r\nI have no idea why. Maybe @yossigo can think of something. "
    },
    {
      "id": 1236289114,
      "user": "yossigo",
      "created_at": "2022-09-04T08:36:03Z",
      "body": "If I understand correctly, we're dealing with modules loaded from NFS which may have their text pages unavailable. I believe this can easily explain `SIGBUS` trying to access them."
    },
    {
      "id": 1236290858,
      "user": "oranagra",
      "created_at": "2022-09-04T08:46:35Z",
      "body": "@yossigo yes, but why would it SIGBUG again when we print the stack trace?\r\nohh, maybe calling `backtrace_symbols_fd`"
    },
    {
      "id": 1236477448,
      "user": "ambarsarkar",
      "created_at": "2022-09-05T02:04:44Z",
      "body": "So do we now know why the stack trace was not printed and can anything be done to make it print (handle exception etc)? \r\nAlso, will the behavior be any different with the latest 7.x versions? Thanks"
    },
    {
      "id": 1236584701,
      "user": "oranagra",
      "created_at": "2022-09-05T06:26:38Z",
      "body": "Yes, when we print the stack trace, other than getting the addresses of the functions on the stack, we also need to translate them to symbols (function names), and that part probably crashed on SIGBUS too since the ELF is inaccessible.\r\n\r\nIn theory, we can catch that, and resort to printing just the addresses, but it won't be very useful and considering this case is rare, i don't think we want to do that.\r\n\r\nin think the outcome of this case would have been the same on any version of redis.\r\nI think we should close this case without any modification to redis."
    }
  ]
}