{
  "issue_number": 10729.0,
  "title": "[BUG] Redis cluster looses configuration",
  "body": "**Describe the bug**\r\n\r\nThe Redis cluster looses configuration when nodes reboot.\r\n\r\n * Both appendonly and rdb saves are enabled.\r\n * Running in docker with network mode set to \"host\" and read-write volumes for storing data and config.\r\n\r\nThis is a 15 nodes cluster, running on 5 servers (so 3 nodes per server). Initiated with 2 replications per master (so there is 5 masters, 10 replicas) -- goal being that we can loose up to 2 servers.\r\n\r\nWhen rebooting all hosts simultaneously, the configuration of the cluster has changed after the boot... some master node have now have 3 or 4 replicas, others only 1 replica...\r\n\r\nThe cluster has no data (it's being deployed and configured for future use), but I'm concerned to go in production without figuring this problem.\r\n\r\n**To reproduce**\r\n\r\n* Initiate a 5x3 nodes redis cluster with the docker-compose file below.\r\n* Initiate cluster mode: `redis-cli --cluster create host:port... --cluster-replicas 2`.\r\n* Reboot all servers.\r\n\r\n**Expected behavior**\r\n\r\nI expected each master to have 2 replicas after reboot (so my redundancy preference is kept).\r\n\r\n**Additional information**\r\n\r\nThe `docker-compose` file used on all 5 servers, generated with Ansible.\r\n\r\n```yml\r\n---\r\nversion: '3.0'\r\nservices:\r\n\r\n{% for db in databases %}\r\n{% for i in [0, 1, 2] %}\r\n  redis_{{ db }}{{ i }}:\r\n    container_name: redis_{{ db }}{{ i }}\r\n    restart: always\r\n    image: redis:6-alpine\r\n    network_mode: host\r\n    volumes:\r\n      - /opt/redis/data/{{ db }}{{ i }}:/data\r\n      - /opt/redis/config/{{ db }}{{ i }}:/config\r\n    command: >\r\n      redis-server\r\n      --save 600 1\r\n      --appendonly yes\r\n      --loglevel warning\r\n      --bind {{ vlan0 }}\r\n      --port {{ redis_port[db][i] }}\r\n      --databases 1\r\n      --cluster-enabled yes\r\n      --cluster-config-file /config/nodes.conf\r\n\r\n{% endfor %}\r\n{% endfor %}\r\n```",
  "state": "closed",
  "created_at": "2022-05-15T08:39:08Z",
  "updated_at": "2022-06-10T21:15:14Z",
  "closed_at": "2022-06-10T21:15:14Z",
  "labels": [],
  "comments_data": [
    {
      "id": 1127849244,
      "user": "hwware",
      "created_at": "2022-05-16T15:57:34Z",
      "body": "Hi @j3k0 Can I understand you have the issue with the following config in a cluster?\r\n\r\n5 master and 10 replicas, with enable appendonly and rdb saves options\r\nand the redis version is 6.0 or higher version such as 6.2 or 7.0?\r\n\r\nThanks"
    },
    {
      "id": 1127987118,
      "user": "j3k0",
      "created_at": "2022-05-16T18:17:19Z",
      "body": "Yes, I attached the docker-compose file which shows the exact configuration and versions:\r\n\r\n- Image: `redis:6-alpine` (pulled a couple of days ago)\r\n- Command: `redis-server\r\n      --save 600 1\r\n      --appendonly yes\r\n      --loglevel warning\r\n      --bind {{ vlan0 }}\r\n      --port {{ redis_port[db][i] }}\r\n      --databases 1\r\n      --cluster-enabled yes\r\n      --cluster-config-file /config/nodes.conf`"
    },
    {
      "id": 1135449025,
      "user": "j3k0",
      "created_at": "2022-05-24T06:07:17Z",
      "body": "@hwware any idea what I should look at to figure out how the cluster configuration is lost?"
    },
    {
      "id": 1135993428,
      "user": "uvletter",
      "created_at": "2022-05-24T14:21:08Z",
      "body": "hi @j3k0, can you post the `cluster nodes` outputs of problem node before and after the reboot?"
    },
    {
      "id": 1136080171,
      "user": "j3k0",
      "created_at": "2022-05-24T15:32:11Z",
      "body": "This isn't 100% predictable. Happens only on some reboots.\r\n\r\nTo simplify the context, I disabled rdb saves, only appendonly is enabled (and dump files removed).\r\n\r\nHere for example:\r\n\r\nBefore (masters in blue - nodes that changed config highlighted in color -- same as below graphs):\r\n<img width=\"895\" alt=\"Screen Shot 2022-05-24 at 17 27 46\" src=\"https://user-images.githubusercontent.com/191881/170074086-86efe606-011b-4ab4-af05-cd44e6f780e8.png\">\r\n\r\nAfter rebooting all servers: Red node somehow joined a different group...\r\n<img width=\"379\" alt=\"Screen Shot 2022-05-24 at 18 05 53\" src=\"https://user-images.githubusercontent.com/191881/170074095-99f02ca5-bf75-4811-9c71-81c98a034bc2.png\">\r\n\r\nAfter rebooting only `.41`, `.43` and `.44`: Red node now replicates a replica...\r\n<img width=\"654\" alt=\"Screen Shot 2022-05-24 at 18 24 00\" src=\"https://user-images.githubusercontent.com/191881/170074109-96c40729-900e-4c95-9fef-c45a717950c8.png\">"
    },
    {
      "id": 1136131187,
      "user": "uvletter",
      "created_at": "2022-05-24T16:17:45Z",
      "body": "Thanks for your graphs, it's very vivid. As for the second graph, can you provide the log in the red node(i.e. 192.168.41:5006), it's a little bit odd that it joined a different group.\r\nBTW, `cluster nodes` is a command to let redis tell the cluster topology, which shows a more detailed raw informations. It would be better if you can also provide this : ) "
    },
    {
      "id": 1136270803,
      "user": "hwware",
      "created_at": "2022-05-24T18:01:32Z",
      "body": "@j3k0 Sorry for delaying response for you. I need take some time to learn something about docker-compose because I am not familar with that part.\r\n\r\nAnd Thanks for your picture. I summarize your network structure as below:\r\n\r\nmaster: 192.168.100.43:5004  slave: 192.168.100.42:5006     192.168.100.41:5005  \r\n\r\nmaster: 192.168.100.42:5004  slave: 192.168.100.43:5006     192.168.100.41:5004\r\n\r\nmaster: 192.168.100.45:5004  slave: 192.168.100.42:5005     192.168.100.44:5006  \r\n\r\nmaster: 192.168.100.45:5005  slave: 192.168.100.43:5005     192.168.100.44:5005  \r\n\r\nmaster: 192.168.100.44:5004  slave: 192.168.100.45:5006     192.168.100.41:5006\r\n\r\nI found the group (master: 192.168.100.44:5004  slave: 192.168.100.45:5006     192.168.100.41:5006) changes after rebooting all nodes and other group still keeps as before:\r\nI have 2 questions for it:\r\n\r\n1. If the  issue always happens in this group -- master: 192.168.100.44:5004  slave: 192.168.100.45:5006     192.168.100.41:5006\r\n2. If you do not use this group, and only includes 4 master nodes and 8 replicas node in the cluster, the issue still happens?  \r\n\r\nThanks.\r\n\r\n\r\n\r\n\r\n"
    },
    {
      "id": 1136271179,
      "user": "j3k0",
      "created_at": "2022-05-24T18:01:59Z",
      "body": "Sure.\r\n\r\nNow we're in the buggy state, I'm running `cluster nodes` from `.42:5004` and `.41:5006`.\r\n\r\n```sh\r\n# redis-cli -h 192.168.100.42 -p 5004 CLUSTER NODES\r\n0b42f5d63a26f95e4d4061e6476099242efa29a2 192.168.100.42:5006@15006 master - 0 1653412310000 54 connected 6554-9829\r\n894eb6eb357de3103a2e778b93358f23be7f68b5 192.168.100.41:5005@15005 slave 0b42f5d63a26f95e4d4061e6476099242efa29a2 0 1653412309923 54 connected\r\n89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 192.168.100.45:5004@15004 master - 0 1653412310524 23 connected 13107-16383\r\n8b52c017790fcbc707d97a665573073ad1f618ca 192.168.100.42:5004@15004 myself,master - 0 1653412304000 55 connected 0-3276\r\n95d46662312d464e6969c84e727932367b05032c 192.168.100.44:5006@15006 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653412309000 23 connected\r\n51dc2dc93c12dafede60c80fbc8c863f567ea471 192.168.100.41:5004@15004 slave 8b52c017790fcbc707d97a665573073ad1f618ca 0 1653412306000 55 connected\r\n74a50110f6bf99d651fd029b0e1da4a1b2115044 192.168.100.43:5006@15006 slave 8b52c017790fcbc707d97a665573073ad1f618ca 0 1653412306000 55 connected\r\n226106848958b59199f2c253966a14c39b0e1f38 192.168.100.42:5005@15005 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653412309000 23 connected\r\ne2e34814fa91b3ce49378210b2227d2b88f7c30f 192.168.100.43:5004@15004 slave 0b42f5d63a26f95e4d4061e6476099242efa29a2 0 1653412309000 54 connected\r\n096e6fb32cc6ebe8ba2fe61def121f9b5c51216a 192.168.100.41:5006@15006 slave 51dc2dc93c12dafede60c80fbc8c863f567ea471 0 1653412310926 55 connected\r\na1fbcbff7da750ec8d33bf14a59b913dffeceb7f 192.168.100.45:5005@15005 master - 0 1653412308000 41 connected 3277-6553\r\n45f0ac04929c8f6f9420cc36bb48274a1db46ba0 192.168.100.44:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653412307514 41 connected\r\nc888ce5346a2458224b07dee3578870d74a91f46 192.168.100.44:5004@15004 slave fab0578f1a3890740b97453d2c5c70f4999f01e1 0 1653412311528 42 connected\r\nfab0578f1a3890740b97453d2c5c70f4999f01e1 192.168.100.45:5006@15006 master - 0 1653412308000 42 connected 9830-13106\r\n3640507d72415a87c5409b4ebc911abe43956a66 192.168.100.43:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653412310000 41 connected\r\n# redis-cli -h 192.168.100.41 -p 5006 CLUSTER NODES\r\n096e6fb32cc6ebe8ba2fe61def121f9b5c51216a 192.168.100.41:5006@15006 myself,slave 51dc2dc93c12dafede60c80fbc8c863f567ea471 0 1653412318000 55 connected\r\n95d46662312d464e6969c84e727932367b05032c 192.168.100.44:5006@15006 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653412320860 23 connected\r\na1fbcbff7da750ec8d33bf14a59b913dffeceb7f 192.168.100.45:5005@15005 master - 0 1653412318853 41 connected 3277-6553\r\n226106848958b59199f2c253966a14c39b0e1f38 192.168.100.42:5005@15005 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653412317000 23 connected\r\nc888ce5346a2458224b07dee3578870d74a91f46 192.168.100.44:5004@15004 slave fab0578f1a3890740b97453d2c5c70f4999f01e1 0 1653412320559 42 connected\r\n89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 192.168.100.45:5004@15004 master - 0 1653412319856 23 connected 13107-16383\r\nfab0578f1a3890740b97453d2c5c70f4999f01e1 192.168.100.45:5006@15006 master - 0 1653412318000 42 connected 9830-13106\r\n894eb6eb357de3103a2e778b93358f23be7f68b5 192.168.100.41:5005@15005 slave 0b42f5d63a26f95e4d4061e6476099242efa29a2 0 1653412318000 54 connected\r\ne2e34814fa91b3ce49378210b2227d2b88f7c30f 192.168.100.43:5004@15004 slave 0b42f5d63a26f95e4d4061e6476099242efa29a2 0 1653412321863 54 connected\r\n8b52c017790fcbc707d97a665573073ad1f618ca 192.168.100.42:5004@15004 master - 0 1653412320000 55 connected 0-3276\r\n51dc2dc93c12dafede60c80fbc8c863f567ea471 192.168.100.41:5004@15004 slave 8b52c017790fcbc707d97a665573073ad1f618ca 0 1653412316000 55 connected\r\n45f0ac04929c8f6f9420cc36bb48274a1db46ba0 192.168.100.44:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653412316000 41 connected\r\n0b42f5d63a26f95e4d4061e6476099242efa29a2 192.168.100.42:5006@15006 master - 0 1653412317848 54 connected 6554-9829\r\n3640507d72415a87c5409b4ebc911abe43956a66 192.168.100.43:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653412317000 41 connected\r\n74a50110f6bf99d651fd029b0e1da4a1b2115044 192.168.100.43:5006@15006 slave 8b52c017790fcbc707d97a665573073ad1f618ca 0 1653412319000 55 connected\r\n```\r\n\r\n---\r\n\r\nGetting the cluster back in a correct state (each master having 2 replicas), by running:\r\n```sh\r\n# redis-cli -h 192.168.100.41 -p 5006 CLUSTER REPLICATE fab0578f1a3890740b97453d2c5c70f4999f01e1\r\n```\r\n\r\nNow here is the `cluster nodes` output:\r\n\r\n```sh\r\n# redis-cli -h 192.168.100.41 -p 5006 cluster nodes\r\n096e6fb32cc6ebe8ba2fe61def121f9b5c51216a 192.168.100.41:5006@15006 myself,slave 51dc2dc93c12dafede60c80fbc8c863f567ea471 0 1653412318000 55 connected\r\n95d46662312d464e6969c84e727932367b05032c 192.168.100.44:5006@15006 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653412320860 23 connected\r\na1fbcbff7da750ec8d33bf14a59b913dffeceb7f 192.168.100.45:5005@15005 master - 0 1653412318853 41 connected 3277-6553\r\n226106848958b59199f2c253966a14c39b0e1f38 192.168.100.42:5005@15005 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653412317000 23 connected\r\nc888ce5346a2458224b07dee3578870d74a91f46 192.168.100.44:5004@15004 slave fab0578f1a3890740b97453d2c5c70f4999f01e1 0 1653412320559 42 connected\r\n89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 192.168.100.45:5004@15004 master - 0 1653412319856 23 connected 13107-16383\r\nfab0578f1a3890740b97453d2c5c70f4999f01e1 192.168.100.45:5006@15006 master - 0 1653412318000 42 connected 9830-13106\r\n894eb6eb357de3103a2e778b93358f23be7f68b5 192.168.100.41:5005@15005 slave 0b42f5d63a26f95e4d4061e6476099242efa29a2 0 1653412318000 54 connected\r\ne2e34814fa91b3ce49378210b2227d2b88f7c30f 192.168.100.43:5004@15004 slave 0b42f5d63a26f95e4d4061e6476099242efa29a2 0 1653412321863 54 connected\r\n8b52c017790fcbc707d97a665573073ad1f618ca 192.168.100.42:5004@15004 master - 0 1653412320000 55 connected 0-3276\r\n51dc2dc93c12dafede60c80fbc8c863f567ea471 192.168.100.41:5004@15004 slave 8b52c017790fcbc707d97a665573073ad1f618ca 0 1653412316000 55 connected\r\n45f0ac04929c8f6f9420cc36bb48274a1db46ba0 192.168.100.44:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653412316000 41 connected\r\n0b42f5d63a26f95e4d4061e6476099242efa29a2 192.168.100.42:5006@15006 master - 0 1653412317848 54 connected 6554-9829\r\n3640507d72415a87c5409b4ebc911abe43956a66 192.168.100.43:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653412317000 41 connected\r\n74a50110f6bf99d651fd029b0e1da4a1b2115044 192.168.100.43:5006@15006 slave 8b52c017790fcbc707d97a665573073ad1f618ca 0 1653412319000 55 connected\r\n```\r\n\r\nAnd a vivid graph :-)\r\n<img width=\"458\" alt=\"Screen Shot 2022-05-24 at 20 18 40\" src=\"https://user-images.githubusercontent.com/191881/170094693-a28cd286-5f5e-4013-ac07-b778a39330a7.png\">\r\n\r\n---\r\n\r\nAfter **rebooting server `.41`**\r\n\r\n`cluster nodes` is still correct:\r\n\r\n```\r\n# redis-cli -h 192.168.100.41 -p 5006 cluster nodes\r\n894eb6eb357de3103a2e778b93358f23be7f68b5 192.168.100.41:5005@15005 slave 0b42f5d63a26f95e4d4061e6476099242efa29a2 0 1653412876000 54 connected\r\n74a50110f6bf99d651fd029b0e1da4a1b2115044 192.168.100.43:5006@15006 slave 8b52c017790fcbc707d97a665573073ad1f618ca 0 1653412878287 55 connected\r\n51dc2dc93c12dafede60c80fbc8c863f567ea471 192.168.100.41:5004@15004 slave 8b52c017790fcbc707d97a665573073ad1f618ca 0 1653412877278 55 connected\r\ne2e34814fa91b3ce49378210b2227d2b88f7c30f 192.168.100.43:5004@15004 slave 0b42f5d63a26f95e4d4061e6476099242efa29a2 0 1653412876000 54 connected\r\n226106848958b59199f2c253966a14c39b0e1f38 192.168.100.42:5005@15005 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653412875000 23 connected\r\nc888ce5346a2458224b07dee3578870d74a91f46 192.168.100.44:5004@15004 slave fab0578f1a3890740b97453d2c5c70f4999f01e1 0 1653412875000 42 connected\r\n0b42f5d63a26f95e4d4061e6476099242efa29a2 192.168.100.42:5006@15006 master - 0 1653412876580 54 connected 6554-9829\r\n8b52c017790fcbc707d97a665573073ad1f618ca 192.168.100.42:5004@15004 master - 0 1653412875000 55 connected 0-3276\r\n95d46662312d464e6969c84e727932367b05032c 192.168.100.44:5006@15006 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653412876000 23 connected\r\nfab0578f1a3890740b97453d2c5c70f4999f01e1 192.168.100.45:5006@15006 master - 0 1653412877590 42 connected 9830-13106\r\n096e6fb32cc6ebe8ba2fe61def121f9b5c51216a 192.168.100.41:5006@15006 myself,slave fab0578f1a3890740b97453d2c5c70f4999f01e1 0 1653412873000 42 connected\r\na1fbcbff7da750ec8d33bf14a59b913dffeceb7f 192.168.100.45:5005@15005 master - 0 1653412876000 41 connected 3277-6553\r\n89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 192.168.100.45:5004@15004 master - 0 1653412875275 23 connected 13107-16383\r\n3640507d72415a87c5409b4ebc911abe43956a66 192.168.100.43:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653412877000 41 connected\r\n45f0ac04929c8f6f9420cc36bb48274a1db46ba0 192.168.100.44:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653412877585 41 connected\r\n```\r\n\r\n<img width=\"525\" alt=\"Screen Shot 2022-05-24 at 20 23 06\" src=\"https://user-images.githubusercontent.com/191881/170095411-1bf3c4a7-440d-4cdc-9cf2-a64dc97a3aae.png\">\r\n\r\n---\r\n\r\n* **rebooting server `.45`**, `cluster nodes` still correct (same as above)\r\n* **rebooting `.41` and `.45`**, cluster configuration is still correct.\r\n* **rebooting `.41`, `.44` and `.45`**, cluster configuration is still correct.\r\n* **rebooting all hosts**... x2\r\n* **rebooting server `.42`**... finally got an inconsistency\r\n\r\nHere's the output of `cluster nodes`:\r\n\r\n```sh\r\n# redis-cli -h 192.168.100.41 -p 5006 cluster nodes\r\na1fbcbff7da750ec8d33bf14a59b913dffeceb7f 192.168.100.45:5005@15005 master - 0 1653415037000 41 connected 3277-6553\r\nfab0578f1a3890740b97453d2c5c70f4999f01e1 192.168.100.45:5006@15006 master - 0 1653415040552 42 connected 9830-13106\r\n894eb6eb357de3103a2e778b93358f23be7f68b5 192.168.100.41:5005@15005 master - 0 1653415038000 57 connected 6554-9829\r\n89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 192.168.100.45:5004@15004 master - 0 1653415042158 23 connected 13107-16383\r\n74a50110f6bf99d651fd029b0e1da4a1b2115044 192.168.100.43:5006@15006 slave 51dc2dc93c12dafede60c80fbc8c863f567ea471 0 1653415039147 56 connected\r\ne2e34814fa91b3ce49378210b2227d2b88f7c30f 192.168.100.43:5004@15004 slave 894eb6eb357de3103a2e778b93358f23be7f68b5 0 1653415037641 57 connected\r\n8b52c017790fcbc707d97a665573073ad1f618ca 192.168.100.42:5004@15004 slave 51dc2dc93c12dafede60c80fbc8c863f567ea471 0 1653415041556 56 connected\r\n3640507d72415a87c5409b4ebc911abe43956a66 192.168.100.43:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653415041154 41 connected\r\n51dc2dc93c12dafede60c80fbc8c863f567ea471 192.168.100.41:5004@15004 master - 0 1653415040000 56 connected 0-3276\r\n226106848958b59199f2c253966a14c39b0e1f38 192.168.100.42:5005@15005 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653415039000 23 connected\r\nc888ce5346a2458224b07dee3578870d74a91f46 192.168.100.44:5004@15004 slave fab0578f1a3890740b97453d2c5c70f4999f01e1 0 1653415038544 42 connected\r\n45f0ac04929c8f6f9420cc36bb48274a1db46ba0 192.168.100.44:5005@15005 slave a1fbcbff7da750ec8d33bf14a59b913dffeceb7f 0 1653415038143 41 connected\r\n096e6fb32cc6ebe8ba2fe61def121f9b5c51216a 192.168.100.41:5006@15006 myself,slave 894eb6eb357de3103a2e778b93358f23be7f68b5 0 1653415036000 57 connected\r\n0b42f5d63a26f95e4d4061e6476099242efa29a2 192.168.100.42:5006@15006 slave 894eb6eb357de3103a2e778b93358f23be7f68b5 0 1653415040151 57 connected\r\n95d46662312d464e6969c84e727932367b05032c 192.168.100.44:5006@15006 slave 89b83937cb7e478bc97a1b7fa0ab12225eeaec1f 0 1653415040552 23 connected\r\n```\r\n"
    },
    {
      "id": 1136312814,
      "user": "j3k0",
      "created_at": "2022-05-24T18:46:24Z",
      "body": "@hwware I apologize for having you look into docker-compose, useful skill but might have not be necessary for this issue.\r\n\r\nAfter having reproducing the issue, it's strange that the same \"red\" node `x.41:5006` was again migrated (when rebooting a machine that has nothing to do with the `x.44.5004,x.45:5006,x.41.5006` group (node `x.42`).\r\n\r\nVivid graph of the new configuration.\r\n\r\n<img width=\"688\" alt=\"Screen Shot 2022-05-24 at 21 01 49\" src=\"https://user-images.githubusercontent.com/191881/170107875-1ed31b64-8894-4819-9341-18abbbc29aea.png\">\r\n\r\nAnnotated logs of node `41.5006`:\r\n\r\nLog starts when I rebooted all nodes:\r\n```\r\n1:signal-handler (1653414425) Received SIGTERM scheduling shutdown...\r\n1:S 24 May 2022 17:47:05.967 # User requested shutdown...\r\n1:S 24 May 2022 17:47:05.968 # Redis is now ready to exit, bye bye...\r\n1:C 24 May 2022 17:48:23.600 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\r\n```\r\n\r\nHost going up...\r\n```\r\n1:C 24 May 2022 17:48:23.600 # Redis version=6.2.6, bits=64, commit=00000000, modified=0, pid=1, just started\r\n1:C 24 May 2022 17:48:23.600 # Configuration loaded\r\n1:M 24 May 2022 17:48:23.602 # Server initialized\r\n1:M 24 May 2022 17:48:23.603 # Done loading RDB, keys loaded: 0, keys expired: 0.\r\n1:S 24 May 2022 17:48:23.603 # Cluster state changed: ok\r\n1:S 24 May 2022 17:48:38.864 # Error condition on socket for SYNC: Connection refused\r\n1:S 24 May 2022 17:48:39.618 # Done loading RDB, keys loaded: 0, keys expired: 0.\r\n```\r\n\r\nNow rebooting host `x.42`.\r\n```\r\n1:S 24 May 2022 17:54:07.082 # Cluster state changed: fail\r\n1:S 24 May 2022 17:54:07.954 # Cluster state changed: ok\r\n1:S 24 May 2022 17:54:08.518 # Cluster state changed: fail\r\n1:S 24 May 2022 17:54:09.369 # Cluster state changed: ok\r\n1:S 24 May 2022 17:54:14.421 # Migrating to orphaned master 894eb6eb357de3103a2e778b93358f23be7f68b5\r\n1:M 24 May 2022 17:54:14.421 # Connection with master lost.\r\n1:S 24 May 2022 17:54:14.448 # Done loading RDB, keys loaded: 0, keys expired: 0.\r\n```\r\n\r\n2 things I notice:\r\n\r\n- **Cluster state changed: fail**\r\n- **Migrating to orphaned master 894eb6eb357de3103a2e778b93358f23be7f68b5**, which is the unwanted action taken by this node.\r\n"
    },
    {
      "id": 1136691732,
      "user": "uvletter",
      "created_at": "2022-05-25T03:42:23Z",
      "body": "I think I grasp the reason, the key clue is `Migrating to orphaned master 894eb6eb357de3103a2e778b93358f23be7f68b5`, which means the reboot trigger the CLUSTER-slave-migration strategy unintentionally.\r\n```\r\n * CLUSTER slave migration\r\n *\r\n * Slave migration is the process that allows a slave of a master that is\r\n * already covered by at least another slave, to \"migrate\" to a master that\r\n * is orpaned, that is, left with no working slaves.\r\n```\r\nLet me reproduce the process. After rebooting host x.42, now only node `x.41:5006`  is left in the group(`x.43:5004` is also unavailable now as x.43 is in reboot), so node `x.41:5006` is orphan.  Slave node `x.42:5006` found it and join the group `x.41:5006` belongs to voluntarily. After x.43 and x.42 complete the rebooting, the node `x.41:5006` will have 3 slaves.\r\n\r\nAs for the log `Cluster state changed: fail`, it's reported when there're unavailable master, e.g. the host where a master resides is in rebooting. It turn to `Cluster state changed: ok` when the failover is done and a slave is promoted to new master. \r\n\r\nSo if you wanna forbid the misjoin-like behavior, keeping every master with at least one slave should be ok\r\n"
    },
    {
      "id": 1138193141,
      "user": "j3k0",
      "created_at": "2022-05-26T06:15:00Z",
      "body": "Thanks @uvletter!\r\n\r\nIt's still probably a bug that a replica ended up replicating another replica, or is this an acceptable behavior?\r\n\r\nAnyway, I learned something (didn't know of that auto-migration behavior), which I believe I can prevent in my case by setting `cluster-migration-barrier` to `2`, as such a replica won't ever found itself in a position it can decide to migrate automatically. My \"requirement\" is that I know I can **always** loose any 2 hosts and be fine. Auto-migrations break that requirement in my case.\r\n\r\nThanks again for looking into this."
    },
    {
      "id": 1138644570,
      "user": "uvletter",
      "created_at": "2022-05-26T14:33:32Z",
      "body": "I think the configuration `cluster-allow-replica-migration` satisfy your requirement :-)"
    }
  ]
}