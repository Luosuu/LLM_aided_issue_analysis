{
  "issue_number": 12316,
  "title": "set storage.flow-control.enable: false，the transaction OPS drops to 0. after the load is stopped, connect to tidb cluster executes SQL statements without response",
  "body": "## Bug Report\r\n\r\n<!-- Thanks for your bug report! Don't worry if you can't fill out all the sections. -->\r\n\r\n### What version of TiKV are you using?\r\n```\r\n[2022/03/31 05:02:26.669 +00:00] [INFO] [lib.rs:80] [\"Welcome to TiKV\"]\r\n[2022/03/31 05:02:26.670 +00:00] [INFO] [lib.rs:85] [\"Release Version:   6.0.0-alpha\"]\r\n[2022/03/31 05:02:26.670 +00:00] [INFO] [lib.rs:85] [\"Edition:           Community\"]\r\n[2022/03/31 05:02:26.670 +00:00] [INFO] [lib.rs:85] [\"Git Commit Hash:   5ee7d037d4e2e63d710410daac81baca7e9efe69\"]\r\n[2022/03/31 05:02:26.670 +00:00] [INFO] [lib.rs:85] [\"Git Commit Branch: heads/refs/tags/v6.1.0-alpha\"]\r\n[2022/03/31 05:02:26.670 +00:00] [INFO] [lib.rs:85] [\"UTC Build Time:    Unknown (env var does not exist when building)\"]\r\n[2022/03/31 05:02:26.670 +00:00] [INFO] [lib.rs:85] [\"Rust Version:      rustc 1.60.0-nightly (1e12aef3f 2022-02-13)\"]\r\n[2022/03/31 05:02:26.670 +00:00] [INFO] [lib.rs:85] [\"Enable Features:   jemalloc mem-profiling portable sse test-engines-rocksdb cloud-aws cloud-gcp cloud-azure\"]\r\n[2022/03/31 05:02:26.670 +00:00] [INFO] [lib.rs:85] [\"Profile:           dist_release\"]\r\n[2022/03/31 05:02:26.670 +00:00] [INFO] [mod.rs:73] [\"cgroup quota: memory=9223372036854771712, cpu=None, cores={1, 3, 2, 5, 6, 7, 0, 4}\"]\r\n[2022/03/31 05:02:26.672 +00:00] [INFO] [mod.rs:80] [\"memory limit in bytes: 17056027648, cpu cores quota: 8\"]\r\n```\r\n\r\n### What operating system and CPU are you using?\r\n`do not care`\r\n\r\n### Steps to reproduce\r\n```\r\ntikv set the following configuration to produces write stall\r\ntikv:\r\n    raftstore.consistency-check-interval: 10s\r\n    rocksdb.defaultcf.level0-slowdown-writes-trigger: 1\r\n    rocksdb.defaultcf.max-write-buffer-number: 1\r\n    rocksdb.lockcf.level0-slowdown-writes-trigger: 1\r\n    rocksdb.lockcf.max-write-buffer-number: 1\r\n    rocksdb.writecf.level0-slowdown-writes-trigger: 1\r\n    rocksdb.writecf.max-write-buffer-number: 1\r\n    storage.flow-control.enable: false\r\n\r\nset store limit：\r\n{\r\n  \"1\": {\r\n    \"add-peer\": 100,\r\n    \"remove-peer\": 100\r\n  },\r\n  \"4\": {\r\n    \"add-peer\": 100,\r\n    \"remove-peer\": 100\r\n  },\r\n  \"5\": {\r\n    \"add-peer\": 100,\r\n    \"remove-peer\": 100\r\n  }\r\n}\r\n\r\nexecute utf case as  the following: \r\ncase code :https://github.com/pingcap/automated-tests/pull/1026\r\ncase as follow\r\n   \"cases\": [\r\n      {\r\n         \"impl\": \"GCTest\",\r\n         \"meta\": {\r\n            \"components\": [\r\n               \"tidb/transaction\"\r\n            ],\r\n            \"maintainers\": [\r\n               \"zhaoyu@pingcap.com\"\r\n            ]\r\n         },\r\n         \"name\": \"CompationGCHighConcurrentWrite\",\r\n         \"params\": {\r\n            \"change_compaction_filter\": false,\r\n            \"clear_tran_config\": [ ],\r\n            \"config\": [ ],\r\n            \"ddl_theads\": 20,\r\n            \"load_runtime\": \"6h\",\r\n            \"load_theads\": 600,\r\n            \"prepare_data_num\": 1000000,\r\n            \"prepare_data_size\": 10,\r\n            \"prepare_table_num\": 32,\r\n            \"safepoint_check_interval\": \"20m\"\r\n         },\r\n         \"resources\": {\r\n            \"tidb\": \"tidb-compation-gc\"\r\n         }\r\n      },\r\n   ],\r\n```\r\n\r\n\r\n### What did you expect?\r\n\r\n`case run success.`\r\n\r\n### What did happened?\r\n\r\n```\r\nI see that write stall is generated. About one hour after the use case is executed, the use case fails to run. At this time, check the monitoring information in grafana, the transaction OPS drops 0, the thread CPU drops 0, and a large number of pending commands are generated.After stopping the load for a long time, connect to the tidb cluster to execute SQL operations and do not return for a long time.\r\nThe possible reason is that the configuration item level0-slowdown-writes-trigger =1 is smaller than the configuration item level0-file-num-compaction-trigger = 4.\r\n\r\nCheck the tidb log, the following logs exist:\r\n[2022/03/30 20:41:00.047 +00:00] [INFO] [region_cache.go:1617] [\"region epoch is ahead of tikv\"] [error=\"region epoch is ahead of tikv. rpc ctx: region ID: 15711373, meta: id:15711373 start_key:\\\"t\\\\200\\\\000\\\\000\\\\000\\\\000\\\\005\\\\005r_r\\\\200\\\\000\\\\000\\\\000\\\\000\\\\005f\\\\337\\\" end_key:\\\"t\\\\200\\\\000\\\\000\\\\000\\\\000\\\\005\\\\005r_r\\\\200\\\\000\\\\000\\\\000\\\\000\\\\006\\\\316\\\\324\\\" region_epoch:<conf_ver:33 version:650411 > peers:<id:15711374 store_id:1 > peers:<id:15711375 store_id:4 > peers:<id:15711376 store_id:5 > , peer: id:15711376 store_id:5 , addr: 172.16.4.159:20260, idx: 0, reqStoreType: TiKvOnly, runStoreType: tikv, currentRegions: [id:15711373 start_key:\\\"t\\\\200\\\\000\\\\000\\\\000\\\\000\\\\005\\\\005\\\\377r_r\\\\200\\\\000\\\\000\\\\000\\\\000\\\\377\\\\003\\\\322W\\\\000\\\\000\\\\000\\\\000\\\\000\\\\372\\\" end_key:\\\"t\\\\200\\\\000\\\\000\\\\000\\\\000\\\\005\\\\005\\\\377r_r\\\\200\\\\000\\\\000\\\\000\\\\000\\\\377\\\\006\\\\316\\\\324\\\\000\\\\000\\\\000\\\\000\\\\000\\\\372\\\" region_epoch:<conf_ver:33 version:650410 > peers:<id:15711374 store_id:1 > peers:<id:15711375 store_id:4 > peers:<id:15711376 store_id:5 > ]\"]\r\n[2022/03/30 20:41:00.048 +00:00] [INFO] [2pc.go:1105] [\"send TxnHeartBeat\"] [startTS=432189692886384929] [newTTL=40349]\r\n[2022/03/30 20:41:00.047 +00:00] [WARN] [region_request.go:1404] [\"tikv reports `ServerIsBusy` retry later\"] [reason=\"deadline is exceeded\"] [ctx=\"region ID: 15654481, meta: id:15654481 start_key:\\\"t\\\\200\\\\000\\\\000\\\\000\\\\000\\\\005\\\\304\\\\257_r\\\\200\\\\000\\\\000\\\\000\\\\000-\\\\241\\\\201\\\" end_key:\\\"t\\\\200\\\\000\\\\000\\\\000\\\\000\\\\005\\\\304\\\\262_i\\\\200\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\001\\\\001YRSsMfsv\\\\377xo\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\371\\\\003\\\\200\\\\000\\\\000\\\\000\\\\000\\\\005;\\\\026\\\" region_epoch:<conf_ver:33 version:644448 > peers:<id:15654482 store_id:1 > peers:<id:15654483 store_id:4 > peers:<id:15654484 store_id:5 > , peer: id:15654484 store_id:5 , addr: 172.16.4.159:20260, idx: 0, reqStoreType: TiKvOnly, runStoreType: tikv\"]\r\n```\r\n\r\n\r\n\r\n",
  "state": "closed",
  "created_at": "2022-03-31T09:13:55Z",
  "updated_at": "2023-10-24T00:51:02Z",
  "closed_at": "2023-10-24T00:51:02Z",
  "labels": [
    "type/bug",
    "severity/moderate"
  ],
  "comments_data": [
    {
      "id": 1084540180,
      "user": "vivid392845427",
      "created_at": "2022-03-31T12:53:37Z",
      "body": "/type bug"
    },
    {
      "id": 1085337324,
      "user": "Lily2025",
      "created_at": "2022-04-01T02:18:04Z",
      "body": "/severity Moderate\r\n/assign Connor1996"
    },
    {
      "id": 1776282445,
      "user": "tonyxuqqi",
      "created_at": "2023-10-24T00:50:59Z",
      "body": "It's by design as disabling flow control would effectively falls back to write stall. "
    }
  ]
}