{
  "issue_number": 15003,
  "title": "tikv panic when tikv exit the import mode but import process is still not stopped during \"import into\" command is cancelled",
  "body": "## Bug Report\r\n\r\n<!-- Thanks for your bug report! Don't worry if you can't fill out all the sections. -->\r\n\r\n### What version of TiKV are you using?\r\nmaster\r\n\r\n### What operating system and CPU are you using?\r\n<!-- If you're using Linux, you can run `cat /proc/cpuinfo` -->\r\n\r\n### Steps to reproduce\r\n1. set global tidb_enable_dist_task=off;\r\n2. IMPORT INTO big.items  FROM \"s3://tmp/9T-csv/big.items.*.csv?access-key=minioadmin&secret-access-key=minioadmin&endpoint=http%3a%2f%2f10.2.12.100%3a32762&force-path-style=true\" with thread=16,detached;\r\n3. cancel this job \r\n4. clear table of big.items\r\n5. set global tidb_enable_dist_task=on;\r\n6. execute import into command again\r\n\r\n### What did you expect?\r\nimport job can be successfully\r\n### What did happened?\r\n```\r\n[2023/06/26 03:25:03.580 +00:00] [FATAL] [[lib.rs:497](http://lib.rs:497/)] [\"[region 15563512] 15563513 ingest uuid: 5ACC4E816AC84B9682AA3E6985C3B924 range { start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end: 7480000000000000FF665F698000000000FF000008014A6E4D66FF34574B4EFF746E4AFF3078783263FF4850FF6A416778786CFF47FF426E456A527279FFFF3034353743715247FFFF71555438506E59FF49FF576736306B77FF574FFF6A61796959FF555236FF426F4643FF664C4875FF6E434FFF6D62794878FF304BFF544442704B67FF4BFF4C70504A69645AFFFF51636E6E414D5746FFFF3152587454694CFF6BFF69757341344FFF5036FF3245497665FF33366BFF6F4E5072FF336A5668FF7A7745FF7150556B66FF4579FF784F71496458FF4EFF613979546A7A4DFFFF454662456E394B30FFFF73736272447439FF4AFF786E3771556DFF7246FF3877325744FF4A326FFF4C415943FF6478566DFF327867FF4A38723378FF5367FF64497230624FFF49FF6637484C554863FFFF5A78594A57434843FFFF70395050686F4AFF6EFF74656D417971FF3850FF526D6E6F7AFF425258FF6E545331FF59706542FF487356FF3344555967FF4B62FF57644B7A496EFF30FF6372714C53354CFFFF6851515A5A796B6AFFFF78486C4D6F5A51FF57FF685A5870486DFF594DFF50585A5A62FF325346FF6F59496AFF73714F48FF634267FF56496E5347FF4546FF684B514E5144FF47FF4C424930614A72FFFF5A674C6D7136416EFFFF506F6444346935FF68FF334C79786E4AFF3365FF5342525551FF335379FF39495479FF566A5856FF386C48FF3350445365FF7A50FF43726D4C576BFF4DFF4B6B7067305778FFFF6D6A6C7534634856FFFF3976675051464BFF43FF34354C616B30FF5148FF776B436E45FF47546FFF61427432FF6B6B4342FF59714CFF4E7A4A736DFF514DFF50726D6E7432FF32FF325754776A5A6CFFFF4C4531596B6B4B6CFFFF4E616\r\n```",
  "state": "closed",
  "created_at": "2023-06-26T06:48:24Z",
  "updated_at": "2024-08-06T05:08:03Z",
  "closed_at": "2023-10-16T17:56:01Z",
  "labels": [
    "type/bug",
    "severity/major",
    "affects-6.5",
    "affects-7.1",
    "affects-7.5",
    "component/lightning"
  ],
  "comments_data": [
    {
      "id": 1606806695,
      "user": "seiya-annie",
      "created_at": "2023-06-26T06:53:05Z",
      "body": "[tikv.log.gz](https://github.com/tikv/tikv/files/11865225/tikv.log.gz)\r\n"
    },
    {
      "id": 1606819939,
      "user": "seiya-annie",
      "created_at": "2023-06-26T06:56:51Z",
      "body": "when import job is cancelled, status maybe not updated in time, import job will still running for a while, but at this time, tikv has been exit the import mode. this may lead to the panic"
    },
    {
      "id": 1606831855,
      "user": "D3Hunter",
      "created_at": "2023-06-26T07:03:25Z",
      "body": "stack\r\n```\r\n[2023/06/25 11:10:23.597 +00:00] [FATAL] [lib.rs:497] [\"[region 15563512] 15563513 ingest uuid: 5ACC4E816AC84B9682AA3E6985C3B924 range { start: 7480000000000000FF665F698000000000FF000008014A6C3179FF6F6163\r\n62FF456879FF7555526174FF517AFF7667316B5654FF64FF6646714B633253FFFF44397650414D446DFFFF436D7635466E55FF66FF32636C364249FF5775FF5042516472FF386642FF38555145FF57317630FF594A58FF56346D6146FF5738FF3536436B4D61\r\nFF53FF326E4568465470FFFF64726C6C564F4949FFFF354C3239316F54FF36FF73314B345246FF344AFF64704D7045FF376A52FF3252396CFF556F4A5AFF69646FFF4E76575546FF6979FF6F507A5A4C37FF33FF71724451683566FFFF5749795373574B48FF\r\nFF77566E6B35474BFF68FF33396E494875FF3958FF625A6B4769FF386955FF664B676AFF666D5875FF525049FF536261477AFF7773FF637A39506C63FF4AFF4B6D396C554143FFFF4955587951713571FFFF6A516D485A5557FF4AFF767230674865FF7243FF\r\n4767573468FF687234FF687A324CFF31776C47FF555471FF4C43436D30FF304BFF465379454878FF67FF3961674E486D68FFFF4C415A7633645749FFFF63524D6E464343FF66FF6C6567304536FF5856FF763853786DFF377134FF32586A54FF76446171FF65\r\n5964FF4D48746D78FF314AFF53437857547AFF56FF6944776D654737FFFF6847485166333231FFFF76346B33494D68FF55FF3651726D3346FF6457FF3248587442FF4F6A6BFF784C6457FF77796D46FF704C36FF63714F4476FF7177FF645772693275FF31FF\r\n4D5A4967746F36FFFF516B70676A637445FFFF7144446C6C4149FF33FF72584E67434CFF7438FF3251504632FF745437FF63386A41FF6158434DFF4D6E69FF4935307259FF6236FF645970573658FF31FF75697A7A427352FFFF47315453755A3757FFFF6D33\r\n4A30615934FF6CFF45646466455AFF4972FF6661324C48FF62526FFF4B357438FF54666145FF59396AFF5444774A35FF7233FF68654B556E78FF57FF514D30664D6664FFFF6B4F39446B435774FFFF4765796968356EFF4EFF79466D5A446CFF567AFF657556\r\n4A44FF4A556EFF5854544CFF546E4C4FFF667143FF4644535849FF3167FF746C357A754BFF4CFF707A3468715837FFFF6731526368445273FFFF6B7870524E3137FF65FF4E5041333547FF6D38FF5A7272494FFF516D66FF32646C6AFF49446D71FF554C75FF\r\n4E43756775FF5739FF61425568586AFF58FF567773364A5143FFFF6477513754594E4EFFFF574B7551657947FF42FF75784D5A4D42FF5579FF3647683356FF327867FF71335468FF41303168FF6F6337FF7945486974FF4B75FF327847396F45FF34FF395435\r\n50693257FFFF52687A314A484C31FFFF667332524B544AFF6AFF5A51766A4E44FF7441FF396577466BFF787968FF6A493875FF66385241FF386342FF4432516167FF6A75FF353474734838FF62FF36433856474559FFFF0000000000000000FFF7016E6F6465\r\n3054FF3234FF497350516FFF4F556CFF4E305059FF61795973FF637578FF524F6E4E79FF4F73FF616273776353FF56FF354356346B6D53FFFF3668536551596743FFFF7171677464744BFF6EFF4D5346703047FF695AFF4948735672FF715536FF4443524FFF\r\n72494F4EFF673248FF38324C5A70FF5747FF446B76334F55FF39FF776F3571636242FFFF4247336974667332FFFF306F6561745056FF56FF5A7A344B7569FF3130FF4453704435FF4A6C6DFF4D553642FF37644D6FFF6D737AFF5468674F61FF5754FF55506A\r\n326264FF79FF3034674D536C57FFFF7272304279374E46FFFF35514D46523666FF64FF775641466A64FF4E4DFF7172434A5AFF627165FF616F3247FF5A343871FF676A45FF4473564F66FF4C00FF000000000000F800FE end: 7480000000000000FF665F69\r\n8000000000FF000008014A6E4D66FF34574B4EFF746E4AFF3078783263FF4850FF6A416778786CFF47FF426E456A527279FFFF3034353743715247FFFF71555438506E59FF49FF576736306B77FF574FFF6A61796959FF555236FF426F4643FF664C4875FF6E\r\n434FFF6D62794878FF304BFF544442704B67FF4BFF4C70504A69645AFFFF51636E6E414D5746FFFF3152587454694CFF6BFF69757341344FFF5036FF3245497665FF33366BFF6F4E5072FF336A5668FF7A7745FF7150556B66FF4579FF784F71496458FF4EFF\r\n613979546A7A4DFFFF454662456E394B30FFFF73736272447439FF4AFF786E3771556DFF7246FF3877325744FF4A326FFF4C415943FF6478566DFF327867FF4A38723378FF5367FF64497230624FFF49FF6637484C554863FFFF5A78594A57434843FFFF7039\r\n5050686F4AFF6EFF74656D417971FF3850FF526D6E6F7AFF425258FF6E545331FF59706542FF487356FF3344555967FF4B62FF57644B7A496EFF30FF6372714C53354CFFFF6851515A5A796B6AFFFF78486C4D6F5A51FF57FF685A5870486DFF594DFF50585A\r\n5A62FF325346FF6F59496AFF73714F48FF634267FF56496E5347FF4546FF684B514E5144FF47FF4C424930614A72FFFF5A674C6D7136416EFFFF506F6444346935FF68FF334C79786E4AFF3365FF5342525551FF335379FF39495479FF566A5856FF386C48FF\r\n3350445365FF7A50FF43726D4C576BFF4DFF4B6B7067305778FFFF6D6A6C7534634856FFFF3976675051464BFF43FF34354C616B30FF5148FF776B436E45FF47546FFF61427432FF6B6B4342FF59714CFF4E7A4A736DFF514DFF50726D6E7432FF32FF325754\r\n776A5A6CFFFF4C4531596B6B4B6CFFFF4E616E784A4555FF31FF74354A58555AFF5750FF4D6C6C5A70FF78556FFF62777A7AFF534C3850FF753769FF7859354846FF3447FF5874754E3131FF32FF6F5A4D5549546BFFFF33416F6251485950FFFF4D51466873\r\n586CFF6CFF494C7865574DFF6436FF6735714957FF554147FF34707174FF75483633FF366768FF4774784F52FF7262FF546868534666FF74FF5175507A4A5446FFFF3975473673706830FFFF4C63636D6C6868FF43FF486678593038FF6374FF5A3569344EFF\r\n695147FF44584463FF51336755FF4A3650FF6E56356F30FF7061FF677833696937FF49FF4E6454334D7134FFFF6F41513575506C6BFFFF5A376467306541FF47FF4A5136503356FF7439FF50656B3976FF6D524EFF67566153FF71726C6BFF39584CFF4D6556\r\n6C4AFF6474FF5648766C774FFF50FF45466C37505869FFFF6D64696469423470FFFF5350343956644EFF6DFF6C3063384635FF7073FF6374714353FF52444BFF65454569FF7A734278FF446752FF4A6549304CFF364AFF75593345354EFF4AFF386679645A41\r\n69FFFF0000000000000000FFF7016E6F64653062FF357AFF6556444654FF49447AFF4B4A5472FF6473507AFF756546FF3377784163FF5A47FF636E784D5655FF47FF6C4A32674A344FFFFF657565574549376BFFFF70547471375034FF6FFF586B79563549FF\r\n695147FF44584463FF51336755FF4A3650FF6E56356F30FF7061FF677833696937FF49FF4E6454334D7134FFFF6F41513575506C6BFFFF5A376467306541FF47FF4A5136503356FF7439FF50656B3976FF6D524EFF67566153FF71726C6BFF39584CFF4D6556\r\n6C4AFF6474FF5648766C774FFF50FF45466C37505869FFFF6D64696469423470FFFF5350343956644EFF6DFF6C3063384635FF7073FF6374714353FF52444BFF65454569FF7A734278FF446752FF4A6549304CFF364AFF75593345354EFF4AFF386679645A41\r\n69FFFF0000000000000000FFF7016E6F64653062FF357AFF6556444654FF49447AFF4B4A5472FF6473507AFF756546FF3377784163FF5A47FF636E784D5655FF47FF6C4A32674A344FFFFF657565574549376BFFFF70547471375034FF6FFF586B79563549FF\r\n4A46FF70376E4A34FF4F4A49FF476D417AFF33506869FF454870FF44344C6270FF4274FF335047637241FF70FF7835794138614EFFFF62546B45334A414AFFFF77375357526143FF52FF537854763933FF4653FF6C546B724CFF33744DFF6A464563FF316532\r\n4DFF6C654EFF42386E5572FF4850FF564665494B57FF34FF4C386557766357FFFF7567635752723943FFFF68584657414E72FF4AFF556E4C4C4748FF5747FF4A39545173FF765241FF46686F64FF42746B70FF693655FF7448647351FF6900FF000000000000\r\nF800FE } cf_name: \\\"write\\\" region_id: 15563512 region_epoch { conf_ver: 47 version: 734 }: EngineTraits(Engine(Status { code: IoError, sub_code: None, sev: NoError, state: \\\"IO error: No such file or dir\r\nectory: while stat a file for size: /var/lib/tikv/data/import/5acc4e81-6ac8-4b96-82aa-3e6985c3b924_15563512_47_734_write.sst: No such file or directory\\\" }))\"] [backtrace=\"   0: tikv_util::set_panic_hook:\r\n:{{closure}}\r\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/tikv_util/src/lib.rs:496:18\r\n   1: <alloc::boxed::Box<F,A> as core::ops::function::Fn<Args\r\n>>::call\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/alloc/src/boxed.rs:2032:9\r\n      std::panicking::rust_panic_with_hook\r\n             at ru\r\nst/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/panicking.rs:692:13\r\n   2: std::panicking::begin_panic_handler::{{closure}}\r\n             at rust/toolchains/\r\nnightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/panicking.rs:579:13\r\n   3: std::sys_common::backtrace::__rust_end_short_backtrace\r\n             at rust/toolchains/nightly-\r\n2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/sys_common/backtrace.rs:137:18\r\n   4: rust_begin_unwind\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gn\r\nu/lib/rustlib/src/rust/library/std/src/panicking.rs:575:5\r\n   5: core::panicking::panic_fmt\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/s\r\nrc/panicking.rs:65:14\r\n   6: raftstore::store::fsm::apply::ApplyDelegate<EK>::handle_ingest_sst\r\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftsto\r\nre/src/store/fsm/apply.rs:2005:17\r\n      raftstore::store::fsm::apply::ApplyDelegate<EK>::exec_write_cmd\r\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/component\r\ns/raftstore/src/store/fsm/apply.rs:1755:39\r\n      raftstore::store::fsm::apply::ApplyDelegate<EK>::exec_raft_cmd\r\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/c\r\nomponents/raftstore/src/store/fsm/apply.rs:1678:13\r\n      raftstore::store::fsm::apply::ApplyDelegate<EK>::apply_raft_cmd\r\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingc\r\nap/tikv/components/raftstore/src/store/fsm/apply.rs:1442:45\r\n   7: raftstore::store::fsm::apply::ApplyDelegate<EK>::process_raft_cmd\r\n             at home/jenkins/agent/workspace/build-common/go/src/githu\r\nb.com/pingcap/tikv/components/raftstore/src/store/fsm/apply.rs:1378:52\r\n   8: raftstore::store::fsm::apply::ApplyDelegate<EK>::handle_raft_entry_normal\r\n             at home/jenkins/agent/workspace/build-\r\ncommon/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/apply.rs:1256:24\r\n      raftstore::store::fsm::apply::ApplyDelegate<EK>::handle_raft_committed_entries\r\n             at home/jenkin\r\ns/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/apply.rs:1130:43\r\n   9: raftstore::store::fsm::apply::ApplyFsm<EK>::resume_pending\r\n             at home/je\r\nnkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/apply.rs:4107:13\r\n      <raftstore::store::fsm::apply::ApplyPoller<EK> as batch_system::batch::PollHand\r\nler<raftstore::store::fsm::apply::ApplyFsm<EK>,raftstore::store::fsm::apply::ControlFsm>>::handle_normal\r\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/component\r\ns/raftstore/src/store/fsm/apply.rs:4588:13\r\n  10: batch_system::batch::Poller<N,C,Handler>::poll\r\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/batch-\r\nsystem/src/batch.rs:422:27\r\n  11: raftstore::store::worker::refresh_config::PoolController<N,C,H>::increase_by::{{closure}}\r\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pin\r\ngcap/tikv/components/raftstore/src/store/worker/refresh_config.rs:83:21\r\n      <std::thread::Builder as tikv_util::sys::thread::StdThreadBuildWrapper>::spawn_wrapper::{{closure}}\r\n             at home/jen\r\nkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/tikv_util/src/sys/thread.rs:427:23\r\n      std::sys_common::backtrace::__rust_begin_short_backtrace\r\n             at rust/toolcha\r\nins/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/sys_common/backtrace.rs:121:18\r\n  12: std::thread::Builder::spawn_unchecked_::{{closure}}::{{closure}}\r\n             at\r\n rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/thread/mod.rs:551:17\r\n       <core::panic::unwind_safe::AssertUnwindSafe<F> as core::ops::function::FnOnce<\r\n()>>::call_once\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src/panic/unwind_safe.rs:271:9\r\n      std::panicking::try::do_call\r\n\r\n    at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/panicking.rs:483:40\r\n          std::panicking::try\r\n                 at rust/toolchains/nightly-2022-11-15-x\r\n86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/std/src/panicking.rs:447:19\r\n      std::panic::catch_unwind\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/sr\r\nc/rust/library/std/src/panic.rs:137:14\r\n      std::thread::Builder::spawn_unchecked_::{{closure}}\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/\r\nstd/src/thread/mod.rs:550:30\r\n      core::ops::function::FnOnce::call_once{{vtable.shim}}\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/core/src\r\n/ops/function.rs:513:5\r\n  13: <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/lib\r\nrary/alloc/src/boxed.rs:2000:9\r\n      <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/\r\nrust/library/alloc/src/boxed.rs:2000:9\r\n      std::sys::unix::thread::Thread::new::thread_start\r\n             at rust/toolchains/nightly-2022-11-15-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/library/st\r\nd/src/sys/unix/thread.rs:108:17\r\n  14: start_thread\r\n  15: clone3\r\n\"] [location=/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/apply.rs:2005]\r\n[thread_name=apply-low-0]\r\n```"
    },
    {
      "id": 1606957339,
      "user": "lance6716",
      "created_at": "2023-06-26T08:24:07Z",
      "body": "import logic is independent with raft, so it's hard to tell whether an intermediate import SST file will be used in future. Because of this, we don't have a simple logic to clean up stale import SST file.\r\n\r\nTake this as an example: clean up thread found there's a import SST file whose region is not at this TiKV (so can't use region epoch to check staleness), but it can't know \r\n- whether the region has been removed from this TiKV, or\r\n- whether the region will be scheduled to this TiKV in following raft log, or\r\n- whether the region will be scheduled to this TiKV in following raft log, and it will be removed afterwards. https://github.com/tikv/tikv/issues/10438#issuecomment-897481656\r\n\r\nin order to solve this problem, we plan to add a synchronize point to the import client (lightning). The import client has a write+ingest protocal like 2 phase commit. When the server receives a \"write\" request, it should return \"retry later\" error to the client when the region is not ready. So for a successful \"write\" request, server can guarantee the following \"ingest\" request must success as long as the region is still on this TiKV and epoch/confver is not changed. And when the region is gone \"ingest\" request must fail because region confver is changed."
    },
    {
      "id": 1606959015,
      "user": "lance6716",
      "created_at": "2023-06-26T08:25:14Z",
      "body": "> import logic is independent with raft, so it's hard to tell whether an intermediate import SST file will be used in future. Because of this, we don't have a simple logic to clean up stale import SST file.\r\n> \r\n> Take this as an example: clean up thread found there's a import SST file whose region is not at this TiKV (so can't use region epoch to check staleness), but it can't know\r\n> \r\n> * whether the region has been removed from this TiKV, or\r\n> * whether the region will be scheduled to this TiKV in following raft log, or\r\n> * whether the region will be scheduled to this TiKV in following raft log, and it will be removed afterwards. [TiKV panic because of ingest files not exist. #10438 (comment)](https://github.com/tikv/tikv/issues/10438#issuecomment-897481656)\r\n> \r\n> in order to solve this problem, we plan to add a synchronize point to the import client (lightning). The import client has a write+ingest protocal like 2 phase commit. When the server receives a \"write\" request, it should return \"retry later\" error to the client when the region is not ready. So for a successful \"write\" request, server can guarantee the following \"ingest\" request must success as long as the region is still on this TiKV. And when the region is gone \"ingest\" request must fail because region confver is changed.\r\n\r\ncan you help check this idea? @Leavrth @Connor1996 @YuJuncen"
    },
    {
      "id": 1607091646,
      "user": "overvenus",
      "created_at": "2023-06-26T09:39:56Z",
      "body": "Could you elaborate on what is causing \"region is not ready\"?\r\n\r\nAFAIK, if a ingest is committed, it will either be applied successfully or it doesn't get applied*, it never fails.\r\n\r\n\\* Apply may be slow and a region is remove by a new region before applying ingest. And the new region must contain ingested data.\r\n\r\n----\r\n\r\nThe panic is more like a bug in cleanup sst task.\r\n"
    },
    {
      "id": 1607098696,
      "user": "lance6716",
      "created_at": "2023-06-26T09:44:17Z",
      "body": "> what is causing \"region is not ready\"?\r\n\r\nhttps://github.com/tikv/tikv/issues/10438#issuecomment-897481656\r\n\r\n> if a ingest is committed, it will either be applied successfully or it doesn't get applied*, it never fails.\r\n\r\nfor \"ingest request must fail\" I mean fail to commit as in handle_ingest_sst\r\n\r\n"
    },
    {
      "id": 1607103096,
      "user": "lance6716",
      "created_at": "2023-06-26T09:47:07Z",
      "body": "> The panic is more like a bug in cleanup sst task.\r\n\r\nYes, and I want to simplify the import logic to fix the cleanup logic. With the changes at import side, cleanup will either left stale SST files or remove them too early when import_mode is off."
    },
    {
      "id": 1608789027,
      "user": "overvenus",
      "created_at": "2023-06-27T04:43:09Z",
      "body": "> > what is causing \"region is not ready\"?\r\n> \r\n> [#10438 (comment)](https://github.com/tikv/tikv/issues/10438#issuecomment-897481656)\r\n\r\nI see. How about let  tikv check region epoch for `write` RPC? If there is no such region or epoch mismatch just fails the RPC and let lightning retry.\r\n\r\n> > if a ingest is committed, it will either be applied successfully or it doesn't get applied*, it never fails.\r\n> \r\n> for \"ingest request must fail\" I mean fail to commit as in handle_ingest_sst\r\n\r\nCurrently, `handle_ingest_sst` never fails unless sst files are removed unexpectedly. \r\n"
    },
    {
      "id": 1608804576,
      "user": "lance6716",
      "created_at": "2023-06-27T05:06:06Z",
      "body": "> How about let tikv check region epoch for write RPC? If there is no such region or epoch mismatch just fails the RPC and let lightning retry.\r\n\r\nI'm doing this. Currently I have added RegionInfoAccessor as a member of ImportSstService, so in write RPC it can check region epoch. But I see RegionInfoAccessor only has a few usage, not sure if this is the recommended way to check region epoch.\r\n\r\n> Currently, handle_ingest_sst never fails unless sst files are removed unexpectedly.\r\n\r\nThe region_id, epoch and conf_ver is encoded in SST filename, and handle_ingest_sst should be able to check them in check_sst_for_ingestion\r\nhttps://github.com/tikv/tikv/blob/bd11fb033e85512f0dd20cffaf1bcefc5e8c0bd6/components/raftstore/src/store/fsm/apply.rs#L1975-L1984"
    },
    {
      "id": 1609793103,
      "user": "D3Hunter",
      "created_at": "2023-06-27T15:50:27Z",
      "body": "some timeline info:\r\n\r\ntidb-2, cancel and exit import mode at `10:51`, but until `11:46` the framework start cancelling subtask, due to tikv flow control, updating system table is slow.\r\n```log\r\n[2023/06/25 10:51:07.775 +00:00] [INFO] [dispatcher.go:304] [\"process flow, handle an error\"] [task-id=1] [\"err msg\"=\"[cancel]\"]\r\n[2023/06/25 10:51:07.775 +00:00] [INFO] [dispatcher.go:280] [\"process error flow\"] [type=ImportInto] [task-id=1] [step=import] [error-message=\"[cancel]\"]\r\n[2023/06/25 10:51:07.776 +00:00] [INFO] [tikv_mode.go:59] [\"switch tikv mode\"] [type=ImportInto] [task-id=1] [step=import] [mode=Normal]\r\n...\r\n[2023/06/25 10:51:08.212 +00:00] [INFO] [dispatcher.go:429] [\"execute sql\"] [type=ImportInto] [task-id=1] [step=import] [sql=\"TRUNCATE `big`.`items`\"] [args=null]\r\n...\r\n[2023/06/25 10:51:08.462 +00:00] [INFO] [ddl.go:1067] [\"[ddl] start DDL job\"] [job=\"ID:105, Type:truncate table, State:queueing, SchemaState:none, SchemaID:100, TableID:102, RowCount:0, ArgLen:3, start ti\r\nme: 2023-06-25 10:51:08.285 +0000 UTC, Err:<nil>, ErrCount:0, SnapshotVersion:0\"] [query=\"TRUNCATE `big`.`items`\"]\r\n[2023/06/25 10:56:02.072 +00:00] [INFO] [ddl.go:1169] [\"[ddl] DDL job is finished\"] [jobID=105]\r\n...\r\n[2023/06/25 11:46:00.143 +00:00] [WARN] [session.go:1287] [sql] [label=internal] [error=\"[kv:8022]Error: KV error safe to retry Error(Txn(Error(Mvcc(Error(TxnLockNotFound { start_ts: TimeStamp(442418566315376641), commit_ts: TimeStamp(442418650083753992), key: [116, 128, 0, 0, 0, 0, 0, 0, 84, 95, 105, 128, 0, 0, 0, 0, 0, 0, 1, 1, 99, 97, 110, 99, 101, 108, 108, 105, 255, 110, 103, 0, 0, 0, 0, 0, 0, 249, 3, 128, 0, 0, 0, 0, 0, 0, 1] }))))) {tableID=84, indexID=1, indexValues={cancelling, 1, }} [try again later]\"] [txn=\"Txn{state=invalid}\"]\r\n[2023/06/25 11:46:08.652 +00:00] [INFO] [manager.go:221] [onCanceledTasks] [dist_task_manager=upstream-tidb-2.upstream-tidb-peer.import-into-20t-tps-1811937-1-810.svc:4000] [id=1]\r\n```\r\ntidb-0\r\n```\r\n[2023/06/25 11:46:08.459 +00:00] [INFO] [manager.go:221] [onCanceledTasks] [dist_task_manager=upstream-tidb-0.upstream-tidb-peer.import-into-20t-tps-1811937-1-810.svc:4000] [id=1]\r\n```\r\n\r\ntikv-2, panic at `11:09`\r\n```log\r\n[2023/06/25 11:09:56.086 +00:00] [FATAL] [lib.rs:497] EngineTraits(Engine(Status { code: IoError, sub_code: None, sev: NoError, state: \\\"IO error: No such file or directory: while stat a file for size:\r\n/var/lib/tikv/data/import/ff428250-5830-4978-849c-e1f1127b3693_15563516_47_734_write.sst: No such file or directory\r\nhandle_ingest_sst\r\n```"
    },
    {
      "id": 1609984562,
      "user": "tonyxuqqi",
      "created_at": "2023-06-27T18:02:30Z",
      "body": "> Currently, handle_ingest_sst never fails unless sst files are removed unexpectedly.\r\n\r\n@overvenus @lance6716 The statement above seems not true. It will check epoch inside check_sst_for_ingestion which is called by handle_ingest_sst. \r\nIt's ok to use RegionInfoAccessor for checking epoch, it's not strictly up-to-date, but it's good enough. \r\nIn case of the stale information, then handle_ingest_sst will still fail the ingestion. \r\n"
    },
    {
      "id": 1609997045,
      "user": "tonyxuqqi",
      "created_at": "2023-06-27T18:10:06Z",
      "body": "> 1 whether the region has been removed from this TiKV, or\r\n> 2 whether the region will be scheduled to this TiKV in following raft log, or\r\n> 3 whether the region will be scheduled to this TiKV in following raft log, and it will be removed afterwards. \r\n> https://github.com/tikv/tikv/issues/10438#issuecomment-897481656\r\n\r\n@lance6716 So do you mean when the SST file is uploaded, in today's code, we don't check if the SST's region is on this TiKV?  If we check it, then 2 or 3 will not happen.  We can only need to deal with 1. And just delete the SST file in cleanup thread if the region cannot be found or epoch is stale. \r\n\r\n\r\n\r\n"
    },
    {
      "id": 1758504165,
      "user": "mittalrishabh",
      "created_at": "2023-10-11T20:39:58Z",
      "body": "Is it concluded that why sst files are cleaned up here ?\r\nI don't find the exact reason in the discussion. "
    },
    {
      "id": 1760048901,
      "user": "tonyxuqqi",
      "created_at": "2023-10-12T17:27:03Z",
      "body": "@mittalrishabh It's about the SST cleaning mechanism. Today a SST can be deleted after it's successfully applied. The problem is when the SST has not been applied, today we don't have a reliable way to tell if the SST is going to be applied or not-----because when uploading SST, TiKV does not check if the SST's region is in that tikv or if the epoch of SST matches the region's epoch. This is because in lightning scenario,  lightning client could upload SST to a TiKV first and then schedule the related regions to that TiKV. \r\nAnd therefore, we introduce a flag called import mode.  When import mode is on, then these SSTs are not deleted even if TiKV does not have their regions (because TiKV think the region will be moved to it later). \r\nThis bug happens when an import job cancels,  the import mode in TiKV exits and thus TiKV cleaning task deletes these SSTs. However, the import job may not stop at same time as the import mode exits in TikV side. And therefore an SST could be mistakenly deleted by TiKV and thus leads to this issue. \r\n\r\nThe fix we're going to do is to make sure SST upload will have to be done after that region is in the TiKV.  And also may optimize the import job cancelation to avoid disparity of timing between import job and tikv import mode. "
    },
    {
      "id": 1774495955,
      "user": "lance6716",
      "created_at": "2023-10-23T06:10:13Z",
      "body": "/affects release-7.5"
    },
    {
      "id": 1776226058,
      "user": "mittalrishabh",
      "created_at": "2023-10-23T23:44:20Z",
      "body": "\r\n>> TiKV does not check if the SST's region is in that tikv  \r\n\r\nHow is that possible. Region is scheduled to that tikv before lightning start sending SST files. And if region moves than ingest RPC should fails because there is no leader.\r\n  "
    }
  ]
}