{
  "issue_number": 12498,
  "title": "RawKV API V2 timestamp causality violation",
  "body": "## Bug Report\r\n\r\n<!-- Thanks for your bug report! Don't worry if you can't fill out all the sections. -->\r\n\r\n### What version of TiKV are you using?\r\n<!-- You can run `tikv-server --version` -->\r\n(A dirty release build of this PR #12490. Will verify again on master after #12490 is merged)\r\n```\r\nTiKV\r\nRelease Version:   6.0.0-alpha\r\nEdition:           Community\r\nGit Commit Hash:   7d46f1b3b955db05562695d2179b10903c301479\r\nGit Commit Branch: master\r\nUTC Build Time:    2022-05-11 06:42:55\r\nRust Version:      rustc 1.60.0-nightly (1e12aef3f 2022-02-13)\r\nEnable Features:   jemalloc mem-profiling portable sse test-engine-kv-rocksdb test-engine-raft-raft-engine cloud-aws cloud-gcp cloud-azure\r\nProfile:           release\r\n```\r\n\r\n### What operating system and CPU are you using?\r\n<!-- If you're using Linux, you can run `cat /proc/cpuinfo` -->\r\nCentOS 7.6\r\nIntel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\r\n\r\n### Steps to reproduce\r\n<!-- If possible, provide a recipe for reproducing the error. A complete runnable program is good. -->\r\n\r\n1. Setup a cluster with 1 x TiDB + 1 x PD + 4 x TiKV by TiUP playground.\r\n\r\n2. Add scheduler `shuffle-leader-scheduler` to PD\r\n```\r\npd-ctl -u xxx -i\r\n\r\n» scheduler add shuffle-leader-scheduler\r\nSuccess!\r\n» scheduler show\r\n[\r\n  \"balance-hot-region-scheduler\",\r\n  \"balance-leader-scheduler\",\r\n  \"balance-region-scheduler\",\r\n  \"shuffle-leader-scheduler\",\r\n]\r\n```\r\n\r\n3. Run a multi-thread program and each thread running the following codes repeatedly:\r\n\r\n```go\r\nTry(cli.Put(ctx, key, value0))\r\nTry(cli.Put(ctx, key, value1))\r\n\r\n// Verify order by Get\r\nres := Try(cli.Get(ctx, key)).([]byte)\r\nExpect(res).To(Equal(value1))\r\n\r\n// Verify order by Scan\r\nkeys, values, err := cli.Scan(ctx, key, append(key, 0), 100)\r\nExpect(err).Should(Succeed())\r\nExpect(len(keys)).To(Equal(1))\r\nExpect(keys[0]).To(Equal(key))\r\nExpect(values[0]).To(Equal(value1))\r\n\r\n// Verify Delete\r\nTry(cli.Delete(ctx, key))\r\nres = Try(cli.Get(ctx, key)).([]byte)\r\nExpect(res).To(BeEmpty())\r\n\r\n// Verify again\r\nTry(cli.Put(ctx, key, value1))\r\nTry(cli.Put(ctx, key, value0))\r\nres = Try(cli.Get(ctx, key)).([]byte)\r\nExpect(res).To(Equal(value0))\r\n```\r\n\r\n### What did you expect?\r\nExpect succeed.\r\n\r\n### What did happened?\r\nFailed on the 5th line `Expect(res).To(Equal(value1))`. `res` equals to `value0`.\r\n```\r\n    Expected\r\n        <[]uint8 | len:72, cap:80>: 4597000_0000000000000000000000000000000000000000000000000000000000000000\r\n    to equal\r\n        <[]uint8 | len:72, cap:80>: 4597001_0000000000000000000000000000000000000000000000000000000000000000\r\n```\r\n\r\n### Analysis\r\n1. No causal timestamp fall back happened.\r\nNo error log about timestamp fall back in TSO renew is found. See #12489.\r\n\r\n2. Timestamp of entry with `value0` is larger than entry with `value1`. From result of tikv-ctl raw-scan:\r\n```\r\n➜  tikv-ctl  --data-dir tikv-3/data raw-scan -f \"zrk000000\\37700045970\\37700\\000\\000\\000\\000\\000\\000\\371\"\r\n[2022/05/12 12:48:30.182 +08:00] [WARN] [config.rs:590] [\"compaction guard is disabled due to region info provider not available\"]\r\n[2022/05/12 12:48:30.184 +08:00] [WARN] [config.rs:692] [\"compaction guard is disabled due to region info provider not available\"]\r\n[2022/05/12 12:48:39.506 +08:00] [WARN] [pipe_builder.rs:268] [\"The tail of raft log is corrupted but ignored: Rewrite:1, Corruption: Log item offset is smaller than log batch header length\"]\r\n[2022/05/12 12:48:43.968 +08:00] [WARN] [pipe_builder.rs:268] [\"The tail of raft log is corrupted but ignored: Append:122, Corruption: Log item offset is smaller than log batch header length\"]\r\nkey: \"zrk000000\\37700045970\\37700\\000\\000\\000\\000\\000\\000\\371\\371\\375%\\316\\004\\267\\377\\362\", value: \"4597000_0000000000000000000000000000000000000000000000000000000000000000\\000\"\r\nkey: \"zrk000000\\37700045970\\37700\\000\\000\\000\\000\\000\\000\\371\\371\\375%\\316\\005{\\376.\", value: \"4597001_0000000000000000000000000000000000000000000000000000000000000000\\000\"\r\nkey: \"zrk000000\\37700045970\\37700\\000\\000\\000\\000\\000\\000\\371\\371\\375%\\316\\355\\207\\376:\", value: \"4597000_0000000000000000000000000000000000000000000000000000000000000000\\000\"\r\nkey: \"zrk000000\\37700045970\\37700\\000\\000\\000\\000\\000\\000\\371\\371\\375%\\316\\355\\207\\376J\", value: \"4597001_0000000000000000000000000000000000000000000000000000000000000000\\000\"\r\nkey: \"zrk000000\\37700045970\\37700\\000\\000\\000\\000\\000\\000\\371\\371\\375%\\316\\355\\207\\376\\\\\", value: \"\\002\"\r\nkey: \"zrk000000\\37700045970\\37700\\000\\000\\000\\000\\000\\000\\371\\371\\375%\\316\\355\\207\\376p\", value: \"4597001_0000000000000000000000000000000000000000000000000000000000000000\\000\"\r\nkey: \"zrk000000\\37700045970\\37700\\000\\000\\000\\000\\000\\000\\371\\371\\375%\\316\\355\\207\\376\\221\", value: \"4597000_0000000000000000000000000000000000000000000000000000000000000000\\000\"\r\n...\r\n...\r\n\r\nTotal scanned keys: 30\r\n```",
  "state": "closed",
  "created_at": "2022-05-12T06:37:19Z",
  "updated_at": "2022-05-19T13:14:40Z",
  "closed_at": "2022-05-19T13:14:40Z",
  "labels": [
    "type/bug",
    "severity/critical",
    "feature/developing"
  ],
  "comments_data": [
    {
      "id": 1124777442,
      "user": "Lily2025",
      "created_at": "2022-05-12T09:46:06Z",
      "body": "/severity critical"
    }
  ]
}