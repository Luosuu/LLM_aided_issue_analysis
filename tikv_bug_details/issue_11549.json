{
  "issue_number": 11549,
  "title": "TiKV PD worker thread deadlocks",
  "body": "## Bug Report\r\n\r\n<!-- Thanks for your bug report! Don't worry if you can't fill out all the sections. -->\r\n\r\n### What version of TiKV are you using?\r\n\r\nv5.3.0\r\n\r\n### What operating system and CPU are you using?\r\n<!-- If you're using Linux, you can run `cat /proc/cpuinfo` -->\r\n\r\n\\-\r\n\r\n### Steps to reproduce\r\n\r\nThe exact way to trigger the issue is currently uncertain.\r\n\r\n### What did you expect?\r\n\r\nTiKV runs normally.\r\n\r\n### What did happened?\r\n\r\n1.  Its found that some queries in TiDB reports this error:\r\n\r\n```\r\nMySQL [test]> insert into t1(id,name) value(1,'dfdfd'),(2,'dfdfdffff');\r\nERROR 9011 (HY000): TiKV max timestamp is not synced\r\n```\r\n\r\nThis means async commit / 1pc transaction fails due to not updating the max_ts associated to this region.\r\n\r\n2. One of the TiKV process is alive, but PD shows it's down. The TiKV's log is nearly empty, excepts some PD reconnection related logs that's printed every 10 minutes.\r\n\r\n3. The metrics shows this TiKV node's PD heartbeat is zero, however, TiKV's GC worker is updating GC safepoint normally.\r\n\r\nI think it looks like a deadlock related to the PD worker thread. It's confirmed by @BusyJay .\r\n\r\nPartial stack provided by @BusyJay :\r\n\r\n```\r\nThread 36 (Thread 0x7fb7b5df3700 (LWP 13739)):\r\n#0  0x00007fb82e2dd54d in __lll_lock_wait () from /lib64/libpthread.so.0\r\n#1  0x00007fb82e2d8e9b in _L_lock_883 () from /lib64/libpthread.so.0\r\n#2  0x00007fb82e2d8d68 in pthread_mutex_lock () from /lib64/libpthread.so.0\r\n#3  0x00005597d049cd69 in std::sys::unix::mutex::Mutex::lock (self=<optimized out>) at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/sys/unix/mutex.rs:63\r\n#4  std::sys_common::mutex::MovableMutex::raw_lock (self=<optimized out>) at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/sys_common/mutex.rs:76\r\n#5  std::sync::mutex::Mutex<T>::lock (self=<optimized out>) at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/sync/mutex.rs:261\r\n#6  <tikv_util::future::BatchCommandsWaker as futures_task::arc_wake::ArcWake>::wake_by_ref (arc_self=<optimized out>) at components/tikv_util/src/future.rs:84\r\n```\r\n\r\n```\r\n36   Thread 0x7fb7b5df3700 (LWP 13739) \"pd-worker-0\"     0x00007fb82e2dd54d in __lll_lock_wait () from /lib64/libpthread.so.0\r\n```\r\n ",
  "state": "closed",
  "created_at": "2021-12-02T14:28:53Z",
  "updated_at": "2021-12-03T09:09:02Z",
  "closed_at": "2021-12-03T09:09:02Z",
  "labels": [
    "type/bug",
    "component/pd-client",
    "severity/critical",
    "affects-5.2",
    "affects-5.3"
  ],
  "comments_data": [
    {
      "id": 984705209,
      "user": "zz-jason",
      "created_at": "2021-12-02T14:58:21Z",
      "body": "should we set the severity to critical?"
    },
    {
      "id": 984719754,
      "user": "BusyJay",
      "created_at": "2021-12-02T15:13:26Z",
      "body": "I'm not sure how this is triggered as we don't have the full stack. If it's the similar reason like https://github.com/tikv/tikv/issues/7493, then the deadlock is introduced by https://github.com/tikv/tikv/pull/10674. However, it can happen only when timer thread stuck for more than 500ms. /cc @hicqu @5kbpers \r\n\r\nIt's still a guess, but if it's the cause, then versions after and including v5.2.0 are affected."
    }
  ]
}