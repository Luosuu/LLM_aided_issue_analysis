{
  "issue_number": 16676,
  "title": "8.0.0-alpha OOM",
  "body": "## Bug Report\r\nWe use java-client prewrite+commit data to TiKV, set memory-usage-limit=1GB, storage.memory-quota=64MB, tikv.log shows that the parameters are in effect. But tikv-server eventually occupied 200GB of memory.\r\n\r\nLater, we used go-client testing and found that the memory remained around 3GB. go-client is ok, why java-client cause OOM?\r\nWe found java-client the maxExecutionDurationMs default = 24 * 60 * 60 seceonds, go-client the maxExecutionDurationMs default = 20 seceonds(MaxWriteExecutionTime = ReadTimeoutShort - 10*time.Second).\r\nWe set java-client maxExecutionDurationMs =700ms, the memory is ok.\r\n\r\novervenus said:most OOM issues in scheduler eventually boil down to some unknown timeout or retry bugs.\r\n\r\nOur tikv-server is currently the latest version(8.0.0-alpha) compiled and still causes OOM, I would like to provide feedback.\r\n\r\nWe kown there are still some OOM issues that have not been fixed. We hope the OOM issues fixed as soon as possible, or that tikv.log can provide warn when client set abnormal parameter value.\r\n\r\n[tikv1329-1520.pdf](https://github.com/tikv/tikv/files/14647577/tikv1329-1520.pdf)\r\n\r\n\r\ntikv.toml\r\n[cdc]\r\nold-value-cache-memory-quota = \"64MB\"\r\nsink-memory-quota = \"64MB\"\r\n\r\n[log-backup]\r\ninitial-scan-pending-memory-quota = \"64MB\"\r\n\r\n[raftstore]\r\napply-pool-size = 32\r\nraft-base-tick-interval = \"2s\"\r\nstore-pool-size = 4\r\n\r\n[resolved-ts]\r\nadvance-ts-interval = \"20s\"\r\nenable = false\r\n\r\n[rocksdb]\r\nmax-background-jobs = 32\r\nmax-sub-compactions = 16\r\nwal-recovery-mode = 0\r\n[rocksdb.defaultcf]\r\nsoft-pending-compaction-bytes-limit = \"256G\"\r\n\r\n[server]\r\ngrpc-concurrency = 20\r\n\r\n[storage]\r\nmemory-quota = \"64MB\"\r\napi-version = 2\r\nenable-ttl = true\r\nscheduler-pending-write-threshold = \"64MB\"\r\nscheduler-worker-pool-size = 4\r\n[storage.block-cache]\r\ncapacity = \"1G\"\r\n\r\n\r\n### What version of TiKV are you using?\r\n./tikv-server --version\r\nTiKV \r\nRelease Version:   8.0.0-alpha\r\nEdition:           Community\r\nGit Commit Hash:   6368c439eb30c905e97a5a150c813ab5e6ae9285\r\nGit Commit Branch: master\r\nUTC Build Time:    2024-03-18 05:25:25\r\nRust Version:      rustc 1.77.0-nightly (89e2160c4 2023-12-27)\r\nEnable Features:   pprof-fp jemalloc mem-profiling portable sse test-engine-kv-rocksdb test-engine-raft-raft-engine trace-async-tasks openssl-vendored\r\nProfile:           release\r\n\r\n\r\n### What operating system and CPU are you using?\r\nAlmaLinux release 9.1 (Lime Lynx)\r\nIntel(R) Xeon(R) Silver 4210 CPU\r\n\r\n### Steps to reproduce\r\n<!-- If possible, provide a recipe for reproducing the error. A complete runnable program is good. -->\r\n\r\n### What did you expect?\r\nno OOM\r\n### What did happened?\r\nOOM",
  "state": "open",
  "created_at": "2024-03-19T08:27:21Z",
  "updated_at": "2024-08-07T05:47:52Z",
  "closed_at": null,
  "labels": [
    "type/bug",
    "severity/moderate"
  ],
  "comments_data": [
    {
      "id": 2009654116,
      "user": "overvenus",
      "created_at": "2024-03-20T14:04:33Z",
      "body": "Could you elaborate on how to reproduce the OOM issue? What's your workload? \r\n\r\nCould you upload a raw heap profile captured before OOM with the following tikv configs?\r\n\r\n```toml\r\n[memory]\r\nprofiling-sample-per-bytes = \"128MB\"\r\n[storage]\r\n[storage.block-cache]\r\ncapacity = \"1G\"\r\n```\r\n\r\nRaw profiles can be found on TiDB dashboard.\r\n![img_v3_0295_7bba03bf-3d8e-4ab9-bdf9-57fabaf3379g](https://github.com/tikv/tikv/assets/2150711/a218fc37-5640-4749-99dc-dcc480bfc019)\r\n\r\n"
    }
  ]
}