{
  "issue_number": 12366,
  "title": "tikv panic when inject network fault repeatly and  split tables",
  "body": "## Bug Report\r\n\r\n<!-- Thanks for your bug report! Don't worry if you can't fill out all the sections. -->\r\n\r\n### What version of TiKV are you using?\r\n[2022/04/15 03:54:07.621 +00:00] [INFO] [client.go:390] [\"Cluster version information\"] [type=tidb] [version=6.1.0-nightly] [git_hash=654e3d834348e300c951a03d29eee61a9e116b22]\r\n[2022/04/15 03:54:07.621 +00:00] [INFO] [client.go:390] [\"Cluster version information\"] [type=tikv] [version=6.0.0-alpha] [git_hash=b60271983288caf7d978f111cd1878b508861327]\r\n[2022/04/15 03:54:07.621 +00:00] [INFO] [client.go:390] [\"Cluster version information\"] [type=pd] [version=6.1.0-nightly] [git_hash=b7b785fb666544d8cba37f8f8c91fd169979702d]\r\n\r\n### What operating system and CPU are you using?\r\n8core、16GB\r\n\r\n### Steps to reproduce\r\noltp_stability_rel_002\r\nset：consistency-check-interval = \"60s\"\r\n1、[2022/04/15 04:05:40.911 +00:00] [INFO] [cmd.go:124] [\"Start remote command\"] [cmd=\"sysbench --mysql-user=root --db-driver=mysql --time=0 --report-interval=10 --mysql-db=test --mysql-host=tc-tidb.endless-oltp-tps-781679-1-845 --mysql-port=4000 --threads=64 --tables=32 --table-size=10000000 --mysql-ignore-errors=2013,1213,1105,1205,8022,8027,8028,9004,9007,1062 --rand-type=special oltp_insert run\"] [nodename=benchtoolset]\r\n2、[2022/04/15 04:06:41.063 +00:00] [INFO] [pdutil.go:106] [\"/pd-ctl schedule add shuffle-leader-scheduler:Success!\"]\r\n[2022/04/15 04:06:41.184 +00:00] [INFO] [pdutil.go:106] [\"/pd-ctl schedule add shuffle-region-scheduler:Success!\"]\r\n[2022/04/15 04:06:41.311 +00:00] [INFO] [pdutil.go:106] [\"/pd-ctl schedule add random-merge-scheduler:Success!\"]\r\n3、[2022/04/15 04:16:41.436 +00:00] [INFO] [chaos.go:358] [\"fault will last for\"] [duration=4m0.000000005s]\r\n[2022/04/15 04:16:41.440 +00:00] [INFO] [chaos.go:86] [\"Run chaos\"] [name=network-delay] [selectors=\"[endless-oltp-tps-781679-1-845/tc-tikv-1]\"] [experiment=\"{\\\"Duration\\\":\\\"3s\\\",\\\"Scheduler\\\":{\\\"Cron\\\":\\\"@every 5s\\\"},\\\"Latency\\\":\\\"1s\\\",\\\"Correlation\\\":\\\"25\\\",\\\"Jitter\\\":\\\"\\\"}\"]\r\n4、SplitTablesRepeatly\r\n\r\n### What did you expect?\r\nall tikv are normal\r\n\r\n### What did happened?\r\ntest plan：https://tcms.pingcap.net/dashboard/executions/plan/781679\r\nNS：endless-oltp-tps-781679-1-845\r\nlogs：http://minio.pingcap.net:42041/buckets/test-infra-testground/browse/YXJjaGl2ZS9lbmRsZXNzLW9sdHAtdHBzLTc4MTY3OS0xLTg0NQ==\r\ntikv3 panic\r\n[2022/04/15 08:59:49.032 +00:00] [FATAL] [lib.rs:468] [\"[region 23938] 127641 hash at 11550 not correct, want \\\"u0\\\\370$\\\", got \\\"J\\\\030\\\\335\\\\003\\\"!!!\"] [backtrace=\"   0: tikv_util::set_panic_hook::{{closure}}\\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/tikv_util/src/lib.rs:467:18\\n   1: std::panicking::rust_panic_with_hook\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:702:17\\n   2: std::panicking::begin_panic_handler::{{closure}}\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:588:13\\n   3: std::sys_common::backtrace::__rust_end_short_backtrace\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/sys_common/backtrace.rs:138:18\\n   4: rust_begin_unwind\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:584:5\\n   5: core::panicking::panic_fmt\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panicking.rs:143:14\\n   6: raftstore::store::fsm::peer::PeerFsmDelegate<EK,ER,T>::verify_and_store_hash\\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/peer.rs:5631:17\\n   7: raftstore::store::fsm::peer::PeerFsmDelegate<EK,ER,T>::on_ready_verify_hash\\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/peer.rs:5549:9\\n      raftstore::store::fsm::peer::PeerFsmDelegate<EK,ER,T>::on_ready_result\\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/peer.rs:4354:22\\n   8: raftstore::store::fsm::peer::PeerFsmDelegate<EK,ER,T>::on_apply_res\\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/peer.rs:1900:17\\n      raftstore::store::fsm::peer::PeerFsmDelegate<EK,ER,T>::handle_msgs\\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/peer.rs:657:21\\n   9: <raftstore::store::fsm::store::RaftPoller<EK,ER,T> as batch_system::batch::PollHandler<raftstore::store::fsm::peer::PeerFsm<EK,ER>,raftstore::store::fsm::store::StoreFsm<EK>>>::handle_normal\\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/store.rs:804:9\\n  10: batch_system::batch::Poller<N,C,Handler>::poll\\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/batch-system/src/batch.rs:458:27\\n  11: raftstore::store::worker::refresh_config::PoolController<N,C,H>::increase_by::{{closure}}\\n             at home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/worker/refresh_config.rs:71:21\\n      std::sys_common::backtrace::__rust_begin_short_backtrace\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/sys_common/backtrace.rs:122:18\\n  12: std::thread::Builder::spawn_unchecked_::{{closure}}::{{closure}}\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/thread/mod.rs:498:17\\n      <core::panic::unwind_safe::AssertUnwindSafe<F> as core::ops::function::FnOnce<()>>::call_once\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panic/unwind_safe.rs:271:9\\n      std::panicking::try::do_call\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:492:40\\n      std::panicking::try\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:456:19\\n      std::panic::catch_unwind\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panic.rs:137:14\\n      std::thread::Builder::spawn_unchecked_::{{closure}}\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/thread/mod.rs:497:30\\n      core::ops::function::FnOnce::call_once{{vtable.shim}}\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/ops/function.rs:227:5\\n  13: <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/alloc/src/boxed.rs:1854:9\\n      <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/alloc/src/boxed.rs:1854:9\\n      std::sys::unix::thread::Thread::new::thread_start\\n             at rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/sys/unix/thread.rs:108:17\\n  14: <unknown>\\n  15: clone\\n\"] [location=/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/peer.rs:5631] [thread_name=raftstore-4-0]\r\n[2022/04/15 08:59:53.086 +00:00] [INFO] [lib.rs:80] [\"Welcome to TiKV\"]\r\n",
  "state": "open",
  "created_at": "2022-04-15T10:05:42Z",
  "updated_at": "2024-11-01T10:09:14Z",
  "closed_at": null,
  "labels": [
    "type/bug",
    "severity/major",
    "affects-6.1",
    "affects-6.2",
    "affects-6.3",
    "affects-6.4",
    "affects-6.5",
    "affects-6.6",
    "affects-7.0",
    "affects-7.1",
    "affects-7.5",
    "affects-8.1",
    "affects-8.5"
  ],
  "comments_data": [
    {
      "id": 1100014150,
      "user": "Lily2025",
      "created_at": "2022-04-15T10:07:37Z",
      "body": "/type bug\r\n/severity Critical\r\n/assign hicqu"
    },
    {
      "id": 1100019505,
      "user": "Lily2025",
      "created_at": "2022-04-15T10:16:55Z",
      "body": "/remove-severity critical\r\n/severity major"
    },
    {
      "id": 1102928229,
      "user": "BusyJay",
      "created_at": "2022-04-19T17:53:24Z",
      "body": "How about running the test without dropping tables?"
    },
    {
      "id": 1103577883,
      "user": "hicqu",
      "created_at": "2022-04-20T07:47:50Z",
      "body": "There are lots of log about \"delete data in range because of stale\", which is implemented with `delete_files_in_range`. I guess it's a known problem.How about running the test without dropping tables and based on 3 tikv replicas?"
    },
    {
      "id": 1103601251,
      "user": "BusyJay",
      "created_at": "2022-04-20T08:14:02Z",
      "body": "Note delete files in range is only invoked when all existing snapshots are younger than the delete range command is generated. So I think conf change should not break correctness."
    },
    {
      "id": 1104999430,
      "user": "BusyJay",
      "created_at": "2022-04-21T10:05:28Z",
      "body": "I checked the logs, there is no \"delete data in range\" during the time when hash is being computed. @Lily2025 can you reproduce the issue with compaction filter gc disabled?"
    },
    {
      "id": 1271980015,
      "user": "tonyxuqqi",
      "created_at": "2022-10-07T18:56:02Z",
      "body": "/cc cosven\r\nPlease work with Lihua to repro this issue with compaction filter disabled and see what happen. Thanks. "
    }
  ]
}