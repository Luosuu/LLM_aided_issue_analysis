{
  "issue_number": 17731,
  "title": "tiflash is always in `Disconnected` state when upgrading from v6.1.7 to nightly",
  "body": "## Bug Report\r\n\r\n<!-- Thanks for your bug report! Don't worry if you can't fill out all the sections. -->\r\n\r\n### What version of TiKV are you using?\r\n<!-- You can run `tikv-server --version` -->\r\n\r\n### What operating system and CPU are you using?\r\n<!-- If you're using Linux, you can run `cat /proc/cpuinfo` -->\r\n\r\n### Steps to reproduce\r\n<!-- If possible, provide a recipe for reproducing the error. A complete runnable program is good. -->\r\nuse tiup upgrade tidb cluster from v6.1.7 to nightly\r\ntiup.yaml\r\n```\r\nglobal:\r\n  user: \"root\"\r\n  ssh_port: 22\r\n  deploy_dir: \"/tiup/deploy\"\r\n  data_dir: \"/tiup/data\"\r\n  arch: \"amd64\"\r\npd_servers:\r\n  - host: cluster-peer\r\ntidb_servers:\r\n  - host: cluster-peer\r\ntikv_servers:\r\n  - host: cluster-peer\r\ntiflash_servers:\r\n  - host: cluster-peer\r\nmonitoring_servers:\r\n  - host: cluster-peer\r\ngrafana_servers:\r\n  - host: cluster-peer\r\nalertmanager_servers:\r\n  - host: cluster-peer\r\nserver_configs:\r\n  tidb:\r\n    enable-telemetry: true\r\n    new_collations_enabled_on_first_bootstrap: false\r\n    performance.gogc: 200\r\n```\r\nthe step is as follows:\r\n```\r\ntiup cluster deploy cluster v6.1.7 tiup.yaml --ssh=system -y\r\ntiup cluster start cluster --wait-timeout 300 --ssh=system -y\r\ntiup exec tiup cluster upgrade cluster nightly --wait-timeout 3600 --ssh=system -y\r\n```\r\n\r\n### What did you expect?\r\nupgrade success\r\n\r\n### What did happened?\r\n![img_v3_02g4_0e7ffb17-08e8-44e5-a2ba-d67363cb9a9g](https://github.com/user-attachments/assets/3a8386da-56d0-4e9f-a647-d2c796ffabfd)\r\n```\r\n[2024/10/29 17:21:36.693 +08:00] [ERROR] [util.rs:497] [\"request failed, retry\"] [err_code=KV:Pd:Grpc] [err=\"Grpc(RpcFailure(RpcStatus { code: 12-UNIMPLEMENTED, message: \\\"unknown service meta_storagepb.MetaStorage\\\", details: [] }))\"] [thread_id=17]\r\n[2024/10/29 17:21:36.693 +08:00] [INFO] [client.rs:153] [\"TSO stream is closed, reconnect to PD\"] [thread_id=12]\r\n[2024/10/29 17:21:36.693 +08:00] [WARN] [client.rs:155] [\"failed to update PD client\"] [error=\"Other(\\\"[components/pd_client/src/util.rs:377]: cancel reconnection due to too small interval\\\")\"] [thread_id=12]\r\n[2024/10/29 17:21:36.896 +08:00] [FATAL] [lib.rs:479] [\"failed to load_latest_options \\\"Invalid argument: Could not find option: : enable_pipelined_commit\\\"\"] [backtrace=\"   0: tikv_util::set_panic_hook::{{closure}}\\n             at /workspace/source/tiflash/contrib/tiflash-proxy/components/tikv_util/src/lib.rs:478:18\\n   1: <alloc::boxed::Box<F,A> as core::ops::function::Fn<Args>>::call\\n             at /rustc/89e2160c4ca5808657ed55392620ed1dbbce78d1/library/alloc/src/boxed.rs:2029:9\\n      std::panicking::rust_panic_with_hook\\n             at /rustc/89e2160c4ca5808657ed55392620ed1dbbce78d1/library/std/src/panicking.rs:783:13\\n   2: std::panicking::begin_panic_handler::{{closure}}\\n             at /rustc/89e2160c4ca5808657ed55392620ed1dbbce78d1/library/std/src/panicking.rs:657:13\\n   3: std::sys_common::backtrace::__rust_end_short_backtrace\\n             at /rustc/89e2160c4ca5808657ed55392620ed1dbbce78d1/library/std/src/sys_common/backtrace.rs:171:18\\n   4: rust_begin_unwind\\n             at /rustc/89e2160c4ca5808657ed55392620ed1dbbce78d1/library/std/src/panicking.rs:645:5\\n   5: core::panicking::panic_fmt\\n             at /rustc/89e2160c4ca5808657ed55392620ed1dbbce78d1/library/core/src/panicking.rs:72:14\\n   6: engine_rocks::util::new_engine_opt::{{closure}}\\n             at /workspace/source/tiflash/contrib/tiflash-proxy/components/engine_rocks/src/util.rs:82:33\\n      core::result::Result<T,E>::unwrap_or_else\\n             at /rustc/89e2160c4ca5808657ed55392620ed1dbbce78d1/library/core/src/result.rs:1426:23\\n      engine_rocks::util::new_engine_opt\\n             at /workspace/source/tiflash/contrib/tiflash-proxy/components/engine_rocks/src/util.rs:82:14\\n   7: <raft_log_engine::engine::RaftLogEngine as proxy_server::common_override::ConfiguredRaftEngine>::build\\n             at /workspace/source/tiflash/contrib/tiflash-proxy/proxy_components/proxy_server/src/common_override.rs:131:26\\n   8: proxy_server::run::TiKvServer<CER,F>::init_tiflash_engines\\n             at /workspace/source/tiflash/contrib/tiflash-proxy/proxy_components/proxy_server/src/run.rs:473:50\\n      proxy_server::run::run_impl\\n             at /workspace/source/tiflash/contrib/tiflash-proxy/proxy_components/proxy_server/src/run.rs:202:9\\n   9: proxy_server::run::run_tikv_proxy\\n             at /workspace/source/tiflash/contrib/tiflash-proxy/proxy_components/proxy_server/src/run.rs:395:5\\n  10: proxy_server::proxy::run_proxy\\n             at /workspace/source/tiflash/contrib/tiflash-proxy/proxy_components/proxy_server/src/proxy.rs:325:9\\n  11: _ZN2DB20RaftStoreProxyRunner20runRaftStoreProxyFFIEPv\\n             at /workspace/source/tiflash/dbms/src/Server/Server.cpp:529:9\\n  12: start_thread\\n  13: __clone\\n\"] [location=components/engine_rocks/src/util.rs:82] [thread_name=<unnamed>] [thread_id=1]\r\n\r\n```",
  "state": "closed",
  "created_at": "2024-10-30T01:31:36Z",
  "updated_at": "2024-10-30T06:48:27Z",
  "closed_at": "2024-10-30T06:48:27Z",
  "labels": [
    "type/bug",
    "severity/major",
    "affects-8.4"
  ],
  "comments_data": [
    {
      "id": 2445633443,
      "user": "apollodafoni",
      "created_at": "2024-10-30T01:32:53Z",
      "body": "/assign @v01dstar \r\n/severity major"
    }
  ]
}