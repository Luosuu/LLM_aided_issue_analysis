{
  "issue_number": 11123,
  "title": "CDC panic \"region 298252 miss downstream\"",
  "body": "## Bug Report\r\n\r\n```\r\n[2021/10/22 19:46:48.407 +08:00] [INFO] [endpoint.rs:530] [\"cdc register region\"] [downstream_id=DownstreamID(52355)] [req_id=1435036] [conn_id=ConnID(36700)] [region_id=298252]\r\n[2021/10/22 19:46:48.408 +08:00] [INFO] [endpoint.rs:1418] [\"cdc downstream is initialized\"] [downstream_id=DownstreamID(52355)]\r\n[2021/10/22 19:46:48.442 +08:00] [INFO] [endpoint.rs:530] [\"cdc register region\"] [downstream_id=DownstreamID(52357)] [req_id=1435038] [conn_id=ConnID(36701)] [region_id=298252]\r\n[2021/10/22 19:46:48.442 +08:00] [INFO] [endpoint.rs:392] [\"cdc deregister\"] [deregister=\"Deregister { deregister: \\\"conn\\\", conn_id: ConnID(36700) }\"]\r\n[2021/10/22 19:46:48.442 +08:00] [INFO] [service.rs:256] [\"cdc receive closed\"] [conn_id=ConnID(36700)] [downstream=ipv4:172.16.5.37:58358]\r\n[2021/10/22 19:46:48.442 +08:00] [INFO] [endpoint.rs:1327] [\"cdc resolver initialized and schedule resolver ready\"] [takes=33ms] [observe_id=ObserveID(44389)] [lock_count=0] [resolved_ts=0] [downstream_id=DownstreamID(52355)] [conn_id=ConnID(36700)] [region_id=298252]\r\n[2021/10/22 19:46:48.442 +08:00] [WARN] [service.rs:283] [\"cdc send failed\"] [conn_id=ConnID(36700)] [downstream=ipv4:172.16.5.37:58358] [error=RemoteStopped]\r\n[2021/10/22 19:46:48.442 +08:00] [INFO] [endpoint.rs:1418] [\"cdc downstream is initialized\"] [downstream_id=DownstreamID(52357)]\r\n[2021/10/22 19:46:48.442 +08:00] [INFO] [delegate.rs:390] [\"cdc region is ready\"] [region_id=298252]\r\n[2021/10/22 19:46:48.442 +08:00] [INFO] [delegate.rs:233] [\"cdc fail to subscribe downstream\"] [err=\"EpochNotMatch(\\\"current epoch of region 298252 is conf_ver: 473 version: 7563, but you sent conf_ver: 473 version: 7562\\\", [id: 298252 start_key: 748000000000004DFF235F728000000000FF00405E0000000000FA end_key: 748000000000004DFF245F728000000000FF004C120000000000FA region_epoch { conf_ver: 473 version: 7563 } peers { id: 320838 store_id: 1 } peers { id: 320839 store_id: 5 } peers { id: 320840 store_id: 6 }])\"] [req_id=1435038] [conn_id=ConnID(36701)] [downstream_id=DownstreamID(52357)] [region_id=298252]\r\n[2021/10/22 19:46:48.442 +08:00] [INFO] [endpoint.rs:392] [\"cdc deregister\"] [deregister=\"Deregister { deregister: \\\"delegate\\\", region_id: 298252, observe_id: ObserveID(44389), err: Request(message: \\\"EpochNotMatch current epoch of region 298252 is conf_ver: 473 version: 7563, but you sent conf_ver: 473 version: 7562\\\" epoch_not_match { current_regions { id: 298252 start_key: 748000000000004DFF235F728000000000FF00405E0000000000FA end_key: 748000000000004DFF245F728000000000FF004C120000000000FA region_epoch { conf_ver: 473 version: 7563 } peers { id: 320838 store_id: 1 } peers { id: 320839 store_id: 5 } peers { id: 320840 store_id: 6 } } current_regions { id: 322728 start_key: 748000000000004DFF1C5F728000000000FF0013E40000000000FA end_key: 748000000000004DFF235F728000000000FF00405E0000000000FA region_epoch { conf_ver: 473 version: 7563 } peers { id: 322729 store_id: 1 } peers { id: 322730 store_id: 5 } peers { id: 322731 store_id: 6 } } }) }\"]\r\n[2021/10/22 19:46:48.442 +08:00] [INFO] [delegate.rs:336] [\"cdc met region error\"] [error=\"Request(message: \\\"EpochNotMatch current epoch of region 298252 is conf_ver: 473 version: 7563, but you sent conf_ver: 473 version: 7562\\\" epoch_not_match { current_regions { id: 298252 start_key: 748000000000004DFF235F728000000000FF00405E0000000000FA end_key: 748000000000004DFF245F728000000000FF004C120000000000FA region_epoch { conf_ver: 473 version: 7563 } peers { id: 320838 store_id: 1 } peers { id: 320839 store_id: 5 } peers { id: 320840 store_id: 6 } } current_regions { id: 322728 start_key: 748000000000004DFF1C5F728000000000FF0013E40000000000FA end_key: 748000000000004DFF235F728000000000FF00405E0000000000FA region_epoch { conf_ver: 473 version: 7563 } peers { id: 322729 store_id: 1 } peers { id: 322730 store_id: 5 } peers { id: 322731 store_id: 6 } } })\"] [region_id=298252]\r\n[2021/10/22 19:46:49.673 +08:00] [FATAL] [lib.rs:465] [\"region 298252 miss downstream\"] [backtrace=\"stack backtrace:\r\n   0: tikv_util::set_panic_hook::{{closure}}\r\n             at components/tikv_util/src/lib.rs:464\r\n   1: std::panicking::rust_panic_with_hook\r\n             at library/std/src/panicking.rs:626\r\n   2: std::panicking::begin_panic_handler::{{closure}}\r\n             at library/std/src/panicking.rs:519\r\n   3: std::sys_common::backtrace::__rust_end_short_backtrace\r\n             at library/std/src/sys_common/backtrace.rs:141\r\n   4: rust_begin_unwind\r\n             at library/std/src/panicking.rs:515\r\n   5: std::panicking::begin_panic_fmt\r\n             at library/std/src/panicking.rs:457\r\n   6: cdc::delegate::Delegate::broadcast\r\n             at components/cdc/src/delegate.rs:362\r\n      cdc::delegate::Delegate::stop\r\n             at components/cdc/src/delegate.rs:354\r\n   7: cdc::endpoint::Endpoint<T,E>::on_deregister\r\n             at /home/stn/tikv/components/cdc/src/endpoint.rs:443\r\n   8: <cdc::endpoint::Endpoint<T,E> as tikv_util::worker::pool::Runnable>::run\r\n             at /home/stn/tikv/components/cdc/src/endpoint.rs:1395\r\n   9: tikv_util::worker::pool::Worker::start_with_timer_impl::{{closure}}\r\n             at /home/stn/tikv/components/tikv_util/src/worker/pool.rs:445\r\n      <core::future::from_generator::GenFuture<T> as core::future::future::Future>::poll\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/core/src/future/mod.rs:80\r\n  10: <yatp::task::future::Runner as yatp::pool::runner::Runner>::handle\r\n             at /home/stn/.cargo/git/checkouts/yatp-e704b73c3ee279b6/0c477fb/src/task/future.rs:261\r\n  11: <tikv_util::yatp_pool::YatpPoolRunner<T> as yatp::pool::runner::Runner>::handle\r\n             at /home/stn/tikv/components/tikv_util/src/yatp_pool/mod.rs:104\r\n      yatp::pool::worker::WorkerThread<T,R>::run\r\n             at /home/stn/.cargo/git/checkouts/yatp-e704b73c3ee279b6/0c477fb/src/pool/worker.rs:48\r\n      yatp::pool::builder::LazyBuilder<T>::build::{{closure}}\r\n             at /home/stn/.cargo/git/checkouts/yatp-e704b73c3ee279b6/0c477fb/src/pool/builder.rs:91\r\n      std::sys_common::backtrace::__rust_begin_short_backtrace\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/sys_common/backtrace.rs:125\r\n  12: std::thread::Builder::spawn_unchecked::{{closure}}::{{closure}}\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/thread/mod.rs:476\r\n      <std::panic::AssertUnwindSafe<F> as core::ops::function::FnOnce<()>>::call_once\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/panic.rs:347\r\n      std::panicking::try::do_call\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/panicking.rs:401\r\n      std::panicking::try\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/panicking.rs:365\r\n      std::panic::catch_unwind\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/panic.rs:434\r\n      std::thread::Builder::spawn_unchecked::{{closure}}\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/std/src/thread/mod.rs:475\r\n      core::ops::function::FnOnce::call_once{{vtable.shim}}\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/core/src/ops/function.rs:227\r\n  13: <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/alloc/src/boxed.rs:1572\r\n      <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\r\n             at /rustc/2faabf579323f5252329264cc53ba9ff803429a3/library/alloc/src/boxed.rs:1572\r\n      std::sys::unix::thread::Thread::new::thread_start\r\n             at library/std/src/sys/unix/thread.rs:91\r\n  14: start_thread\r\n  15: __clone\r\n\"] [location=components/cdc/src/delegate.rs:362] [thread_name=cdc-0]\r\n```\r\n\r\n### What version of TiKV are you using?\r\n<!-- You can run `tikv-server --version` -->\r\n\r\n81480b1f32c5e036c3d9a35f69a88431a7b239b3 @ release-5.2 branch.\r\n\r\n### What operating system and CPU are you using?\r\n<!-- If you're using Linux, you can run `cat /proc/cpuinfo` -->\r\n\r\n### Steps to reproduce\r\n<!-- If possible, provide a recipe for reproducing the error. A complete runnable program is good. -->\r\n\r\nRun a changefeed that captures 100 tables.\r\n\r\n### What did you expect?\r\n\r\nNo panic.\r\n\r\n### What did happened?\r\n\r\nPanic.",
  "state": "closed",
  "created_at": "2021-10-22T17:33:45Z",
  "updated_at": "2021-10-25T08:34:49Z",
  "closed_at": "2021-10-25T08:34:49Z",
  "labels": [
    "type/bug",
    "component/CDC"
  ],
  "comments_data": [
    {
      "id": 950356226,
      "user": "overvenus",
      "created_at": "2021-10-24T16:44:44Z",
      "body": "This panic can be reproduced by the test\r\n\r\n```rust\r\n    #[test]\r\n    fn test_deregister_conn_then_delegate() {\r\n        let (mut ep, raft_router, _task_rx) = mock_endpoint(&CdcConfig::default());\r\n        let _raft_rx = raft_router.add_region(1 /* region id */, 100 /* cap */);\r\n        let quota = crate::channel::MemoryQuota::new(usize::MAX);\r\n\r\n        // Open conn a\r\n        let (tx1, mut rx1) = channel::channel(1, quota.clone());\r\n        let _rx1 = rx1.drain();\r\n        let conn_a = Conn::new(tx1, String::new());\r\n        let conn_id_a = conn_a.get_id();\r\n        ep.run(Task::OpenConn { conn: conn_a });\r\n\r\n        // Open conn b\r\n        let (tx2, mut rx2) = channel::channel(1, quota);\r\n        let _rx2 = rx2.drain();\r\n        let conn_b = Conn::new(tx2, String::new());\r\n        let conn_id_b = conn_b.get_id();\r\n        ep.run(Task::OpenConn { conn: conn_b });\r\n\r\n        // Register region 1 (epoch 2) at conn a.\r\n        let mut req_header = Header::default();\r\n        req_header.set_cluster_id(0);\r\n        let mut req = ChangeDataRequest::default();\r\n        req.set_region_id(1);\r\n        req.mut_region_epoch().set_version(2);\r\n        let region_epoch_2 = req.get_region_epoch().clone();\r\n        let downstream =\r\n            Downstream::new(\"\".to_string(), region_epoch_2.clone(), 0, conn_id_a, true);\r\n        ep.run(Task::Register {\r\n            request: req.clone(),\r\n            downstream,\r\n            conn_id: conn_id_a,\r\n            version: semver::Version::new(0, 0, 0),\r\n        });\r\n        assert_eq!(ep.capture_regions.len(), 1);\r\n        let observe_id = ep.capture_regions[&1].handle.id;\r\n\r\n        // Register region 1 (epoch 1) at conn b.\r\n        let mut req_header = Header::default();\r\n        req_header.set_cluster_id(0);\r\n        let mut req = ChangeDataRequest::default();\r\n        req.set_region_id(1);\r\n        req.mut_region_epoch().set_version(1);\r\n        let region_epoch_1 = req.get_region_epoch().clone();\r\n        let downstream =\r\n            Downstream::new(\"\".to_string(), region_epoch_1.clone(), 0, conn_id_b, true);\r\n        ep.run(Task::Register {\r\n            request: req.clone(),\r\n            downstream,\r\n            conn_id: conn_id_b,\r\n            version: semver::Version::new(0, 0, 0),\r\n        });\r\n        assert_eq!(ep.capture_regions.len(), 1);\r\n\r\n        // Deregister conn a.\r\n        ep.run(Task::Deregister(Deregister::Conn(conn_id_a)));\r\n        assert_eq!(ep.capture_regions.len(), 1);\r\n\r\n        // Schedule resolver ready (resolver is built by conn a).\r\n        let mut region = Region::default();\r\n        region.id = 1;\r\n        region.set_region_epoch(region_epoch_2);\r\n        ep.run(Task::ResolverReady {\r\n            observe_id,\r\n            region: region.clone(),\r\n            resolver: Resolver::new(1),\r\n        });\r\n\r\n        // Deregister deletgate due to epoch not match for conn b.\r\n        let mut epoch_not_match = ErrorHeader::default();\r\n        epoch_not_match\r\n            .mut_epoch_not_match()\r\n            .mut_current_regions()\r\n            .push(region);\r\n        ep.run(Task::Deregister(Deregister::Delegate {\r\n            region_id: 1,\r\n            observe_id,\r\n            err: Error::request(epoch_not_match),\r\n        }));\r\n    }\r\n```"
    }
  ]
}