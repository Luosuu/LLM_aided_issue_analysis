{
  "issue_number": 16661,
  "title": "slow store during TiKV scale out, and CDC lag up to 15s",
  "body": "## Bug Report\r\n\r\n<!-- Thanks for your bug report! Don't worry if you can't fill out all the sections. -->\r\n\r\n### What version of TiKV are you using?\r\n```\r\n[2024/03/14 13:06:52.475 +00:00] [INFO] [lib.rs:95] [\"Release Version:   8.0.0-alpha\"] [thread_id=1]                             \r\n[2024/03/14 13:06:52.475 +00:00] [INFO] [lib.rs:95] [\"Edition:           Community\"] [thread_id=1]                               \r\n[2024/03/14 13:06:52.475 +00:00] [INFO] [lib.rs:95] [\"Git Commit Hash:   4c121d72b842e5e4088f2741a4d2ed21cce0c59d\"] [thread_id=1]\r\n[2024/03/14 13:06:52.475 +00:00] [INFO] [lib.rs:95] [\"Git Commit Branch: heads/refs/tags/v8.0.0\"] [thread_id=1]                  \r\n```\r\n\r\n### What operating system and CPU are you using?\r\n```\r\n[root@upstream-tikv-26 log]# cat /etc/*-release                                                                  \r\nNAME=\"Rocky Linux\"                                                                                               \r\nVERSION=\"9.3 (Blue Onyx)\"                                                                                        \r\nID=\"rocky\"                                                                                                       \r\nID_LIKE=\"rhel centos fedora\"                                                                                     \r\nVERSION_ID=\"9.3\"                                                                                                 \r\nPLATFORM_ID=\"platform:el9\"                                                                                       \r\nPRETTY_NAME=\"Rocky Linux 9.3 (Blue Onyx)\"                                                                        \r\nANSI_COLOR=\"0;32\"                                                                                                \r\nLOGO=\"fedora-logo-icon\"                                                                                          \r\nCPE_NAME=\"cpe:/o:rocky:rocky:9::baseos\"                                                                          \r\nHOME_URL=\"https://rockylinux.org/\"                                                                               \r\nBUG_REPORT_URL=\"https://bugs.rockylinux.org/\"                                                                    \r\nSUPPORT_END=\"2032-05-31\"                                                                                         \r\nROCKY_SUPPORT_PRODUCT=\"Rocky-Linux-9\"                                                                            \r\nROCKY_SUPPORT_PRODUCT_VERSION=\"9.3\"                                                                              \r\nREDHAT_SUPPORT_PRODUCT=\"Rocky Linux\"                                                                             \r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"9.3\"                                                                             \r\nRocky Linux release 9.3 (Blue Onyx)                                                                              \r\nRocky Linux release 9.3 (Blue Onyx)                                                                              \r\nRocky Linux release 9.3 (Blue Onyx)                                                                              \r\n[root@upstream-tikv-26 log]# uname -a                                                                            \r\nLinux upstream-tikv-26 5.15.146+ #1 SMP Wed Jan 31 11:25:27 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux              \r\n```\r\n\r\n### Steps to reproduce\r\n1. TiDB cluster deployed in GCP GKE env, with 24 TiKV (16c64g) and PD SSD disk, cluster size ~40TB. 3 workload running, one workload with row width ~1mb, one 9kb, one 1.7kb.\r\n2. Scale out TiKV from 24 to 30 nodes.\r\n\r\n### What did you expect?\r\nScale out TiKV should not trigger slow store and evict leader scheduler, and cdc lag should be <10s during tikv scale out.\r\n\r\n### What did happened?\r\nTiKV slow store up to 100 after the TiKV scale out, and CDC lag >10s. \r\nFrom GCP disk metric, we can see that disk throughput (rw) > 1200MB/s (throughput limit of PD SSD disk), though I have set storage.io-rate-limit max-bytes-per-sec = 700MB. \r\n\r\n![image](https://github.com/tikv/tikv/assets/7403864/cc158dda-43b0-4ec4-8103-3b182d39366c)\r\n![image](https://github.com/tikv/tikv/assets/7403864/17bedc60-3e91-424f-8200-e287e0a6a218)\r\n![image](https://github.com/tikv/tikv/assets/7403864/34ea7bcb-be6b-4bcb-8a2e-3d1cb5f30e55)\r\n![image](https://github.com/tikv/tikv/assets/7403864/4d470e38-59b7-4e89-bed4-cce79b475eb6)\r\n\r\n",
  "state": "open",
  "created_at": "2024-03-17T02:01:28Z",
  "updated_at": "2024-05-22T11:25:26Z",
  "closed_at": null,
  "labels": [
    "type/bug",
    "severity/moderate",
    "affects-7.5",
    "affects-8.0",
    "affects-8.1"
  ],
  "comments_data": [
    {
      "id": 2002279306,
      "user": "fubinzh",
      "created_at": "2024-03-17T02:04:22Z",
      "body": "Cluster configuration:\r\n```\r\n==tikv==\r\nstorageClassName: premium-rwo         \r\nstorageVolumes:                       \r\n- mountPath: /var/lib/tikv/log        \r\n  name: log                           \r\n  storageClassName: local-path        \r\n  storageSize: 100Gi                  \r\n- mountPath: /var/lib/raft            \r\n  name: raft                          \r\n  storageSize: 50Gi                   \r\n- mountPath: /var/lib/wal             \r\n  name: wal                           \r\n  storageSize: 50Gi                   \r\nconfig: |                                                            \r\n  log-file = \"/var/lib/tikv/log/tikv.log\"                            \r\n                                                                     \r\n  [backup]                                                           \r\n    num-threads = 14                                                 \r\n                                                                     \r\n  [cdc]                                                              \r\n    min-ts-interval = \"50ms\"                                         \r\n                                                                     \r\n  [coprocessor]                                                      \r\n    region-max-keys = 6400000                                        \r\n    region-max-size = \"640MiB\"                                       \r\n    region-split-keys = 5120000                                      \r\n    region-split-size = \"512MiB\"                                     \r\n                                                                     \r\n  [gc]                                                               \r\n    enable-compaction-filter = false                                 \r\n                                                                     \r\n  [import]                                                           \r\n    num-threads = 18                                                 \r\n                                                                     \r\n  [quota]                                                            \r\n    foreground-write-bandwidth = \"40MB\"                              \r\n    max-delay-duration = \"1s\"                                        \r\n                                                                     \r\n  [raft-engine]                                                      \r\n    dir = \"/var/lib/raft/raft-engine\"                                \r\n    enable = true                                                    \r\n                                                                     \r\n  [raftdb]                                                           \r\n    max-open-files = 10240                                           \r\n    wal-dir = \"/var/lib/wal/raftdb\"                                  \r\n                                                                     \r\n  [raftstore]                                                        \r\n    max-leader-missing-duration = \"20m\"                              \r\n    raftdb-path = \"/var/lib/raft/raftdb\"                             \r\n    region-compact-tombstones-percent = 10                           \r\n    store-io-pool-size = 2                                           \r\n                                                                     \r\n  [readpool]                                                         \r\n    [readpool.unified]                                               \r\n      max-tasks-per-worker = 20000                                   \r\n      max-thread-count = 80                                          \r\n                                                                     \r\n  [resolved-ts]                                                      \r\n    advance-ts-interval = \"2s\"                                       \r\n                                                                     \r\n  [rocksdb]                                                          \r\n    max-open-files = 10240                                           \r\n    wal-dir = \"/var/lib/wal/rocksdb\"                                 \r\n    [rocksdb.defaultcf]                                              \r\n      level0-stop-writes-trigger = 50                                \r\n      [rocksdb.defaultcf.titan]                                      \r\n        blob-cache-size = \"24GB\"                                     \r\n        discardable-ratio = 0.4                                      \r\n        min-blob-size = \"4KB\"                                        \r\n    [rocksdb.titan]                                                  \r\n      enabled = true                                                 \r\n                                                                     \r\n  [server]                                                           \r\n    grpc-concurrent-stream = 65535                                   \r\n[storage]                             \r\n  reserve-space = \"300GB\"             \r\n  scheduler-worker-pool-size = 16     \r\n  [storage.block-cache]               \r\n    capacity = \"12GB\"                 \r\n    num-shard-bits = 4                \r\n  [storage.flow-control]              \r\n    l0-files-threshold = 45           \r\n  [storage.io-rate-limit]             \r\n    max-bytes-per-sec = \"700MB\"      \r\n==pd==\r\n config: |                                       \r\n   [log]                                         \r\n     [log.file]                                  \r\n       filename = \"/var/lib/pd/log/pd.log\"       \r\n                                                 \r\n   [schedule]                                    \r\n     enable-cross-table-merge = false             \r\n```"
    },
    {
      "id": 2002279940,
      "user": "fubinzh",
      "created_at": "2024-03-17T02:06:11Z",
      "body": "/severity major"
    },
    {
      "id": 2011721781,
      "user": "fubinzh",
      "created_at": "2024-03-21T09:22:08Z",
      "body": "This issue is not seen during a recent TiKV scale out from 27 to 30 nodes.\r\n![img_v3_0295_80eff391-3fbc-46fd-98c3-4030b7e458eg](https://github.com/tikv/tikv/assets/7403864/7d3c33c4-d79d-45a4-bcbb-cfc58c69578d)\r\n![img_v3_0295_137ee07a-4eb1-4d37-a342-a0079a03d78g](https://github.com/tikv/tikv/assets/7403864/c12bd7e3-dc93-4a50-979a-4c10a5ab07b4)\r\n![img_v3_0295_80eff391-3fbc-46fd-98c3-4030b7e458eg](https://github.com/tikv/tikv/assets/7403864/f8332b11-3876-475a-b45e-4953fa43b127)\r\n\r\n![img_v3_0295_d3f32797-6a88-41bc-9527-a3aea9f3967g](https://github.com/tikv/tikv/assets/7403864/88120164-735e-4b7d-b888-b48c24f6460e)\r\n"
    },
    {
      "id": 2011781068,
      "user": "LykxSassinator",
      "created_at": "2024-03-21T09:52:11Z",
      "body": "The root cause of this issue is that the scheduling on slow store by evicting leaders from slow nodes will impact the `check leader` progress of `resolve-ts`. The marking of slow nodes is expected as the related nodes are already slow on IO operations.\r\n\r\nThe previous issue on scaling-out is executed from scaling a cluster with 24 nodes to 30 nodes. And during the scaling progress, the IO bandwidth is fully occupied by scanning and generating snapshot, which greatly enlarges the WRITE latency on some TiKV nodes and delays the WRITE. And it causes the increasing of SlowScore.\r\n![img_v3_028t_8c951c2e-56cd-4d81-80e6-0ec8da363dag](https://github.com/tikv/tikv/assets/18441614/be672284-50f2-4c6a-b92f-3193b2e88b30)\r\n\r\nBut the latest tests based on scaling out the cluster from 27 nodes to 30 nodes, which has smaller pressures on disk. So, the impacts to WRITE latency is expected and the SlowScore does not increase.\r\n"
    },
    {
      "id": 2100153254,
      "user": "LykxSassinator",
      "created_at": "2024-05-08T09:26:28Z",
      "body": "This issue is currently anticipated and can potentially be alleviated if the storage.io-rate-limit max-bytes-per-sec feature functions as intended. Further enhancements may be implemented as discussed in https://github.com/tikv/tikv/issues/16701."
    }
  ]
}