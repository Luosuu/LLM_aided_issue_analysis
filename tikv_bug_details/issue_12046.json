{
  "issue_number": 12046,
  "title": "RaftStore panicked with out of bounds access error",
  "body": "## Bug Report\r\n\r\n<!-- Thanks for your bug report! Don't worry if you can't fill out all the sections. -->\r\n\r\n### What version of TiKV are you using?\r\n<!-- You can run `tikv-server --version` -->\r\nmaster @ cbcaab6ce56cdc0a503a5f9171470bff3c0b53da\r\n\r\n### What operating system and CPU are you using?\r\n<!-- If you're using Linux, you can run `cat /proc/cpuinfo` -->\r\nkubernetes\r\n\r\n### Steps to reproduce\r\n<!-- If possible, provide a recipe for reproducing the error. A complete runnable program is good. -->\r\nRun jepsen monotonic test.\r\n\r\n### What did you expect?\r\n\r\nNo unexpected panic of tikv during test.\r\n\r\n### What did happened?\r\n\r\nRaftStore panicked as the following log shown\r\n```\r\n[2022/02/27 10:11:04.211 +00:00] [FATAL] [lib.rs:466] [\"Out of bounds access\"] [backtrace=\"   0: tikv_util::set_panic_hook::{{closure}}\\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/tikv_util/src/lib.rs:465:18\\n   1: std::panicking::rust_panic_with_hook\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:702:17\\n   2: std::panicking::begin_panic_handler::{{closure}}\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:588:13\\n   3: std::sys_common::backtrace::__rust_end_short_backtrace\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/sys_common/backtrace.rs:138:18\\n   4: rust_begin_unwind\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:584:5\\n   5: core::panicking::panic_fmt\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panicking.rs:143:14\\n   6: core::panicking::panic_display\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panicking.rs:73:5\\n   7: core::panicking::panic_str\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panicking.rs:56:5\\n   8: core::option::expect_failed\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/option.rs:1852:5\\n   9: core::option::Option<T>::expect\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/option.rs:715:21\\n      <alloc::collections::vec_deque::VecDeque<T,A> as core::ops::index::Index<usize>>::index\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/alloc/src/collections/vec_deque/mod.rs:2853:9\\n      raftstore::store::read_queue::ReadIndexQueue<S>::advance_leader_reads\\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/read_queue.rs:238:30\\n      raftstore::store::peer::Peer<EK,ER>::apply_reads\\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/peer.rs:2694:13\\n      raftstore::store::peer::Peer<EK,ER>::handle_raft_ready_append\\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/peer.rs:2092:9\\n  10: raftstore::store::fsm::peer::PeerFsmDelegate<EK,ER,T>::collect_ready\\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/peer.rs:1307:19\\n      <raftstore::store::fsm::store::RaftPoller<EK,ER,T> as batch_system::batch::PollHandler<raftstore::store::fsm::peer::PeerFsm<EK,ER>,raftstore::store::fsm::store::StoreFsm<EK>>>::handle_normal\\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/store.rs:791:13\\n  11: batch_system::batch::Poller<N,C,Handler>::poll\\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/batch-system/src/batch.rs:446:27\\n  12: raftstore::store::worker::refresh_config::PoolController<N,C,H>::increase_by::{{closure}}\\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/worker/refresh_config.rs:71:21\\n      std::sys_common::backtrace::__rust_begin_short_backtrace\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/sys_common/backtrace.rs:122:18\\n  13: std::thread::Builder::spawn_unchecked_::{{closure}}::{{closure}}\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/thread/mod.rs:498:17\\n      <core::panic::unwind_safe::AssertUnwindSafe<F> as core::ops::function::FnOnce<()>>::call_once\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panic/unwind_safe.rs:271:9\\n      std::panicking::try::do_call\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:492:40\\n      std::panicking::try\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:456:19\\n      std::panic::catch_unwind\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panic.rs:137:14\\n      std::thread::Builder::spawn_unchecked_::{{closure}}\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/thread/mod.rs:497:30\\n      core::ops::function::FnOnce::call_once{{vtable.shim}}\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/ops/function.rs:227:5\\n  14: <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/alloc/src/boxed.rs:1854:9\\n      <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/alloc/src/boxed.rs:1854:9\\n      std::sys::unix::thread::Thread::new::thread_start\\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/sys/unix/thread.rs:108:17\\n  15: start_thread\\n  16: clone\\n\"] [location=/home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/read_queue.rs:238] [thread_name=raftstore-7-0]\r\n   0: tikv_util::set_panic_hook::{{closure}}\r\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/tikv_util/src/lib.rs:465:18\r\n   1: std::panicking::rust_panic_with_hook\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:702:17\r\n   2: std::panicking::begin_panic_handler::{{closure}}\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:588:13\r\n   3: std::sys_common::backtrace::__rust_end_short_backtrace\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/sys_common/backtrace.rs:138:18\r\n   4: rust_begin_unwind\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:584:5\r\n   5: core::panicking::panic_fmt\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panicking.rs:143:14\r\n   6: core::panicking::panic_display\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panicking.rs:73:5\r\n   7: core::panicking::panic_str\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panicking.rs:56:5\r\n   8: core::option::expect_failed\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/option.rs:1852:5\r\n   9: core::option::Option<T>::expect\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/option.rs:715:21\r\n      <alloc::collections::vec_deque::VecDeque<T,A> as core::ops::index::Index<usize>>::index\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/alloc/src/collections/vec_deque/mod.rs:2853:9\r\n      raftstore::store::read_queue::ReadIndexQueue<S>::advance_leader_reads\r\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/read_queue.rs:238:30\r\n      raftstore::store::peer::Peer<EK,ER>::apply_reads\r\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/peer.rs:2694:13\r\n      raftstore::store::peer::Peer<EK,ER>::handle_raft_ready_append\r\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/peer.rs:2092:9\r\n  10: raftstore::store::fsm::peer::PeerFsmDelegate<EK,ER,T>::collect_ready\r\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/peer.rs:1307:19\r\n      <raftstore::store::fsm::store::RaftPoller<EK,ER,T> as batch_system::batch::PollHandler<raftstore::store::fsm::peer::PeerFsm<EK,ER>,raftstore::store::fsm::store::StoreFsm<EK>>>::handle_normal\r\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/fsm/store.rs:791:13\r\n  11: batch_system::batch::Poller<N,C,Handler>::poll\r\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/batch-system/src/batch.rs:446:27\r\n  12: raftstore::store::worker::refresh_config::PoolController<N,C,H>::increase_by::{{closure}}\r\n             at /home/jenkins/agent/workspace/build-common/go/src/github.com/pingcap/tikv/components/raftstore/src/store/worker/refresh_config.rs:71:21\r\n      std::sys_common::backtrace::__rust_begin_short_backtrace\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/sys_common/backtrace.rs:122:18\r\n  13: std::thread::Builder::spawn_unchecked_::{{closure}}::{{closure}}\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/thread/mod.rs:498:17\r\n      <core::panic::unwind_safe::AssertUnwindSafe<F> as core::ops::function::FnOnce<()>>::call_once\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/panic/unwind_safe.rs:271:9\r\n      std::panicking::try::do_call\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:492:40\r\n      std::panicking::try\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panicking.rs:456:19\r\n      std::panic::catch_unwind\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/panic.rs:137:14\r\n      std::thread::Builder::spawn_unchecked_::{{closure}}\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/thread/mod.rs:497:30\r\n      core::ops::function::FnOnce::call_once{{vtable.shim}}\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/core/src/ops/function.rs:227:5\r\n  14: <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/alloc/src/boxed.rs:1854:9\r\n      <alloc::boxed::Box<F,A> as core::ops::function::FnOnce<Args>>::call_once\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/alloc/src/boxed.rs:1854:9\r\n      std::sys::unix::thread::Thread::new::thread_start\r\n             at /rustc/1e12aef3fab243407f9d71ba9956cb2a1bf105d5/library/std/src/sys/unix/thread.rs:108:17\r\n  15: start_thread\r\n  16: clone\r\n```\r\nThe full log can be accessed [here](http://minio.pingcap.net:9000/test-infra/2022-02-26/plan-exec-634870/plan-exec-634870-1335848004/archive.tgz).\r\n",
  "state": "closed",
  "created_at": "2022-02-28T08:59:11Z",
  "updated_at": "2022-04-21T08:11:50Z",
  "closed_at": "2022-03-30T09:52:29Z",
  "labels": [
    "type/bug",
    "sig/raft",
    "severity/minor",
    "affects-5.0",
    "affects-5.1",
    "affects-5.2",
    "affects-5.3",
    "affects-5.4",
    "affects-6.0"
  ],
  "comments_data": [
    {
      "id": 1055345724,
      "user": "BusyJay",
      "created_at": "2022-03-01T11:50:06Z",
      "body": "The only one way that can lead to the problem I can think of is https://github.com/tikv/tikv/pull/6348.\r\n\r\nIf a retry happens after all read states are committed inside the raft core, the raft can produce duplicated ready read states. What do you think? /cc @hicqu @5kbpers @NingLin-P "
    },
    {
      "id": 1073838761,
      "user": "you06",
      "created_at": "2022-03-21T12:34:31Z",
      "body": "This issue blocks the release of 6.0 now, what's the progress of the investigation, is it still a blocking issue? @BusyJay "
    },
    {
      "id": 1073853286,
      "user": "BusyJay",
      "created_at": "2022-03-21T12:48:58Z",
      "body": "Still no clue yet. Perhaps we should add more logs in case it's reproduced."
    },
    {
      "id": 1081093771,
      "user": "tonyxuqqi",
      "created_at": "2022-03-28T20:13:26Z",
      "body": "> The only one way that can lead to the problem I can think of is #6348.\r\n> \r\n> If a retry happens after all read states are committed inside the raft core, the raft can produce duplicated ready read states. What do you think? /cc @hicqu @5kbpers @NingLin-P\r\n\r\n#6348 retry_pending_reads() will skip on leader.  The callstack in this issue is in leader path. Do you mean retry_pending_reads() on a peer and then that peer becomes a leader and then run into this issue somehow?"
    },
    {
      "id": 1081573417,
      "user": "BusyJay",
      "created_at": "2022-03-29T08:22:05Z",
      "body": "My guess was wrong. I added more logs to check what happened. Luckily, it's not hard to reproduce."
    },
    {
      "id": 1082307184,
      "user": "BusyJay",
      "created_at": "2022-03-29T19:46:20Z",
      "body": "So the problem is packets travel too long in the network.\r\n\r\nSupposing there are 3 peers a, b and c. If c is leader and inform both a and b. Then a and c are isolated from each other. If there is a replica read request to a, it will send a ReadIndexRequest to c and then buffer in the raft client. c then transfer leader to b, and then b transfer leader to a. At that time, the network is recovered. So the read index will be sent to c first, and then c will redirect to b, and then b redirect back to a. After handling the request, a consider the read states are part of the pending reads as the from field of the request is itself. However, the request is cleared back in the time when a just becomes leader. Hence lead to panic.\r\n\r\nTo fix the problem, we need to check if the read states can be found in contexts before panicking. Perhaps we should also filter all messages that from id is the peer itself. However, this can bring more side affects."
    },
    {
      "id": 1082432095,
      "user": "tonyxuqqi",
      "created_at": "2022-03-29T22:29:40Z",
      "body": "> So the problem is packets travel too long in the network.\r\n> \r\n> Supposing there are 3 peers a, b and c. If c is leader and inform both a and b. Then a and c are isolated from each other. If there is a replica read request to a, it will send a ReadIndexRequest to c and then buffer in the raft client. c then transfer leader to b, and then b transfer leader to a. At that time, the network is recovered. So the read index will be sent to c first, and then c will redirect to b, and then b redirect back to a. After handling the request, a consider the read states are part of the pending reads as the from field of the request is itself. However, the request is cleared back in the time when a just becomes leader. Hence lead to panic.\r\n> \r\n> To fix the problem, we need to check if the read states can be found in contexts before panicking. Perhaps we should also filter all messages that from id is the peer itself. However, this can bring more side affects.\r\n\r\nwill it be more safe to just filter ReadIndexRequest instead of all messages that from id is the peer itself."
    },
    {
      "id": 1082620148,
      "user": "BusyJay",
      "created_at": "2022-03-30T04:53:11Z",
      "body": "> will it be more safe to just filter ReadIndexRequest instead of all messages that from id is the peer itself.\r\n\r\nYes, that's exact how #12300 is implemented."
    },
    {
      "id": 1082721582,
      "user": "NingLin-P",
      "created_at": "2022-03-30T07:22:55Z",
      "body": "> To fix the problem, we need to check if the read states can be found in contexts before panicking. Perhaps we should also filter all messages that from id is the peer itself. However, this can bring more side affects.\r\n\r\nHow about instead changing\r\nhttps://github.com/tikv/raft-rs/blob/2357cb22760719bcd107a90d1e64ef505bdb1e15/src/raft.rs#L2832\r\n```rust\r\nif req.from == INVALID_ID || req.from == self.id {\r\n        let rs = ReadState {...};\r\n        self.read_states.push(rs);\r\n        return None;\r\n}\r\n```\r\nto ignore the `req.from == self.id` case, which implies that the message is redirected from other peer\r\n\r\nSince `RawNode::read_index` is the only place that generates `MsgReadIndex` and for the leader's read request, these messages should always be local message (where `req.from == INVALID_ID`) because the `read_only` queue will clear when role changed in `reset`.\r\n"
    },
    {
      "id": 1082738957,
      "user": "BusyJay",
      "created_at": "2022-03-30T07:44:09Z",
      "body": "The raft message can be constructed by application and step as they are not considered local messages. Ignoring it in raft library is a broken change. Though I agree it's better fix the problem inside raft if we can ensure only `read_index` API is accepted to create the request."
    }
  ]
}